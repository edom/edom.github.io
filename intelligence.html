<!DOCTYPE html>
<html lang="">
    <head>
        <meta charset="UTF-8"/>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Making intelligence</title>
        <link rel="stylesheet" href="/assets/main.css"/>
        <script>
// Help the reader estimate how much time the reading is going to take.
// Show word count and reading time estimation in TOC entry.
//
// TOC = table of contents
//
// Known issue: This janks: this DOM manipulation is done after the page is rendered.
// If we don't want jank, we have to manipulate the HTML source before it reaches the browser.
// We assume that the user doesn't refresh the page while reading.
// The benefit of fixing that jank is not enough for me to justify trying to fix it.
document.addEventListener("DOMContentLoaded", function () {
    function count_word (string) {
        return string.trim().split(/\s+/).length;
    }
    function show_quantity (count, singular) {
        let plural = singular + "s"; // For this script only.
        return count + " " + ((count == 1) ? singular : plural);
    }
    function create_length_indicator (word, minute) {
        let e = document.createElement("span");
        e.className = "toc_entry__length_indicator";
        e.textContent = " (" + show_quantity(word, "word") + " ~ " + show_quantity(minute, "minute") + ")";
        return e;
    }
    // We assume that readers read this many words per minute with 100% comprehension.
    // This assumption may not hold for dense texts such as philosophy and mathematics.
    const wpm_assumption = 200;
    // We assume a certain Jekyll template.
    let page = document.querySelector("main.page-content");
    if (page === null) {
        console.log("toc_generate_estimate: Impossible: CSS selector \"main.page-content\" does not match anything");
        return;
    }
    let page_title = document.querySelector("header.post-header h1.post-title");
    if (page_title === null) {
        console.log("toc_generate_estimate: Impossible: CSS selector \"header.post-header h1.post-title\" does not match anything");
        return;
    }
    let page_word = count_word(page.textContent);
    let page_minute = Math.ceil(page_word / wpm_assumption);
    page_title.insertAdjacentElement("afterend", create_length_indicator(page_word, page_minute));
    // We violate the HTML specification.
    // The page may have several elements with the same ID.
    // We assume that Org HTML Export generates a DIV element with ID "table-of-contents".
    // We assume that Jekyll Markdown-to-HTML generates a UL element with ID "markdown-toc".
    // This only works for Org HTML Export's TOC.
    let toc_entries = document.querySelectorAll("#table-of-contents a, #text-table-of-contents a");
    toc_entries.forEach((toc_entry_a) => {
        let href = toc_entry_a.getAttribute("href"); // We assume that this is a string like "#org0123456".
        if (href.charAt(0) !== '#') {
            console.log("toc_generate_estimate: Impossible: " + href + " does not begin with hash sign");
            return;
        }
        // We can't just document.querySelector(href) because target_id may contain invalid ID characters such as periods.
        let target_id = href.substring(1);
        let id_escaped = target_id.replace("\"", "\\\"");
        let h_elem = document.querySelector("[id=\"" + id_escaped + "\"]"); // We assume that this is the h1/h2/h3 element referred by the TOC entry.
        if (h_elem === null) { // We assume that this is impossible.
            console.log("toc_generate_estimate: Impossible: " + href + " does not refer to anything");
            return;
        }
        let section = h_elem.parentNode;
        let section_word = count_word(section.textContent);
        let section_minute = Math.ceil(section_word / wpm_assumption);
        toc_entry_a.insertAdjacentElement("afterend", create_length_indicator(section_word, section_minute));
    });
});
        </script>

        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-12628443-6"></script>
<script>
  window['ga-disable-UA-12628443-6'] = window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1";
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-12628443-6');
</script>
        
        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            jax: ["input/TeX","input/MathML","input/AsciiMath",
            "output/CommonHTML"
            ],
            extensions: ["tex2jax.js","mml2jax.js","asciimath2jax.js","MathMenu.js","MathZoom.js","AssistiveMML.js", "a11y/accessibility-menu.js"],
            TeX: {
                extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
                , equationNumbers: {
                    autoNumber: "AMS"
                }
            },
            "CommonHTML": {
                scale: 100
            },
            "fast-preview": {
                disabled: true,
            }
        });
        </script>
        <style>
            /*
            PreviewHTML produces small Times New Roman text.
            PreviewHTML scale doesn't work.
            */
            .MathJax_PHTML { font-size: 110%; }
        </style>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js" async defer></script>
    </head>
    <body>
        <header class="site-header" role="banner">
            <div class="wrapper">
                <a class="site-title" rel="author" href="/">Erik Dominikus Research Group</a>
            </div>
        </header>
    <div style="display:none;">\(
    \renewcommand\emptyset{\varnothing}
    \newcommand\abs[1]{\left|#1\right|}
    \newcommand\dom{\textrm{dom}}
    \newcommand\cod{\textrm{cod}}
    \newcommand\Bernoulli{\textrm{Bernoulli}}
    \newcommand\Binomial{\textrm{Binomial}}
    \newcommand\Expect[1]{\mathbb{E}[#1]}
    \newcommand\Nat{\mathbb{N}}
    \newcommand\Integers{\mathbb{Z}}
    \newcommand\Real{\mathbb{R}}
    \newcommand\Rational{\mathbb{Q}}
    \newcommand\Complex{\mathbb{C}}
    \newcommand\Pr{\mathrm{P}}
    \newcommand\Time{\text{Time}}
    \newcommand\DTime{\text{DTime}}
    \newcommand\NTime{\text{NTime}}
    \newcommand\TimeP{\text{P}}
    \newcommand\TimeNP{\text{NP}}
    \newcommand\TimeExp{\text{ExpTime}}
    \newcommand\norm[1]{\left\lVert#1\right\rVert}
    \newcommand\bbA{\mathbb{A}}
    \newcommand\bbC{\mathbb{C}}
    \newcommand\bbD{\mathbb{D}}
    \newcommand\bbE{\mathbb{E}}
    \newcommand\bbN{\mathbb{N}}
    \newcommand\frakI{\mathfrak{I}}
    % deprecated; use TimeExp
    \newcommand\ExpTime{\text{ExpTime}}
    \newcommand\Compute{\text{Compute}}
    \newcommand\Search{\text{Search}}
    % model theory structure
    \newcommand\struc[1]{\mathcal{#1}}
    \newcommand\SetBuilder[2]{\{#1 ~|~ #2\}}
    \newcommand\Set[1]{\{#1\}}
    \newcommand\semantics[1]{\langle #1 \rangle}
    \newcommand\bigsemantics[1]{S\left(#1\right)}
    \)</div>
        <main class="page-content" aria-label="Content">
            <div class="wrapper">
                <article class="post">
                    <header class="post-header">
                        <h1 class="post-title">Making intelligence</h1>
                    </header>
                </article>
                <div class="post-content">
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">1</span><span class="section_title"><a href="#introduction">Introduction</a></span><span class="word_count">(336w~2m)</span></li>
<li><span class="section_number">2</span><span class="section_title"><a href="#worldagent-models">World–agent models</a></span><span class="word_count">(361w~2m)</span></li>
<li><span class="section_number">3</span><span class="section_title"><a href="#intelligence">Intelligence</a></span><span class="word_count">(1546w~8m)</span></li>
<li><span class="section_number">4</span><span class="section_title"><a href="#learning">Learning</a></span><span class="word_count">(1595w~8m)</span></li>
<li><span class="section_number">5</span><span class="section_title"><a href="#prediction">Prediction</a></span><span class="word_count">(583w~3m)</span></li>
<li><span class="section_number">6</span><span class="section_title"><a href="#planning-simulation-and-regret">Planning, simulation, and regret</a></span><span class="word_count">(368w~2m)</span></li>
<li><span class="section_number">7</span><span class="section_title"><a href="#classification">Classification</a></span><span class="word_count">(134w~1m)</span></li>
<li><span class="section_number">8</span><span class="section_title"><a href="#compression">Compression</a></span><span class="word_count">(119w~1m)</span></li>
<li><span class="section_number">9</span><span class="section_title"><a href="#attention">Attention</a></span><span class="word_count">(13w~1m)</span></li>
<li><span class="section_number">10</span><span class="section_title"><a href="#content-plan">Content plan?</a></span><span class="word_count">(101w~1m)</span></li>
<li><span class="section_number">11</span><span class="section_title"><a href="#belief-language-thought-logic">Belief, language, thought, logic</a></span><span class="word_count">(404w~3m)</span></li>
<li><span class="section_number">12</span><span class="section_title"><a href="#pain">Pain</a></span><span class="word_count">(57w~1m)</span></li>
<li><span class="section_number">13</span><span class="section_title"><a href="#ethics">Ethics?</a></span><span class="word_count">(330w~2m)</span></li>
<li><span class="section_number">14</span><span class="section_title"><a href="#literature-study">Literature study?</a></span><span class="word_count">(683w~4m)</span></li>
<li><span class="section_number">15</span><span class="section_title"><a href="#required-mathematics">Required mathematics?</a></span><span class="word_count">(1536w~8m)</span></li>
<li><span class="section_number">16</span><span class="section_title"><a href="#conversational-ai-personal-assistant">Conversational AI, personal assistant</a></span><span class="word_count">(43w~1m)</span></li>
<li><span class="section_number">17</span><span class="section_title"><a href="#crap-delete">Crap? Delete?</a></span><span class="word_count">(2221w~12m)</span></li>
<li><span class="section_number">18</span><span class="section_title"><a href="#system-models-todo-clean-up-system.org">System models? TODO clean up system.org</a></span><span class="word_count">(1310w~7m)</span></li>
<li><span class="section_number">19</span><span class="section_title"><a href="#are-we-squinting-too-hard">Are we squinting too hard?</a></span><span class="word_count">(1225w~7m)</span></li>
<li><span class="section_number">20</span><span class="section_title"><a href="#more-math">More math?</a></span><span class="word_count">(801w~5m)</span></li>
<li><span class="section_number">21</span><span class="section_title"><a href="#designing-intelligent-systems">Designing intelligent systems</a></span><span class="word_count">(1158w~6m)</span></li>
<li><span class="section_number">22</span><span class="section_title"><a href="#building-intelligent-systems">Building intelligent systems</a></span><span class="word_count">(467w~3m)</span></li>
<li><span class="section_number">23</span><span class="section_title"><a href="#meta">Meta</a></span><span class="word_count">(33w~1m)</span></li>
<li><span class="section_number">24</span><span class="section_title"><a href="#intelligence-is-self-defeating">Intelligence is self-defeating?</a></span><span class="word_count">(35w~1m)</span></li>
<li><span class="section_number">25</span><span class="section_title"><a href="#self-modifying-code">Self-modifying code?</a></span><span class="word_count">(38w~1m)</span></li>
<li><span class="section_number">26</span><span class="section_title"><a href="#what-2">What</a></span><span class="word_count">(51w~1m)</span></li>
<li><span class="section_number">27</span><span class="section_title"><a href="#karl-friston-free-energy-principle">Karl Friston free energy principle?</a></span><span class="word_count">(5w~1m)</span></li>
<li><span class="section_number">28</span><span class="section_title"><a href="#causality-machine">Causality Machine?</a></span><span class="word_count">(57w~1m)</span></li>
<li><span class="section_number">29</span><span class="section_title"><a href="#inquisitive-machines">Inquisitive machines</a></span><span class="word_count">(13w~1m)</span></li>
<li><span class="section_number">30</span><span class="section_title"><a href="#bibliography">Bibliography</a></span><span class="word_count">(1061w~6m)</span></li>
</ul>
</div>
<h2 id="introduction"><span class="section_number">1</span><span class="section_title">Introduction</span></h2>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">1.1</span><span class="section_title"><a href="#target-audience-and-goal">Target audience and goal</a></span><span class="word_count">(141w~1m)</span></li>
<li><span class="section_number">1.2</span><span class="section_title"><a href="#linguistic-conventions">Linguistic conventions</a></span><span class="word_count">(110w~1m)</span></li>
<li><span class="section_number">1.3</span><span class="section_title"><a href="#always-begin-with-analytic-philosophy">Always begin with analytic philosophy</a></span><span class="word_count">(87w~1m)</span></li>
</ul>
</div>
<h3 id="target-audience-and-goal"><span class="section_number">1.1</span><span class="section_title">Target audience and goal</span></h3>
<p>The target audience is people interested in building intelligent systems that will free us from work.</p>
<p>How do we do that? What do we need? We need a theory that shows that it is <em>possible</em> and <em>practical</em>. Then we need to design the hardware and the software. Then we need to actually build it.</p>
<p>We need a healthy mix of theory and practice: a healthy mix of philosophy, science, and engineering:</p>
<ul>
<li>Philosophers <strong>seek</strong> the <em>truth</em>.</li>
<li>Scientists <strong>find</strong> the <em>truth</em> about <em>reality</em>.</li>
<li>Engineers <strong>change</strong> <em>reality</em>.</li>
</ul>
<p><em>Philosophers</em> ask questions that advance science and engineering.</p>
<p><em>Scientists</em> craft falsifiable theories and do theory-falsifying experiments. These experiments discover some truth about reality. This truth gives the philosophers clues about what questions to ask next.</p>
<p><em>Engineers</em> builds things based on philosophy and science. However, reality differs from theory, and the engineers always have to compromise in order to build anything at all.</p>
<h3 id="linguistic-conventions"><span class="section_number">1.2</span><span class="section_title">Linguistic conventions</span></h3>
<p>In this document, &quot;thon&quot; is the gender-neutral third-person pronoun. This brilliant idea was proposed by Charles Crozat Converse in 1858.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> If you think this is arbitrary, <em>every word</em> in English is arbitrary. Why should a word invented in 1858 be discriminated from a word invented in 1500 or 2000? Why do we readily accept &quot;bromance&quot; and &quot;twerk&quot; but not &quot;thon&quot;? English is a messy living language. (What living natural language isn't?) There is no particular reason why &quot;eat&quot; had to be &quot;eat&quot; and not &quot;eet&quot; or &quot;nomm&quot;. The important thing is that we agree on the meanings of the symbols, not the details of the shape of the symbols.</p>
<h3 id="always-begin-with-analytic-philosophy"><span class="section_number">1.3</span><span class="section_title">Always begin with analytic philosophy</span></h3>
<p>We always begin our inquiry with some analytic philosophy because we have to understand what words mean. We need <em>some</em> philosophy. Too little, and we're aimless. Too much, and we get lost in linguistic masturbation.</p>
<p>Analytic philosophy is the careful usage of words. By &quot;analysis&quot;, we mean the following. First we find what a word means, using an etymology dictionary. Then we infer what that meaning implies, using only logic and language. An example of analysis is inferring that &quot;bachelor&quot; implies &quot;unmarried&quot; and &quot;wifeless&quot;.</p>
<h2 id="worldagent-models"><span class="section_number">2</span><span class="section_title">World–agent models</span></h2>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">2.1</span><span class="section_title"><a href="#the-endofunction-worldagent-model">The endofunction world–agent model</a></span><span class="word_count">(5w~1m)</span></li>
<li><span class="section_number">2.2</span><span class="section_title"><a href="#agent-intelligence-model">Agent intelligence model</a></span><span class="word_count">(200w~1m)</span></li>
<li><span class="section_number">2.3</span><span class="section_title"><a href="#other-world-agent-models">Other world-agent models?</a></span><span class="word_count">(157w~1m)</span></li>
</ul>
</div>
<h3 id="the-endofunction-worldagent-model"><span class="section_number">2.1</span><span class="section_title">The endofunction world–agent model</span></h3>
<p>See <a href="endo.html">file:endo.html</a>.</p>
<h3 id="agent-intelligence-model"><span class="section_number">2.2</span><span class="section_title">Agent intelligence model</span></h3>
<p>We assume that you have read <a href="endo.html">file:endo.html</a>.</p>
<p>Now we define intelligence, but we have to define the required things first.</p>
<p>We define the <em>orbit</em><a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> of <span class="math inline">\(A\)</span> at <span class="math inline">\(x\)</span> as the sequence <span class="math inline">\(A^0(x), A^1(x), A^2(x), \ldots\)</span>.</p>
<p>We have a function <span class="math inline">\(judge : (S&#39;)^\infty \to \Real\)</span> that judges an orbit.</p>
<p>Now we assume that every state <span class="math inline">\(x \in S&#39;\)</span> is distributed uniformly. Define <span class="math inline">\(p(r)\)</span> as the probability of finding a state <span class="math inline">\(x\)</span> where <span class="math inline">\(judge(x) \le r\)</span>. The shape of the distribution <span class="math inline">\(p\)</span> describes the intelligence of the agent.</p>
<p>The function <span class="math inline">\(penalty : S&#39; \to \Real\)</span> defines the undesirability of an agent state. Alternatively, the function <span class="math inline">\(reward : S&#39; \to \Real\)</span> defines the desirability of an agent state. The function measures how bad or how good the agent performs. This is the agent's hidden objective function. This is hardwired. This is arbitrary. The agent doesn't have to be aware of this. An intelligent agent acts to make its <span class="math inline">\(penalty(x)\)</span> as close to zero as possible in the long term for as many <span class="math inline">\(x\)</span> as possible.</p>
<p>The agent displays an intelligent behavior if it can minimize the long-term penalty from lots of starting states. The most intelligent agent is the one that minimizes its lifelong sum of penalty?</p>
<h3 id="other-world-agent-models"><span class="section_number">2.3</span><span class="section_title">Other world-agent models?</span></h3>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">2.3.1</span><span class="section_title"><a href="#input-output-model">Input-output model?</a></span><span class="word_count">(46w~1m)</span></li>
<li><span class="section_number">2.3.2</span><span class="section_title"><a href="#discrete-dynamical-system-model">Discrete dynamical system model?</a></span><span class="word_count">(74w~1m)</span></li>
<li><span class="section_number">2.3.3</span><span class="section_title"><a href="#measuring-the-intelligence-of-a-phase-space-trajectory">Measuring the intelligence of a phase space trajectory?</a></span><span class="word_count">(36w~1m)</span></li>
</ul>
</div>
<h4 id="input-output-model"><span class="section_number">2.3.1</span><span class="section_title">Input-output model?</span></h4>
<p>An agent has input and output.</p>
<p>An <em>agent logic</em> is a function <span class="math inline">\(A : M \times I \to M \times O\)</span> where <span class="math inline">\(M\)</span> is the memory type, <span class="math inline">\(I\)</span> is the input type, and <span class="math inline">\(O\)</span> is the output type.</p>
<p>We assume that the world remembers the agent memory.</p>
<h4 id="discrete-dynamical-system-model"><span class="section_number">2.3.2</span><span class="section_title">Discrete dynamical system model?</span></h4>
<p>Let <span class="math inline">\(w\)</span> be a world. Let <span class="math inline">\(a\)</span> be an agent in world <span class="math inline">\(w\)</span>. Let <span class="math inline">\(x~t\)</span> be the input of the agent at time <span class="math inline">\(t\)</span>. Let <span class="math inline">\(y~t\)</span> be the output of the agent at time <span class="math inline">\(t\)</span>. Let <span class="math inline">\(m~t\)</span> be the memory of the agent at time <span class="math inline">\(t\)</span>.</p>
<p>We assume that the agent needs one time step to compute the output. <span class="math display">\[
\begin{aligned}
    y~(t+1) &amp;= Y~(x~t)~(m~t)~t
    \\
    m~(t+1) &amp;= M~(x~t)~(m~t)~t
    \\
    x~(t+1) &amp;= X~(x~t)~(y~t)~t
\end{aligned}
\]</span></p>
<h4 id="measuring-the-intelligence-of-a-phase-space-trajectory"><span class="section_number">2.3.3</span><span class="section_title">Measuring the intelligence of a phase space trajectory?</span></h4>
<p>We can think of a human as a dynamical system. Given two phase space trajectories, the most intelligent is the most homeostatic, the most stabilizing, the most controlling. (Why?)</p>
<h2 id="intelligence"><span class="section_number">3</span><span class="section_title">Intelligence</span></h2>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">3.1</span><span class="section_title"><a href="#what-is-intelligence">What is intelligence?</a></span><span class="word_count">(421w~3m)</span></li>
<li><span class="section_number">3.2</span><span class="section_title"><a href="#artificial-intelligence">Artificial intelligence</a></span><span class="word_count">(141w~1m)</span></li>
<li><span class="section_number">3.3</span><span class="section_title"><a href="#ramble">RAMBLE</a></span><span class="word_count">(638w~4m)</span></li>
<li><span class="section_number">3.4</span><span class="section_title"><a href="#functions-involved-in-intelligence-theory">Functions involved in intelligence theory</a></span><span class="word_count">(64w~1m)</span></li>
<li><span class="section_number">3.5</span><span class="section_title"><a href="#transferability">Transferability?</a></span><span class="word_count">(32w~1m)</span></li>
<li><span class="section_number">3.6</span><span class="section_title"><a href="#what-is-the-relationship-between-ai-and-ml">What is the relationship between AI and ML?</a></span><span class="word_count">(46w~1m)</span></li>
<li><span class="section_number">3.7</span><span class="section_title"><a href="#aiml-taxonomy">AI/ML taxonomy?</a></span><span class="word_count">(202w~2m)</span></li>
<li><span class="section_number">3.8</span><span class="section_title"><a href="#interpretability">Interpretability?</a></span><span class="word_count">(9w~1m)</span></li>
</ul>
</div>
<h3 id="what-is-intelligence"><span class="section_number">3.1</span><span class="section_title">What is intelligence?</span></h3>
<p>As of 2018 there is still no firm agreement on what &quot;intelligence&quot; is.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> <span class="citation" data-cites="sep-artificial-intelligence">[<a href="#ref-sep-artificial-intelligence">8</a>]</span></p>
<p>The etymology of &quot;intelligence&quot; is unclear.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> The word &quot;intelligent&quot; might have come from a Latin word that means &quot;to choose between&quot;.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> Related words are &quot;intellect&quot; and &quot;intellectual&quot;. We think that &quot;stupid&quot; is the opposite of &quot;intelligent&quot;. Although we don't know what &quot;intelligence&quot; is, we generally agree that most humans are somewhat &quot;intelligent&quot;.</p>
<p>Some definitions give hints for modeling intelligence mathematically. In 1923, Edwin Boring proposed that we start out by defining intelligence as what intelligence tests measure &quot;until further scientific observation allows us to extend the definition&quot;.<span class="citation" data-cites="boring1923intelligence">[<a href="#ref-boring1923intelligence">7</a>]</span> Intelligence is relative to the test that is used to measure it. As of 2018 the most general definition of &quot;intelligence&quot; is Hutter and Legg's 2006 definition: &quot;Intelligence measures an agent's ability to achieve goals in a wide range of environments&quot;<span class="citation" data-cites="DefineMachIntel">[<a href="#ref-DefineMachIntel">32</a>]</span><span class="citation" data-cites="Legg2007Collection LeggHutterFormal LeggPhd">[<a href="#ref-LeggPhd">29</a>–<a href="#ref-LeggHutterFormal">31</a>]</span>. I think it subsumes all other definitions listed in their 2007 collection of definitions<span class="citation" data-cites="Legg2007Collection">[<a href="#ref-Legg2007Collection">30</a>]</span>. Legg and Hutter approached intelligence from algorithmic complexity theory (Solomonoff induction).<span class="citation" data-cites="DefineMachIntel">[<a href="#ref-DefineMachIntel">32</a>]</span> Schmidhuber, Hutter, and team have used Solomonoff algorithmic probability and Kolmogorov complexity to define a theoretically optimal predictor they call AIXI, and they define &quot;universal&quot; and &quot;optimal&quot;.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a><a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> There are many definitions in psychology, but I ignored them because their anthropocentrism encumbers mathematization.</p>
<p>There are more exotic theories that I have not understood. Warren D. Smith approached intelligence from computational complexity theory (NP-completeness).<span class="citation" data-cites="WdsIntel WdsIntelSlide">[<a href="#ref-WdsIntelSlide">47</a>, <a href="#ref-WdsIntel">48</a>]</span> Alexander Wissner-Gross's causal entropic forces <span class="citation" data-cites="wissner2013causal">[<a href="#ref-wissner2013causal">61</a>]</span>. Tononi's integrated information theory<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>. Shour 2018 defined intelligence as &quot;a rate of problem solving […]&quot;<span class="citation" data-cites="shour2018defining">[<a href="#ref-shour2018defining">45</a>]</span>. Karl Friston's free-energy principle <span class="citation" data-cites="friston2006free friston2010free">[<a href="#ref-friston2010free">15</a>, <a href="#ref-friston2006free">16</a>]</span><a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>.</p>
<p>Why did intelligence evolve? From nature's point of view, intelligence is the ability to survive and reproduce under wide variety of environments (selection pressures). Intelligence evolved because it promotes survival and reproduction. Natural selection chooses intelligence. Intelligent individuals are more likely to survive and breed than unintelligent individuals are.</p>
<p>Microbial intelligence<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>?</p>
<p>Intelligence is something intrinsic to an individual that promotes its and its descendants' survival and reproduction. Thus we are intelligent because: our recent ancestors were intelligent, and their intelligence helped them survive and reproduce enough to finally beget us.</p>
<p>There is a philosophical treason that we have to commit in order to be able to make progress at all: we have to <em>conflate internal state and external behavior</em>. As of 2018 I still haven't seen how I can write anything without <em>conflating internal state and external behavior</em>. Thus, for progress, I commit the duck-typing<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a> fallacy: &quot;If it <em>looks</em> intelligent, then it <em>is</em> intelligent.&quot; The <em>behavior</em> of a system is whatever it exhibits that can be observed from outside.</p>
<h3 id="artificial-intelligence"><span class="section_number">3.2</span><span class="section_title">Artificial intelligence</span></h3>
<p>AI stands for &quot;artificial intelligence&quot;. &quot;Artificial&quot; simply means &quot;made by humans&quot;. In the 1950s, AI was whatever McCarthy et al. were doing.<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a><a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a><a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a></p>
<p>What are AI approaches? How are we trying to make an AI? Pedro Domingos <span class="citation" data-cites="domingos2015master">[<a href="#ref-domingos2015master">14</a>]</span> categorizes AI approaches into five <em>tribes</em>: symbolists (symbolic logic), connectionists (neural networks), evolutionaries (genetic algorithms), bayesians (statistical learning, probabilistic inference), and analogizers (what is this?).</p>
<p>What else could &quot;intelligence&quot; mean? &quot;Intelligent&quot; means smart. &quot;Intelligent&quot; means &quot;does something well&quot;? &quot;Intelligent&quot; means able to survive in wide environments. In politics, intelligence is covert warfare, and is often contrasted against physical power. Chemotaxis is an example of intelligence. Chemotaxis can be modeled as mathematical optimization, as gradient following (ascent or descent). Andrea Schmidt described chemotaxis as a biased random walk.<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a> The bias is the chemical concentration gradient.</p>
<p>Intelligence is relative: it depends on the goal used to measure it.<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a></p>
<h3 id="ramble"><span class="section_number">3.3</span><span class="section_title">RAMBLE</span></h3>
<p>Intelligence is an ordering (2018-04-26). This idea goes back at least to 2004 in <span class="citation" data-cites="hutter2004universal">[<a href="#ref-hutter2004universal">23</a>]</span>. Intelligence is an <em>ordering</em> of systems. An order is a transitive antisymmetric relation.</p>
<p>How do we decide which of system <span class="math inline">\(A\)</span> and system <span class="math inline">\(B\)</span> is more intelligent in task <span class="math inline">\(T\)</span>?</p>
<p>Let <span class="math inline">\(T(A)\)</span> denote how well system <span class="math inline">\(A\)</span> does task <span class="math inline">\(T\)</span>. This is a number. Higher is better. We can invent any measurement. Our definition of &quot;intelligence&quot; is only as good as this measurement.</p>
<p>We say &quot;<span class="math inline">\(A\)</span> is <em><span class="math inline">\(T\)</span>-better</em> than <span class="math inline">\(B\)</span>&quot; iff <span class="math inline">\(T(A) &gt; T(B)\)</span>.</p>
<p>Let <span class="math inline">\(S\)</span> be a set of tasks.</p>
<p>We say &quot;<span class="math inline">\(A\)</span> <em><span class="math inline">\(S\)</span>-dominates</em> <span class="math inline">\(B\)</span>&quot; iff <span class="math inline">\(T(A) &gt; T(B)\)</span> for every task <span class="math inline">\(T \in S\)</span>.</p>
<p>We define &quot;to be more <span class="math inline">\(S\)</span>-intelligent than&quot; to mean &quot;to <span class="math inline">\(S\)</span>-dominate&quot;.</p>
<p>The <span class="math inline">\(S\)</span>-domination relation forms a partial order of all systems.</p>
<p>Example: Which is more intelligent, a dog or a rock? That depends on the task. It's the rock if the task is to sit still. It's the dog if the task is to move around.</p>
<p>Intelligence is function optimization (2018-04-27). Let <span class="math inline">\(g\)</span> be a goal function. A system's <span class="math inline">\(g\)</span>-intelligence is how well it optimizes <span class="math inline">\(g\)</span>. What is &quot;how well&quot;? Optimization (extremization) is either minimization or maximization.</p>
<p>Intelligence is what?</p>
<p>Intelligence is a spectrum. Is a human intelligent? Is a rock intelligent? A human is more intelligent than a rock. Is a human pretending to be a rock intelligent?</p>
<p>Can an intelligent system look non-intelligent (hide its intelligence)?</p>
<p>We can measure intelligence as numbers.</p>
<p>Adapting needs learning.</p>
<p>We say X adapts to Y iff Y surprises X less as time goes by. (Whose idea is this?)</p>
<p>Intelligence needs state. State needs time. Intelligence is control. An intelligent system is a special case of control system.</p>
<p>Intelligence relative to something is a real number.</p>
<p>Is a company, which consists of intelligent people, intelligent?</p>
<p>Alan Turing proposed the Turing test.</p>
<p>I think we use the word 'intelligence' to refer to a stabilizing behavior that is complex enough to elude a simple explanation.</p>
<p>I think we agree that we are intelligent.</p>
<p>We cannot know if something is intrinsically intelligent. We can only determine intelligence from what we can observe.</p>
<p>How do we determine how intelligent something is? An intelligent being may elude detection by pretending to be unintelligent.</p>
<p>What is a mathematical theory of intelligence?</p>
<p>(RAMBLE; DELETE)</p>
<p>Here I try an alternative formalization to <span class="citation" data-cites="DefineMachIntel">[<a href="#ref-DefineMachIntel">32</a>]</span>.</p>
<p>Let <span class="math inline">\(E\)</span> be a set of <em>environments</em>.</p>
<p>Let <span class="math inline">\(G : E \to \Real\)</span> be a <em>goal function</em>. The value of <span class="math inline">\(G(e)\)</span> measures how well the agent performs in environment <span class="math inline">\(e\)</span>.</p>
<p>The <em>intelligence</em> of the agent <em>with respect to <span class="math inline">\(G\)</span> across $E$</em> is <span class="math inline">\(\int_E G\)</span>.</p>
<p>A <em>performance</em> consists of an agent and an environment.</p>
<p>Assumption: The agent cannot modify <span class="math inline">\(G\)</span>.</p>
<p>Behavior is a function taking an environment and outputing something.</p>
<p>Intelligence is <em>relative</em> to <span class="math inline">\(G\)</span> and <span class="math inline">\(E\)</span>: <em>goal</em> and <em>environment</em>.</p>
<p>If we see longevity as intelligence test, then an illiterate farmer who lives to 80 is more intelligent than a scientist who dies at 20, but a rock that has been there for 100 years would even be more intelligent than the farmer.</p>
<p>If we see money as intelligence test, then a corrupt politician who steals billions of dollars without getting caught is more intelligent than a honest farmer who only has tens of thousands of dollars.</p>
<p>Gaming the system is a sign of intelligence. It is hard to design a goal function that gives the desired outcome without undesired side effects.</p>
<p>IQ tests are intelligence measures with small environment set.</p>
<p>Lifespan may be an intelligence measure with huge environment set.</p>
<p>A human can optimize <em>several</em> goal functions across the same environment set. A human may be asked to clean a floor, to write a report, to run a company, to cook food, and to find the quickest route between home and office, and optimize them all.</p>
<p>Some goal functions for humans may be:</p>
<ul>
<li>Maximize happiness</li>
<li>Minimize pain</li>
<li>Optimize the level of a chemical in the brain</li>
<li>Optimize the time integral of such chemical</li>
<li>Maximize the chance of survival</li>
</ul>
<p>But I don't know the root goal function that explains all those behaviors.</p>
<h3 id="functions-involved-in-intelligence-theory"><span class="section_number">3.4</span><span class="section_title">Functions involved in intelligence theory</span></h3>
<p>Several types of functions are involved in intelligence theory. They are summarized in the following table; each row describes a function type.</p>
<table>
<caption>Some types of functions related to learning</caption>
<thead>
<tr class="header">
<th>domain</th>
<th>codomain</th>
<th>name</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\{0,1\}^*\)</span></td>
<td><span class="math inline">\(\{0,1\}^*\)</span></td>
<td>compression (if bijective)</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\{0,1\}^*\)</span></td>
<td><span class="math inline">\(\{0,1\}\)</span></td>
<td>decider</td>
</tr>
<tr class="odd">
<td><span class="math inline">\([0,1]^n\)</span></td>
<td><span class="math inline">\([0,1]\)</span></td>
<td>neuron</td>
</tr>
<tr class="even">
<td><span class="math inline">\(E\)</span></td>
<td><span class="math inline">\(C\)</span> finite</td>
<td>classification (if surjective)</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(E\)</span> finite</td>
<td><span class="math inline">\(C\)</span> finite</td>
<td>discrete classification (if surjective)</td>
</tr>
<tr class="even">
<td><span class="math inline">\(E\)</span> finite</td>
<td><span class="math inline">\(C\)</span> of size 2</td>
<td>discrete binary classification (if surjective)</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\Nat\)</span></td>
<td><span class="math inline">\(E\)</span></td>
<td>sequence</td>
</tr>
<tr class="even">
<td><span class="math inline">\(E^n\)</span></td>
<td><span class="math inline">\(E\)</span></td>
<td>stateless next-value predictor with lag <span class="math inline">\(n\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(C \times E^n\)</span></td>
<td><span class="math inline">\(C \times E\)</span></td>
<td>stateful next-value predictor with lag <span class="math inline">\(n\)</span></td>
</tr>
</tbody>
</table>
<h3 id="transferability"><span class="section_number">3.5</span><span class="section_title">Transferability?</span></h3>
<p>A test only measures how good the subject is at <em>doing that test</em>. What justifies our belief that a high test score implies the ability to do things <em>similar</em> to the test?</p>
<h3 id="what-is-the-relationship-between-ai-and-ml"><span class="section_number">3.6</span><span class="section_title">What is the relationship between AI and ML?</span></h3>
<p>ML is a subset of AI.</p>
<p>Then what is the rest of AI that is not ML?</p>
<ul>
<li>Ethics? Philosophy? Rule systems?</li>
<li><a href="https://ai.stackexchange.com/questions/35/what-is-the-difference-between-artificial-intelligence-and-machine-learning">AI SE 35: What is the difference between artificial intelligence and machine learning?</a></li>
<li>What is intelligence without learning? Non-adaptive intelligence? Static intelligence?</li>
</ul>
<h3 id="aiml-taxonomy"><span class="section_number">3.7</span><span class="section_title">AI/ML taxonomy?</span></h3>
<p>What should the categories be?</p>
<p>Artificial intelligence is constrained optimization.</p>
<p>Generate vs discriminative.</p>
<p>Type type of an <em>expert system</em> is <span class="math inline">\(Facts \to Query \to Answer\)</span>. Decision tree. Linearized decision tree.</p>
<p>A learning algorithm is <em>stable</em> iff its generalization error is bounded.</p>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">3.7.1</span><span class="section_title"><a href="#hyperplane-classifier">Hyperplane classifier</a></span><span class="word_count">(45w~1m)</span></li>
<li><span class="section_number">3.7.2</span><span class="section_title"><a href="#support-vector-machine">Support vector machine</a></span><span class="word_count">(121w~1m)</span></li>
</ul>
</div>
<h4 id="hyperplane-classifier"><span class="section_number">3.7.1</span><span class="section_title">Hyperplane classifier</span></h4>
<p>Let <span class="math inline">\(h\)</span> be a hyperplane. Define <span class="math inline">\(m : \Real^\infty \to \{0,1\}\)</span>, the <em>hard linear binary classifier</em> of <span class="math inline">\(h\)</span>, as <span class="math inline">\(m~x = [h~x \ge 0]\)</span> where <span class="math inline">\([x]\)</span> is 1 iff <span class="math inline">\(x\)</span> is true or 0 iff <span class="math inline">\(x\)</span> is false. Soft classifier: define <span class="math inline">\(m~x = \tanh^{-1}~(h~x)\)</span>.</p>
<h4 id="support-vector-machine"><span class="section_number">3.7.2</span><span class="section_title">Support vector machine</span></h4>
<p>A training point <span class="math inline">\(x\)</span> is a support of <span class="math inline">\(h\)</span> iff it is the closest point to <span class="math inline">\(h\)</span> among all points in the class of <span class="math inline">\(x\)</span>.</p>
<p>Alternative formulation: An upper level is a hyperplane <span class="math inline">\(h_u\)</span> such that <span class="math inline">\(\forall a \in U : h_u~a &gt; 0\)</span>. A lower level is a hyperplane <span class="math inline">\(h_l\)</span> such that <span class="math inline">\(\forall b \in L : h_l~b &lt; 0\)</span>. Let <span class="math inline">\(h_u\)</span> and <span class="math inline">\(h_l\)</span> be parallel. Maximize the distance between <span class="math inline">\(h_u\)</span> and <span class="math inline">\(h_l\)</span>. Then <span class="math inline">\(h_u\)</span> is the upper margin and <span class="math inline">\(h_l\)</span> is the lower margin. Define <span class="math inline">\(h\)</span> as the hyperplane exactly between <span class="math inline">\(h_u\)</span> and <span class="math inline">\(h_l\)</span>.</p>
<p>Define <span class="math inline">\(m : \Real^\infty \to \{0,1\}\)</span>, the <em>support vector machine</em> (SVM) of <span class="math inline">\(h\)</span>, as <span class="math inline">\(m~x = [h~x \ge 0]\)</span>. Such SVM is a binary classifier.</p>
<h3 id="interpretability"><span class="section_number">3.8</span><span class="section_title">Interpretability?</span></h3>
<p>&lt;2018-09-28&gt; Book: &quot;interpretable machine learning&quot;<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a></p>
<p>2017 survey <span class="citation" data-cites="biran2017explanation">[<a href="#ref-biran2017explanation">6</a>]</span></p>
<p><a href="https://en.wikipedia.org/wiki/Explainable_Artificial_Intelligence">WP:Explainable Artificial Intelligence</a></p>
<h2 id="learning"><span class="section_number">4</span><span class="section_title">Learning</span></h2>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">4.1</span><span class="section_title"><a href="#learning-is-getting-better-at-something">Learning is getting better at something</a></span><span class="word_count">(746w~4m)</span></li>
<li><span class="section_number">4.2</span><span class="section_title"><a href="#non-adaptive-intelligence-without-learning">Non-adaptive intelligence without learning</a></span><span class="word_count">(85w~1m)</span></li>
<li><span class="section_number">4.3</span><span class="section_title"><a href="#teaching-autodidactism-and-metalearning">Teaching, autodidactism, and metalearning</a></span><span class="word_count">(196w~1m)</span></li>
<li><span class="section_number">4.4</span><span class="section_title"><a href="#ml-epistemology-how-do-we-know-that-a-system-has-learned-something">ML epistemology: How do we know that a system has learned something?</a></span><span class="word_count">(33w~1m)</span></li>
<li><span class="section_number">4.5</span><span class="section_title"><a href="#learning-complexity">Learning complexity</a></span><span class="word_count">(107w~1m)</span></li>
<li><span class="section_number">4.6</span><span class="section_title"><a href="#colt-measuring-intelligence">COLT: measuring intelligence</a></span><span class="word_count">(257w~2m)</span></li>
<li><span class="section_number">4.7</span><span class="section_title"><a href="#toward-a-unified-theory-of-learning">Toward a unified theory of learning?</a></span><span class="word_count">(70w~1m)</span></li>
<li><span class="section_number">4.8</span><span class="section_title"><a href="#adversarial-learning">Adversarial learning?</a></span><span class="word_count">(26w~1m)</span></li>
<li><span class="section_number">4.9</span><span class="section_title"><a href="#neural-networks">Neural networks?</a></span><span class="word_count">(83w~1m)</span></li>
</ul>
</div>
<h3 id="learning-is-getting-better-at-something"><span class="section_number">4.1</span><span class="section_title">Learning is getting better at something</span></h3>
<p>What is learning? &quot;Learner <em>learns</em> Thing&quot; iff Learner <em>causes</em> itself to <em>get better</em> at Thing. A teacher may <em>contribute</em> to the improvement, but the learner itself <em>causes</em> that improvement.<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a> Learning is self-improvement.<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a> &quot;To <em>learn</em> Thing&quot; is to <em>become more intelligent</em> in Thing; remember that intelligence is relative. For example, &quot;they learn to cook&quot; means that they are trying to get better in cooking, that is, how to cook more tasty food with less effort in less time. &quot;Learning X&quot; means finding a way to use the brain more efficiently for X so that X feels more effortless.</p>
<p>How should we model learning for ML purposes? Learning can be seen as <em>approximation in Sobolev spaces</em>, if we are into approximation theory, optimization theory, and functional analysis. Another possibility: In 1984 Valiant proposed the PAC (probably approximately correct) learning model<span class="citation" data-cites="valiant1984theory">[<a href="#ref-valiant1984theory">57</a>]</span>, but it is limited to learning propositional logic formulas. It is one piece of the theory that we need to build intelligent systems.</p>
<p>&quot;Better&quot; implies an ordering of goodness. &quot;Get better&quot; implies time. Thus we may model &quot;get better&quot; with <em>monotonically increasing test score</em>, or <em>converging sequence</em>, or <em>vanishing error</em>.</p>
<p>Learning can be defined as <em>convergence</em>. Sequence, learning, and approximation: Here an <em>agent</em> is a sequence. The agent <span class="math inline">\(a : \Nat \to T\)</span> <em>learns</em> the target <span class="math inline">\(t : T\)</span> iff the sequence <span class="math inline">\(a\)</span> converges to <span class="math inline">\(t\)</span>. Formally, the agent <span class="math inline">\(a\)</span> learns the target <span class="math inline">\(t\)</span> iff <span class="math inline">\(\lim_{n\to\infty} a_n = t\)</span>.</p>
<p>Let there be a system. Devise a test. Let the system do the test several times. Let the test results be the sequence <span class="math inline">\(X = x_1, x_2, \ldots, x_n\)</span>. We say that the system is <em>getting better</em> at that test iff <span class="math inline">\(x_1 &lt; x_2 &lt; \ldots &lt; x_n\)</span> (that is iff the sequence of test scores is <em>monotonically increasing</em>).</p>
<p>What is the absolute minimum requirements for learning?? Learning requires feedback and changeable internal state. How do we formalize &quot;experience&quot;? &quot;Experience&quot; can be modeled by a sequence? experience? mistakes? memory?</p>
<p>Here are some other models of learning. (Why do we bother discussing this if we won't use this further?) Psychology sees learning as adaptation and habituation. Formal education sees learning as <em>getting high grades</em> in exams. Epistemology sees learning as <em>acquisition of knowledge</em>. YouTube sees learning as <em>maximizing</em> people's addiction to YouTube so that they linger on YouTube, with the hope that they click more ads. Each of those models captures an aspect of our analytic-philosophical definition of learning as getting better in something.</p>
<p>ML stands for &quot;machine learning&quot;. &quot;Machine learning addresses the question of how to build computers that improve automatically through experience.&quot;<span class="citation" data-cites="jordan2015machine">[<a href="#ref-jordan2015machine">25</a>]</span> However, we are not only interested in humans and machines, but in all intelligent beings.</p>
<p>Machine learning is finding a function fitting a data list, minimizing error on unseen data. Machine learning is about how program improves with experience.</p>
<p>Find a function fitting the data and minimizing the <em>loss function</em>.</p>
<p>Given <span class="math inline">\([(x_1,y_1),\ldots,(x_n,y_n)]\)</span>, find <span class="math inline">\(f\)</span> minimizing <span class="math inline">\(\sum_k \norm{f(x_k) - y_k}^2\)</span>.</p>
<p>A <em>model</em> is a constrained optimization problem: Given <span class="math inline">\(C\)</span>, compute <span class="math inline">\(\min_{x \in C} f(x)\)</span> or <span class="math inline">\(\argmin_{x \in C} f(x)\)</span>. If <span class="math inline">\(C\)</span> is discrete, use dynamic programming. If <span class="math inline">\(C\)</span> is continuous, use gradient descent.</p>
<p>A <em>learner</em> inhabits <span class="math inline">\([(a,b)] \to (a \to b)\)</span>.</p>
<p>A <em>loss function</em> inhabits <span class="math inline">\((a,b,\Real^\infty) \to \Real\)</span>.</p>
<p>The <em>training loss</em> of <span class="math inline">\(g(x) = w \cdot f(x)\)</span> with respect to <span class="math inline">\(D\)</span> is <span class="math inline">\(\frac{1}{|D|} \sum_{(x,y) \in D} L(x,y,w)\)</span> where <span class="math inline">\(L\)</span> is the loss function.</p>
<p>Learning is finding <span class="math inline">\(w\)</span> that minimizes the training loss.</p>
<p>Let <span class="math inline">\(y \in \{-1,+1\}\)</span>. The <em>score</em> of <span class="math inline">\(f\)</span> for <span class="math inline">\((x,y)\)</span> is <span class="math inline">\(f(x)\)</span>. The <em>margin</em> of <span class="math inline">\(f\)</span> for <span class="math inline">\((x,y)\)</span> is <span class="math inline">\(f(x) \cdot y\)</span>.</p>
<p>Binarization of <span class="math inline">\(f\)</span> is <span class="math inline">\(\sgn \circ f\)</span>.</p>
<p>Least-squares linear regression</p>
<p>Minimize training loss</p>
<p>Gradient descent training with initial weight <span class="math inline">\(w_1\)</span>, iteration count <span class="math inline">\(T\)</span>, and step size <span class="math inline">\(\eta\)</span>: Let <span class="math inline">\(K : \Real^n \to \Real\)</span> be the training loss function. Let <span class="math inline">\(\nabla K\)</span> be the gradient of <span class="math inline">\(K\)</span>. The weight update equation is <span class="math inline">\(w_{t+1} = w_t - \eta \cdot (\nabla K)(w_t)\)</span> where <span class="math inline">\(w_1\)</span> may be random. The training result is <span class="math inline">\(w_T\)</span>.</p>
<p>Stochastic gradient descent (SGD) training: <span class="math inline">\(w_{t+1} = w_t - \eta \cdot (\nabla(L~x_t~y_t))(w_t)\)</span>. Note the usage of the loss function <span class="math inline">\(L\)</span> instead of the training loss function <span class="math inline">\(K\)</span>.</p>
<p>SGD is <em>online</em> or <em>incremental</em> training.</p>
<p>Classification is regression with zero-one loss function. Every classification can be turned into regression by using <em>hinge loss</em> or <em>logistic regression</em>.</p>
<p>The <em>logistic function</em> is <span class="math inline">\(f(x) = \frac{1}{1 + e^{-x}}\)</span>.</p>
<p>Nearest neighbor with training data list <span class="math inline">\(D\)</span>: <span class="math inline">\(g(x&#39;) = y\)</span> where <span class="math inline">\((x,y) \in D\)</span> minimizing <span class="math inline">\(\norm{f(x&#39;) - f(x)}^2\)</span>.</p>
<p>Seminal papers?<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a></p>
<p>TODO Read?</p>
<ul>
<li><a href="https://arxiv.org/abs/1405.1513">Ibrahim Alabdulmohsin: A Mathematical Theory of Learning</a></li>
<li>1999: <a href="http://www.cis.syr.edu/people/royer/stl2e/">Sanjay Jain et al.: Systems that learn</a></li>
<li>2017, <a href="https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/building-machines-that-learn-and-think-for-themselves/E28DBFEC380D4189FB7754B50066A96F">Building machines that learn and think for themselves</a></li>
<li><span class="citation" data-cites="geffner2018model">[<a href="#ref-geffner2018model">18</a>]</span></li>
</ul>
<h3 id="non-adaptive-intelligence-without-learning"><span class="section_number">4.2</span><span class="section_title">Non-adaptive intelligence without learning</span></h3>
<p>What is the relationship between intelligence and learning? Can we have one without the other? Yes. A system that stops learning after it obtains intelligence is still intelligent. A computer program with sufficiently many conditionals is intelligent, but it never learns. An intelligent system does not have to learn. A non-learning intelligent system will continue to satisfy its goal as long as the system stays in the environments it is familiar with.</p>
<p>Both intelligence and learning requires measuring <em>how well</em> something is done.</p>
<h3 id="teaching-autodidactism-and-metalearning"><span class="section_number">4.3</span><span class="section_title">Teaching, autodidactism, and metalearning</span></h3>
<p>What is teaching? &quot;Teacher <em>teaches</em> Thing to Learner&quot; iff Teacher <em>helps</em> Learner learn Thing. Teaching is mostly about sequencing lessons to maximize learning speed.</p>
<p>What is the relationship between teaching and learning? Teachers needs learners, because otherwise there is no one to teach. If learning is the shaping of belief, then teaching is the spreading of belief. Belief is software: belief can be duplicated but not be moved. Language enables some belief transfer and capture. If we know how to learn, then we know how to teach, and also the converse. &quot;Learn&quot; is a transitive verb that takes one object: one learns <em>something</em>. &quot;Teach&quot; is a transitive verb that takes <em>two</em> objects: one teaches <em>something</em> to <em>someone</em>, possibly to thonself in case of autodidactism. But &quot;autodidactism&quot; (&quot;self-teaching&quot;) is somewhat nonsensical: you can't tell yourself something that you don't know. When you read a book, the book <em>teaches</em> you, and you <em>learn</em> from the book. But you may speed up your learning using some metalearning techniques. Thus, when we say &quot;autodidactism&quot;, we actually mean &quot;metalearning&quot;. Of human learning, the most important ideas seem to be goal-directed learning, the forgetting curve<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a>, and Bloom's taxonomy of learning<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a>.</p>
<h3 id="ml-epistemology-how-do-we-know-that-a-system-has-learned-something"><span class="section_number">4.4</span><span class="section_title">ML epistemology: How do we know that a system has learned something?</span></h3>
<p>The only way to know whether the system has learning something is by testing it with samples the system has never seen?</p>
<h3 id="learning-complexity"><span class="section_number">4.5</span><span class="section_title">Learning complexity</span></h3>
<p>How complex is something to learn? Every computable thing is learnable, in principle. Formal language with lower descriptive complexity is more learnable. Smoother functions are more learnable. This suggests that computation theory : computation-complexity theory = learning theory : learning-complexity theory.</p>
<p>Smoother functions are more learnable (easier to learn). Convex boundary is more learnable than concave boundary. A polyhedron is a three-dimensional polygon. A polytope is a higher-dimensional polyhedron. The analogy is polytope : polyhedron : polygon = hypercube : cube : square. The boundary of a cluster is a polytope. A cluster with convex polytope boundary is more learnable than a cluster with concave polytope boundary.</p>
<h3 id="colt-measuring-intelligence"><span class="section_number">4.6</span><span class="section_title">COLT: measuring intelligence</span></h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Computational_learning_theory">Wikipedia: Computational learning theory</a>
<ul>
<li>What is the goal of computational learning theory?
<ul>
<li>&quot;Give a rigorous, computationally detailed and plausible account of how learning can be done.&quot; [Angluin1992]</li>
</ul></li>
<li>&quot;a subfield of Artificial Intelligence devoted to studying the design and analysis of machine learning algorithms&quot;</li>
</ul></li>
<li>Supervised learning is extrapolating a function from finite samples. Usually, the function is high-dimensional, and the samples are few.</li>
<li>It is simple to measure learning success in perfect information games such as chess. Chess also doesn't require any sensors and motors.</li>
</ul>
<p>What COLT?</p>
<ul>
<li>2000, György Turán, <a href="https://link.springer.com/article/10.1023%2FA%3A1018948021083">Remarks on COLT</a></li>
<li>2016, Krendzelak, Jakab, <a href="https://ieeexplore.ieee.org/document/7802092/">Fundamental principals of Computational Learning Theory</a>
<ul>
<li>Reading queue:
<ul>
<li>D. Angluin, C. Smith, &quot;Inductive inference: theory and methods&quot;, A.C.M. Computing Surveys, vol. 15, pp. 237-269, 1983.</li>
<li>M. Anthony, N. Biggs, &quot;Computational Learning Theory&quot; in , Cambridge university press, 1992.</li>
<li>M.J. Kearns, &quot;The computational Complexity of Machine Learning&quot; in , The MIT Press, May 1990.</li>
<li>L. Pitt, L.G. Valiant, &quot;Computational limitations on learning from examples&quot;, Journal of the A.C.M., vol. 35, no. 4, pp. 965-984, 1988.</li>
</ul></li>
</ul></li>
<li>helpful slides <a href="https://cs.uwaterloo.ca/~klarson/teaching/W15-486/lectures/22Colt.pdf">https://cs.uwaterloo.ca/~klarson/teaching/W15-486/lectures/22Colt.pdf</a></li>
<li>Bertoni et al. http://elearning.unimib.it/pluginfile.php/283303/mod_resource/content/1/Apprendimento_Automatico/Computational_Learning.pdf</li>
<li><a href="https://stats.stackexchange.com/questions/142906/what-does-pac-learning-theory-mean">https://stats.stackexchange.com/questions/142906/what-does-pac-learning-theory-mean</a></li>
<li><a href="https://pdfs.semanticscholar.org/presentation/fbbd/65646c8a81094864d4e0b0dfb9c1f22181af.pdf">https://pdfs.semanticscholar.org/presentation/fbbd/65646c8a81094864d4e0b0dfb9c1f22181af.pdf</a></li>
<li><a href="http://web.cs.iastate.edu/~honavar/colt-tutorial.pdf">http://web.cs.iastate.edu/~honavar/colt-tutorial.pdf</a></li>
<li><a href="http://www.cis.upenn.edu/~mkearns/">http://www.cis.upenn.edu/~mkearns/</a> the computational complexity of machine learning <a href="http://www.cis.upenn.edu/~mkearns/papers/thesis.pdf">http://www.cis.upenn.edu/~mkearns/papers/thesis.pdf</a> <a href="https://www.worldscientific.com/worldscibooks/10.1142/10175">https://www.worldscientific.com/worldscibooks/10.1142/10175</a></li>
<li>2015 <a href="http://www.cs.tufts.edu/~roni/Teaching/CLT/">http://www.cs.tufts.edu/~roni/Teaching/CLT/</a></li>
<li>probably link to this <a href="http://bactra.org/notebooks/learning-theory.html">http://bactra.org/notebooks/learning-theory.html</a></li>
<li>semantics-first <a href="https://pdfs.semanticscholar.org/83e7/b615c165209af54dd0fe05c850bb08232625.pdf">https://pdfs.semanticscholar.org/83e7/b615c165209af54dd0fe05c850bb08232625.pdf</a></li>
<li>discrete approximation theory see the references of this paper <a href="https://www.worldscientific.com/doi/suppl/10.1142/10175/suppl_file/10175_chap01.pdf">https://www.worldscientific.com/doi/suppl/10.1142/10175/suppl_file/10175_chap01.pdf</a></li>
<li><a href="https://profs.info.uaic.ro/~ciortuz/SLIDES/ml7.pdf">https://profs.info.uaic.ro/~ciortuz/SLIDES/ml7.pdf</a></li>
</ul>
<p>Optimal learning for humans <a href="https://www.kqed.org/mindshift/37289">https://www.kqed.org/mindshift/37289</a></p>
<p>Curate from this <a href="https://thesecondprinciple.com/optimal-learning/">https://thesecondprinciple.com/optimal-learning/</a></p>
<p>Boston dynamics dog robots</p>
<p>Tesla car autopilots</p>
<p>Google and Uber self-driving cars</p>
<p><a href="https://www.quora.com/Will-we-ever-have-a-rigorous-and-robust-definition-for-intelligence">https://www.quora.com/Will-we-ever-have-a-rigorous-and-robust-definition-for-intelligence</a></p>
<p>rigorous definition of intelligence The new ai is general and rigorous, idsia Toward a theory of intelligence,RAND</p>
<p>A system responds to a stimulus. Define: a system is <em>adapting</em> to a stimulus if the same stimulus level elicits decreasing response level from the system. The stimulus level has to be increased to maintain the response level.</p>
<p>Is learning = adapting? Is intelligence = adaptiveness?</p>
<h3 id="toward-a-unified-theory-of-learning"><span class="section_number">4.7</span><span class="section_title">Toward a unified theory of learning?</span></h3>
<p>What is learning? Shallow definitions. To learn is to avoid repeating past mistakes.</p>
<p>TODO Unify learning, prediction, modeling, approximation, control, hysteresis, memory. These things are similar:</p>
<ul>
<li>hysteresis</li>
<li>memory</li>
<li>smoothing</li>
<li>infinite-impulse-response filter</li>
</ul>
<p><em>Optimal reverse prediction</em> unifies supervised and unsupervised learning <span class="citation" data-cites="xu2009optimal">[<a href="#ref-xu2009optimal">62</a>]</span>. Then <span class="citation" data-cites="white2012generalized">[<a href="#ref-white2012generalized">59</a>]</span> generalizes <span class="citation" data-cites="xu2009optimal">[<a href="#ref-xu2009optimal">62</a>]</span> to non-linear predictors.</p>
<p>Is hysteresis<a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a>] learning? Is hysteresis memory? Does intelligence require learning?</p>
<p>Is it possible to accomplish the same goal in different environments without learning?</p>
<p>Use discrete sequences</p>
<p>Gradient descent</p>
<p><a href="https://forum.azimuthproject.org/discussion/1538/machine-learning">https://forum.azimuthproject.org/discussion/1538/machine-learning</a></p>
<h3 id="adversarial-learning"><span class="section_number">4.8</span><span class="section_title">Adversarial learning?</span></h3>
<p>How do we learn amid lies, deception, disinformation, misinformation? Related to adversarial learning? <a href="https://en.wikipedia.org/wiki/Adversarial_machine_learning">https://en.wikipedia.org/wiki/Adversarial_machine_learning</a> ?</p>
<p><span class="math inline">\(P\)</span> tries to predict <span class="math inline">\(G\)</span>. <span class="math inline">\(G\)</span> tries to make <span class="math inline">\(P\)</span> wrong.</p>
<h3 id="neural-networks"><span class="section_number">4.9</span><span class="section_title">Neural networks?</span></h3>
<p>Neural networks is one architecture that makes machine trainable. Neural network is not necessarily the best architecture for intelligence. Evolution is a greedy optimization algorithm.</p>
<p>Topologically, a neural network layer is a continuous map. It transforms the input space into a more separable space. Consider the set of points that satisfy the classifier. This set is a manifold. A neural network layer stretches, rotates, manipulates that manifold. The output wants to be box-shaped. But isn't this just the idea of Kohonen's self-organizing maps?</p>
<h2 id="prediction"><span class="section_number">5</span><span class="section_title">Prediction</span></h2>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">5.1</span><span class="section_title"><a href="#what-is-prediction">What is prediction?</a></span><span class="word_count">(148w~1m)</span></li>
<li><span class="section_number">5.2</span><span class="section_title"><a href="#next-value-prediction-of-a-sequence">Next-value prediction of a sequence</a></span><span class="word_count">(160w~1m)</span></li>
<li><span class="section_number">5.3</span><span class="section_title"><a href="#mess">MESS</a></span><span class="word_count">(277w~2m)</span></li>
</ul>
</div>
<h3 id="what-is-prediction"><span class="section_number">5.1</span><span class="section_title">What is prediction?</span></h3>
<p>&quot;To predict&quot; is to foretell.<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a> &quot;To predict something&quot; is to say it before it happens.</p>
<p>What is the difference between prediction and guessing? Prediction is <em>justified</em>, whereas guessing is <em>luck</em>. Thus prediction is justified belief whose truth is unknown but likely. Thus prediction (justified belief) is <em>almost</em> knowledge (justified true belief).</p>
<p>What is the difference between prediction and reasoning, if prediction is justified (reasoned) foretelling?</p>
<p>Our prediction is the output of our model of reality.</p>
<p>What do we mean by &quot;predicting economic crisis&quot;? It is easy to predict that there <em>will be</em> an economic crisis, but it is hard to predict <em>when</em> that crisis will happen.</p>
<p>How do we model the prediction of economic crisis?</p>
<p>Prediction is extrapolation. Prediction is uncertain. Prediction is probabilistic. Predicting the past is called &quot;counterfactual reasoning&quot;.</p>
<p>What can be predicted? The next values of a sequence. The <em>previous</em> values of a sequence.</p>
<p>What justifies prediction? Past knowledge. Belief? Revelation?</p>
<h3 id="next-value-prediction-of-a-sequence"><span class="section_number">5.2</span><span class="section_title">Next-value prediction of a sequence</span></h3>
<p><em>Next-value prediction with lag <span class="math inline">\(n\)</span></em> is answering &quot;Given <span class="math inline">\(x_1, \ldots, x_n \in E\)</span>, what is the most likely value of <span class="math inline">\(x_{n+1} \in E\)</span>?&quot; This is finite sequence extrapolation?</p>
<p>A <em>stateless next-value predictor with lag <span class="math inline">\(n\)</span></em> is a function <span class="math inline">\( p : E^n \to E \)</span>. &quot;Stateless&quot; is also called &quot;memoryless&quot; or &quot;context-free&quot;. The lag is the memory, the lookback. Examples of such predictor is Markov chains.</p>
<p>A <em>stateful next-value predictor with lag <span class="math inline">\(n\)</span></em> is a function <span class="math inline">\( p : C \times E^n \to C \times E \)</span>. The stateless one is just a special case where <span class="math inline">\(C\)</span> is a singleton set (a set with one element only).</p>
<p>A predictor can predict arbitrarily far by feeding its output back into its input, in the fashion of this recurrence relation:</p>
<span class="math display">\[\begin{align*}
c_1, x_{n+1} &amp;= p(c_0, x_1, \ldots, x_{n+0})
\\ c_2, x_{n+2} &amp;= p(c_1, x_2, \ldots, x_{n+1})
\\ c_3, x_{n+3} &amp;= p(c_2, x_3, \ldots, x_{n+2})
\\ &amp;\vdots
\\ c_k, x_{n+k} &amp;= p(c_{k-1}, x_{k+1}, \ldots, x_{k+n}) &amp; \text{(the recurrence relation)}
\end{align*}
\]</span>
<p>Thus a machine implementing that predictor requires memory for storing one element of <span class="math inline">\(C\)</span> and <span class="math inline">\(n\)</span> elements of <span class="math inline">\(E\)</span>. Also observe that if <span class="math inline">\(p\)</span> is <em>primitive-recursive</em><a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a>, then the recurrence relation above is also primitive-recursive.</p>
<h3 id="mess"><span class="section_number">5.3</span><span class="section_title">MESS</span></h3>
<p>Finitists? Is <span class="math inline">\(x\)</span> where <span class="math inline">\(x_k = k\)</span> a sequence or a <em>description</em> of a sequence? A sequence is finite; for example: <span class="math inline">\(1,2,3\)</span> is a sequence of length 3. The following is a <em>description</em> of a sequence, not a sequence: <span class="math inline">\(1,2,3,\ldots\)</span>.</p>
<p>Topologically, a predictor is a function whose codomain is a <em>projection</em><a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a> or an <em>embedding</em><a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a> of its domain.</p>
<p>A <em>classifier</em> is a predictor with finite codomain.</p>
<p>A <em>feature</em> is a function <span class="math inline">\(f : A \to \Real\)</span>.</p>
<p>A <em>data</em> or an <em>example</em> is a tuple <span class="math inline">\((x,y) \in A \times B\)</span>.</p>
<p>A <em>linear predictor</em> is the equation <span class="math inline">\(y = w \cdot f(x)\)</span> where <span class="math inline">\(w\)</span> is the <em>weight vector</em>, <span class="math inline">\(f(x) = (f_1(x),\ldots,f_n(x))\)</span> is the <em>feature vector</em> of <span class="math inline">\(x\)</span>, <span class="math inline">\(f_k(x)\)</span> is the <span class="math inline">\(k\)</span>th feature, <span class="math inline">\(x\)</span> is the input, and <span class="math inline">\(y\)</span> is the predicted output. The predictor is linear in <span class="math inline">\(w\)</span>.</p>
<p>Now, what if the prediction is probabilistic? Every discrete probability space <span class="math inline">\((\Omega,F,P)\)</span> forms a <em>module</em><a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a> with <span class="math inline">\(\Real\)</span>. A discrete probability space <em>almost</em> forms a vector space. We use &quot;probabilistic value&quot; (&quot;probval vector field&quot;). The idea is to represent the outcome of a fair coin toss as <span class="math inline">\( \frac{1}{2}H + \frac{1}{2}T \)</span> where <span class="math inline">\(H\)</span> represents &quot;head with probability 1&quot; and <span class="math inline">\(T\)</span> represents &quot;tail with probability 1&quot;. Each of <span class="math inline">\(H\)</span> and <span class="math inline">\(T\)</span> is a basis vector. We can represent <span class="math inline">\(H = (0,1)\)</span> and <span class="math inline">\(T = (1,0)\)</span>. If two events are <em>independent</em>, then their <em>dot product</em> is zero. The components of a probability vector must sum up to one. Thus <span class="math inline">\(\frac{1}{2}H\)</span> represents &quot;head with probability 1/2&quot;. This is similar to bra-ket in Dirac quantum electrodynamics formulation, but we use real probabilities instead of complex probability amplitudes. Name? Probabilistic propositional calculus. Propositional calculus commutative group. Real event module. Probabilistic event module. Belief module.</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Probability_vector">https://en.wikipedia.org/wiki/Probability_vector</a></li>
<li><a href="https://en.wikipedia.org/wiki/Bra%E2%80%93ket_notation">https://en.wikipedia.org/wiki/Bra%E2%80%93ket_notation</a></li>
<li>probability monad</li>
</ul>
<h2 id="planning-simulation-and-regret"><span class="section_number">6</span><span class="section_title">Planning, simulation, and regret</span></h2>
<p>We identify three meanings of planning:</p>
<ul>
<li>simulation, regret prevention</li>
<li>topological ordering of known choices</li>
<li>creatively finding a way to achieve goal</li>
</ul>
<p>Planning has several meanings. To plan is to prepare the future. To plan is to prepare for the future.</p>
<p>&quot;Plan&quot; comes from Latin the &quot;planum&quot; which in 1706 meant &quot;drawing&quot;.<a href="#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a> Presumably it means the drawing of something that architects are going to build. Why do architects plan? <em>To prevent expensive mistakes</em>: building is expensive, but drawing is cheap. It is cheap to change the plan, but it is expensive to change the building once it has been built. A 1 man-hour change in the plan may translate to a 100 man-hour change in the building. Thus the essence of planning is not the drawing, but the <em>prevention of future expensive mistakes</em>. Therefore, to <em>plan</em> is to <em>prevent regret</em>. In the 1530s &quot;regret&quot; meant &quot;pain or distress in the mind at something done or left undone&quot;<a href="#fn30" class="footnote-ref" id="fnref30"><sup>30</sup></a>. Regret is the realization that something could have been done in the past that would improve the present. Regret is the wish to have done something differently in the past. Regret is the wish to change the past.</p>
<p>If we were incapable of regret, would we plan?</p>
<p>Planning is <em>simulation</em>. To plan X is to simulate X in order to actually do X, to clarify X. To simulate X is to construct a mental model of X. A plan is a simulation. A plan is a model of what is to be achieved.</p>
<p>Commit to a plan?</p>
<p>Example usages. Planned parenthood. Unplanned children. Unplanned expenses. Disaster recovery plan. Fighting is planning. &quot;If X happens, we will do Y.&quot; &quot;If he right-straights me, I'll dodge right and left-uppercut him.&quot;</p>
<p>&quot;I plan to go there.&quot;</p>
<p>Planning is future-oriented thinking- Planning is future-directed thinking. Planning is a special case of thinking. To plan X is to want X. To plan for X is to be ready for X.</p>
<p>100-year plan</p>
<p>Planning is optimization by permutation?</p>
<p>Given a sequence of actions <span class="math inline">\(a_1, \ldots, a_n\)</span>, permute that sequence to <span class="math inline">\(a_{p(1)}, \ldots, a_{p(n)}\)</span>, in order to minimize <span class="math inline">\(e(a)\)</span> (the effort of doing <span class="math inline">\(a\)</span>).</p>
<p>Planning is anticipation.</p>
<p>Planning can anticipate most but not all things reality may throw on us.</p>
<p>Planning is topologically ordering a set into a directed acyclic graph. Tree? Forest?</p>
<h2 id="classification"><span class="section_number">7</span><span class="section_title">Classification</span></h2>
<p>Classification is surjection and abstraction.</p>
<p>Key ideas:</p>
<ul>
<li>A classification is a surjective function.</li>
<li>A classifier is an approximation of a classification.</li>
</ul>
<p>Relationship between classification and prediction: A classifier tries to <em>predict</em> the class of things in a domain.</p>
<p>Let <span class="math inline">\(X\)</span> be a set of things that we want to classify.</p>
<p>Let <span class="math inline">\(N\)</span> be the set of <em>class indexes</em>. We assume that <span class="math inline">\(N\)</span> is a finite set of some first natural numbers. This set represents class &quot;names&quot;.</p>
<p>The <em>class index</em> of <span class="math inline">\(x\)</span> is <span class="math inline">\(c(x)\)</span>.</p>
<p>A <em>classification</em> is a surjective function <span class="math inline">\(c : X \to N\)</span>. &quot;Surjective&quot; means that there is no empty class (there is no unused class index).</p>
<p>A <em>classifier</em> is an <em>approximation</em> of a classification.</p>
<p>Classification loses details. In a classification from A to B, there have to be more elements in A than in B. Therefore classification is an example of abstraction.</p>
<h2 id="compression"><span class="section_number">8</span><span class="section_title">Compression</span></h2>
<p>Compression is bijection.</p>
<p>A <em><a href="https://en.wikipedia.org/wiki/Data_compression">compression</a></em> is a bijection from strings to strings. Formally, a compression is a bijection <span class="math inline">\( c : B^* \to B^* \)</span> where <span class="math inline">\( B = \{0,1\} \)</span> is the alphabet and <span class="math inline">\(*\)</span> is the <a href="https://en.wikipedia.org/wiki/Kleene_star">Kleene star</a>.</p>
<p>A compression exploits input regularity to shorten likely strings and elongate unlikely strings. We assume that a compression's input strings are narrowly distributed.</p>
<p>An example of compression is a natural language such as English. The word &quot;eat&quot; is shorter than the word &quot;antidisestablishmentarianism&quot; because we are more likely to use the former more than the latter.</p>
<p>A &quot;lossy compression&quot; is called an <em>approximation</em>. For example, &quot;JPEG compression&quot; should be called &quot;JPEG approximation&quot;. There is no need to invent the phrase &quot;lossy compression&quot;.</p>
<p>ML can be used to compress.</p>
<h2 id="attention"><span class="section_number">9</span><span class="section_title">Attention</span></h2>
<p>Attention is temporary discrimination (temporary preferential treatment, temporary focusing) of some sensory inputs.</p>
<h2 id="content-plan"><span class="section_number">10</span><span class="section_title">Content plan?</span></h2>
<ul>
<li>What is the relationship between intelligence, complexity, and compression?</li>
<li>What is the &quot;everything is compression&quot; view of intelligence?</li>
</ul>
<p>What is safe AI? What is friendly AI?</p>
<p>What is seed AI? How do we, with minimum effort, bootstrap a machine that will free us forever from work? That is actually two questions in one: what is the hardware, and what is the software?</p>
<p>Learning theory combines many areas of mathematics: approximation theory, computation theory, functional analysis, information theory, probability theory and statistics, and others.</p>
<p>Some people tried something similar? What?<a href="#fn31" class="footnote-ref" id="fnref31"><sup>31</sup></a><a href="#fn32" class="footnote-ref" id="fnref32"><sup>32</sup></a>.</p>
<p>Bibliography??? <span class="citation" data-cites="DeepArch">[<a href="#ref-DeepArch">4</a>]</span> <span class="citation" data-cites="DeepLearning">[<a href="#ref-DeepLearning">21</a>]</span> <span class="citation" data-cites="RepLearn">[<a href="#ref-RepLearn">5</a>]</span> <span class="citation" data-cites="SuttonBartoRein">[<a href="#ref-SuttonBartoRein">53</a>]</span></p>
<p>Algorithmic information theory <span class="citation" data-cites="AlgoInfTh">[<a href="#ref-AlgoInfTh">22</a>]</span></p>
<p>What?</p>
<ul>
<li>Watch John Cagnol's MOOC &quot;an introduction to functional analysis&quot;<a href="#fn33" class="footnote-ref" id="fnref33"><sup>33</sup></a></li>
<li>Watch <a href="https://bloomberg.github.io/foml/#about">https://bloomberg.github.io/foml/#about</a></li>
</ul>
<h2 id="belief-language-thought-logic"><span class="section_number">11</span><span class="section_title">Belief, language, thought, logic</span></h2>
<p>Prolog seems suitable for parsing and compiling.<span class="citation" data-cites="cohen1987parsing">[<a href="#ref-cohen1987parsing">9</a>]</span><span class="citation" data-cites="vittek1996compiler">[<a href="#ref-vittek1996compiler">58</a>]</span></p>
<p>It is possible to parse limited English in Prolog.<a href="#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a></p>
<p>&lt;2018-12-30&gt; Idea: &quot;Intelligence&quot; is a set of meta-logic rules for updating the knowledge base (internal beliefs) with respect to observations. An agent's total belief is a logic formula in conjunctive-normal form.</p>
<p>Relating symbolism and connectionism: How does our internal representation of logic and language arise from neural networks?</p>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">11.1</span><span class="section_title"><a href="#explaining-reasoning-justifying">Explaining, reasoning, justifying</a></span><span class="word_count">(43w~1m)</span></li>
<li><span class="section_number">11.2</span><span class="section_title"><a href="#conjectures-about-language-and-logic">Conjectures about language and logic</a></span><span class="word_count">(85w~1m)</span></li>
<li><span class="section_number">11.3</span><span class="section_title"><a href="#concept-spaces-word-vectors-concept-vectors-bags-of-words">Concept spaces, word vectors, concept vectors, bags of words</a></span><span class="word_count">(44w~1m)</span></li>
<li><span class="section_number">11.4</span><span class="section_title"><a href="#humes-problem-of-induction">Hume's problem of induction</a></span><span class="word_count">(8w~1m)</span></li>
<li><span class="section_number">11.5</span><span class="section_title"><a href="#exception-inference-machine-doxastic-logic-how-a-machine-may-update-its-own-beliefs-upon-encountering-counterevidence">&lt;2018-12-28&gt; Exception inference, machine doxastic logic, how a machine may update its own beliefs upon encountering counterevidence</a></span><span class="word_count">(165w~1m)</span></li>
</ul>
</div>
<h3 id="explaining-reasoning-justifying"><span class="section_number">11.1</span><span class="section_title">Explaining, reasoning, justifying</span></h3>
<p>Given a finite prefix of a sequence, find the most likely program that generates the sequence with that prefix.</p>
<p>Who (Hutter? Legg?) shows us how to answer this with Solomonoff algorithmic probability<span class="citation" data-cites="solomonoff1996does">[<a href="#ref-solomonoff1996does">49</a>]</span>, which is unfortunately incomputable.</p>
<p>TODO read theory of justification<span class="citation" data-cites="sep-epistemology">[<a href="#ref-sep-epistemology">52</a>]</span><a href="#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a></p>
<p>Natural language processing?</p>
<h3 id="conjectures-about-language-and-logic"><span class="section_number">11.2</span><span class="section_title">Conjectures about language and logic</span></h3>
<p>Conjectures:</p>
<ul>
<li>Natural languages are just <em>surface syntaxes</em> for first-order logic.</li>
</ul>
<p>It is straightforward to write a Prolog program that parses some limited English. It is still practical to write a Prolog program that parses some richer English with named entity recognition. Prolog definite-clause grammars make parsing easy</p>
<p>Another problems:</p>
<ul>
<li>Which information source should the computer trust?</li>
<li>How should the computer reconcile conflicting information?</li>
</ul>
<p>2011 &quot;Natural Language Processing With Prolog in the IBM Watson System&quot; <a href="https://www.cs.nmsu.edu/ALP/2011/03/natural-language-processing-with-prolog-in-the-ibm-watson-system/">https://www.cs.nmsu.edu/ALP/2011/03/natural-language-processing-with-prolog-in-the-ibm-watson-system/</a></p>
<p>If IBM Watson is possible, then a personal search assistant should be possible.</p>
<h3 id="concept-spaces-word-vectors-concept-vectors-bags-of-words"><span class="section_number">11.3</span><span class="section_title">Concept spaces, word vectors, concept vectors, bags of words</span></h3>
<p>Let Car represent the concept of car. Let Red represent the concept of red. Let Modify(Car,Red) represent the concept of red car. Then Modify(X,Red) - Modify(Y,Red) = X - Y.</p>
<p>Modify(X,M) - Modify(Y,M) = X - Y.</p>
<p>Literature?</p>
<h3 id="humes-problem-of-induction"><span class="section_number">11.4</span><span class="section_title">Hume's problem of induction</span></h3>
<p>How do we justify induction?<a href="https://en.wikipedia.org/wiki/Rule_of_succession">https://en.wikipedia.org/wiki/Rule_of_succession</a></p>
<h3 id="exception-inference-machine-doxastic-logic-how-a-machine-may-update-its-own-beliefs-upon-encountering-counterevidence"><span class="section_number">11.5</span><span class="section_title">&lt;2018-12-28&gt; Exception inference, machine doxastic logic, how a machine may update its own beliefs upon encountering counterevidence</span></h3>
<p>Suppose that the machine believes this:</p>
<pre class="example"><code>bird(x) -&gt; fly(x)
</code></pre>
<p>Suppose that it fully trusts us. Then we tell it this:</p>
<pre class="example"><code>bird(penguin)
NOT fly(penguin)
</code></pre>
<p>The machine should infer:</p>
<pre class="example"><code>THUS there_is_something_i_did_not_know_about(penguin)
</code></pre>
<p>A human reasons similarly: &quot;If every bird flies, and penguin is a bird, but penguin doesn't fly, then there is something I didn't know about penguin.&quot; In this case, the thing we &quot;didn't know&quot; is the &quot;flightless&quot; predicate.</p>
<p>We can formalize that reasoning into this algorithm:</p>
<ol>
<li>Suppose that the knowledge base contains rule <span class="math inline">\(R : a(X) \to b(X)\)</span>.</li>
<li>The machine encounters <span class="math inline">\(X\)</span> such that <span class="math inline">\(a(X) \wedge \neg b(X)\)</span>.</li>
<li>The machine creates a fresh predicate <span class="math inline">\(E\)</span> that did not already exist in the knowledge base.</li>
<li>The machine changes rule <span class="math inline">\(R\)</span> to <span class="math inline">\(R&#39; : a(X) \wedge E(X) \to b(X)\)</span>.</li>
</ol>
<p>This is learning. This relates logic and approximation theory. The formula <span class="math inline">\(p \wedge q\)</span> <em>approximates</em> <span class="math inline">\(p \wedge q \wedge r\)</span>. The approximation error is 1 clause.</p>
<p>Weakness: this assumes that all existing beliefs are correct. A wrong belief stays there forever.</p>
<h2 id="pain"><span class="section_number">12</span><span class="section_title">Pain</span></h2>
<p>Pain is a sensory input <em>spike</em>, or dangerously high sensory input. Pain is sensory input level saturation (clipping). Example: extremely bright light, loud noises, pungent smell or taste, extreme heat or cold, abrupt change of velocity when hitting something after falling, what else.</p>
<p>Sensory saturation signals danger. Sensory saturation signals that something is outside the normal operating range.</p>
<h2 id="ethics"><span class="section_number">13</span><span class="section_title">Ethics?</span></h2>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">13.1</span><span class="section_title"><a href="#post-ai-ethical-concerns">&lt;2018-12-28&gt; Post-AI ethical concerns</a></span><span class="word_count">(85w~1m)</span></li>
<li><span class="section_number">13.2</span><span class="section_title"><a href="#chinas-misunderstanding-of-confucianism-implies-that-china-will-use-ai-to-oppress-dissidents-to-maintain-social-order.-should-we-be-concerned">&lt;2018-12-28&gt; China's misunderstanding of Confucianism implies that China will use AI to oppress dissidents to maintain social order. Should we be concerned?</a></span><span class="word_count">(208w~2m)</span></li>
<li><span class="section_number">13.3</span><span class="section_title"><a href="#antinatalism-implies-that-creating-a-sentient-machine-is-immoral">&lt;2018-12-28&gt; Antinatalism implies that creating a sentient machine is immoral</a></span><span class="word_count">(39w~1m)</span></li>
</ul>
</div>
<h3 id="post-ai-ethical-concerns"><span class="section_number">13.1</span><span class="section_title">&lt;2018-12-28&gt; Post-AI ethical concerns</span></h3>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">13.1.1</span><span class="section_title"><a href="#some-ai-ethics-questions">Some AI ethics questions</a></span><span class="word_count">(56w~1m)</span></li>
<li><span class="section_number">13.1.2</span><span class="section_title"><a href="#there-are-only-two-possible-worlds-after-ai">There are only two possible worlds after AI</a></span><span class="word_count">(27w~1m)</span></li>
</ul>
</div>
<h4 id="some-ai-ethics-questions"><span class="section_number">13.1.1</span><span class="section_title">Some AI ethics questions</span></h4>
<ul>
<li>What is the problem with Asimov's three laws of robotics?</li>
<li>Will the rich monopolize AI?</li>
<li>What should we do if everything is free? What should we do if we don't have to work to eat?</li>
</ul>
<p>Who should a machine trust when there is a conflict of belief?</p>
<p>Trust is discussed in <a href="social.html">file:social.html</a>. Perhaps it should be refactored.</p>
<h4 id="there-are-only-two-possible-worlds-after-ai"><span class="section_number">13.1.2</span><span class="section_title">There are only two possible worlds after AI</span></h4>
<p>The optimistic case: Machine does all work. Food is free.</p>
<p>The pessimistic case: Some elites use AI to oppress everyone else.</p>
<h3 id="chinas-misunderstanding-of-confucianism-implies-that-china-will-use-ai-to-oppress-dissidents-to-maintain-social-order.-should-we-be-concerned"><span class="section_number">13.2</span><span class="section_title">&lt;2018-12-28&gt; China's misunderstanding of Confucianism implies that China will use AI to oppress dissidents to maintain social order. Should we be concerned?</span></h3>
<p>By &quot;China&quot;, I mean the Chinese government.</p>
<p>We all, including China itself, misunderstand Confucius.<a href="#fn36" class="footnote-ref" id="fnref36"><sup>36</sup></a></p>
<p>China has always prioritized communal harmony over individual liberty. This is because it misunderstands Confucianism<a href="#fn37" class="footnote-ref" id="fnref37"><sup>37</sup></a>. China will do everything to maintain social order, even if it means mass-surveiling people<a href="#fn38" class="footnote-ref" id="fnref38"><sup>38</sup></a><a href="#fn39" class="footnote-ref" id="fnref39"><sup>39</sup></a> and oppressing dissidents<a href="#fn40" class="footnote-ref" id="fnref40"><sup>40</sup></a>.</p>
<p>The liberal West sees all oppression as evil, but China sees some oppression as necessary for social order. Most international media subscribe to liberal Western ideology. We are observing the same reality from different ideological lenses.</p>
<p>&quot;Confucian values are regarded as incompatible with liberal democracy and are considered to impede democratization.&quot;<a href="#fn41" class="footnote-ref" id="fnref41"><sup>41</sup></a></p>
<p>Every state on Earth oppress some groups to some degrees for some reasons. Nazi Germany, the USSR, Russia, China, the USA, Australia, Denmark, Arabic countries, Islamic countries, you name it. All of them oppress some people.</p>
<p>China is already using AI to oppress dissidents, no later than 2010. In 2018 it &quot;is working to combine its 170+ million security cameras with artificial intelligence and facial recognition technology to create a vast surveillance state&quot;.<a href="#fn42" class="footnote-ref" id="fnref42"><sup>42</sup></a> It is only a matter of time before it perfected that. Should we be concerned?</p>
<p>Is it impossible to maintain social order without government?</p>
<h3 id="antinatalism-implies-that-creating-a-sentient-machine-is-immoral"><span class="section_number">13.3</span><span class="section_title">&lt;2018-12-28&gt; Antinatalism implies that creating a sentient machine is immoral</span></h3>
<p>It is immoral to force a sentient being to exist.</p>
<p>Humans are smart enough to arrive at antinatalism, but they still fuck and have babies. Nobody seems to give a fuck.</p>
<h2 id="literature-study"><span class="section_number">14</span><span class="section_title">Literature study?</span></h2>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">14.1</span><span class="section_title"><a href="#what-publications-may-interest-us">What publications may interest us?</a></span><span class="word_count">(246w~2m)</span></li>
<li><span class="section_number">14.2</span><span class="section_title"><a href="#what-conferences-may-interest-us">What conferences may interest us?</a></span><span class="word_count">(25w~1m)</span></li>
<li><span class="section_number">14.3</span><span class="section_title"><a href="#what-datasets-may-interest-us">What datasets may interest us?</a></span><span class="word_count">(18w~1m)</span></li>
<li><span class="section_number">14.4</span><span class="section_title"><a href="#who-may-have-interests-related-to-mine">Who may have interests related to mine?</a></span><span class="word_count">(261w~2m)</span></li>
<li><span class="section_number">14.5</span><span class="section_title"><a href="#what-are-the-trends-in-ai">What are the trends in AI?</a></span><span class="word_count">(46w~1m)</span></li>
<li><span class="section_number">14.6</span><span class="section_title"><a href="#how-can-i-become-an-ai-researcher">How can I become an AI researcher?</a></span><span class="word_count">(78w~1m)</span></li>
<li><span class="section_number">14.7</span><span class="section_title"><a href="#statistics">Statistics?</a></span><span class="word_count">(14w~1m)</span></li>
</ul>
</div>
<h3 id="what-publications-may-interest-us"><span class="section_number">14.1</span><span class="section_title">What publications may interest us?</span></h3>
<p>Recency is important. The study of AI moves quickly.</p>
<p>The 2018 book <span class="citation" data-cites="mohri2018foundations">[<a href="#ref-mohri2018foundations">35</a>]</span>.</p>
<p>The 2015 book <span class="citation" data-cites="dietterich2015computational">[<a href="#ref-dietterich2015computational">12</a>]</span> does what? Is that a book, or is that a Google Scholar entry error?</p>
<p>The 2016 book <span class="citation" data-cites="russell2016artificial">[<a href="#ref-russell2016artificial">44</a>]</span> is the updated version of the classic undergraduate textbook.</p>
<p>The 1994 book Kearns and Vazirani introduction<span class="citation" data-cites="kearns1994introduction">[<a href="#ref-kearns1994introduction">26</a>]</span>. The 2007 book <span class="citation" data-cites="cucker2007learning">[<a href="#ref-cucker2007learning">10</a>]</span><a href="#fn43" class="footnote-ref" id="fnref43"><sup>43</sup></a> justifies machine learning with approximation theory? It seems to be very relevant to what I'm trying to do?</p>
<p>1984 paper Valiant PAC learning<span class="citation" data-cites="valiant1984theory">[<a href="#ref-valiant1984theory">57</a>]</span></p>
<p>Heavy math?</p>
<p>Approximation theory and practice<span class="citation" data-cites="ApproxThePrac">[<a href="#ref-ApproxThePrac">56</a>]</span></p>
<p>The 1997 monograph Best linear approximation<span class="citation" data-cites="khavinson1997best">[<a href="#ref-khavinson1997best">27</a>]</span></p>
<p>The AlexNet paper<a href="#fn44" class="footnote-ref" id="fnref44"><sup>44</sup></a></p>
<p>Skimming list? Delete?</p>
<ul>
<li>2016 article &quot;Deep vs. shallow networks: An approximation theory perspective&quot; <a href="https://arxiv.org/abs/1608.03287">pdf available</a></li>
<li>1998 book &quot;A Short Course on Approximation Theory&quot; by N. L. Carothers (<a href="http://fourier.math.uoc.gr/~mk/approx1011/carothers.pdf">pdf</a>)</li>
<li>2017 lecture notes &quot;Lectures on multivariate polynomial approximation&quot; (<a href="http://www.math.unipd.it/~demarchi/MultInterp/LectureNotesMI.pdf">pdf</a>)</li>
<li><a href="http://pages.cs.wisc.edu/~jerryzhu/cs731.html">http://pages.cs.wisc.edu/~jerryzhu/cs731.html</a></li>
<li>Very likely
<ul>
<li>2015, slides, &quot;Best polynomial approximation: multidimensional case&quot;, <a href="https://carma.newcastle.edu.au/meetings/spcom/talks/Sukhorukova-SPCOM_2015.pdf">pdf</a></li>
<li><a href="https://en.wikipedia.org/wiki/Bernstein_polynomial#Approximating_continuous_functions">https://en.wikipedia.org/wiki/Bernstein_polynomial#Approximating_continuous_functions</a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Pointwise_convergence">https://en.wikipedia.org/wiki/Pointwise_convergence</a></li>
<li><a href="https://en.wikipedia.org/wiki/Uniform_convergence">https://en.wikipedia.org/wiki/Uniform_convergence</a></li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Approximation">https://en.wikipedia.org/wiki/Approximation</a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Approximation_theory">https://en.wikipedia.org/wiki/Approximation_theory</a>
<ul>
<li>is a branch of <a href="https://en.wikipedia.org/wiki/Functional_analysis">https://en.wikipedia.org/wiki/Functional_analysis</a></li>
<li><a href="https://en.wikipedia.org/wiki/Approximation_theory#Chebyshev_approximation">https://en.wikipedia.org/wiki/Approximation_theory#Chebyshev_approximation</a></li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Approximate_computing">https://en.wikipedia.org/wiki/Approximate_computing</a>
<ul>
<li>example: <a href="https://en.wikipedia.org/wiki/Artificial_neural_network">https://en.wikipedia.org/wiki/Artificial_neural_network</a></li>
</ul></li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Telescoping_series">https://en.wikipedia.org/wiki/Telescoping_series</a></li>
<li>2018 book &quot;Recent Advances in Constructive Approximation Theory&quot; <a href="https://www.springer.com/us/book/9783319921648">paywall</a></li>
</ul></li>
<li>Likely
<ul>
<li>2018, slides, &quot;Deep Learning: Approximation of Functions by Composition&quot;, <a href="http://helper.ipam.ucla.edu/publications/dlt2018/dlt2018_14936.pdf">pdf</a>
<ul>
<li>classical approximation vs deep learning</li>
</ul></li>
<li>2013, short survey article draft, &quot;Multivariate approximation&quot;, <a href="http://num.math.uni-goettingen.de/schaback/research/papers/MultApp_01.pdf">pdf</a></li>
<li>1995, short introduction, &quot;Multivariate Interpolation and Approximation by Translates of a Basis Function&quot;, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.45.2194&amp;rep=rep1&amp;type=pdf">pdf</a></li>
<li>1989, article, &quot;A Theory of Networks for Approximation and Learning&quot;, <a href="http://www.dtic.mil/docs/citations/ADA212359">pdf available</a>
<ul>
<li>What is the summary, especially about learning and approximation theory?</li>
</ul></li>
</ul></li>
</ul>
<p>What are some expository works in AI?</p>
<ul>
<li><a href="https://www.sciencedirect.com/science/article/pii/S1574013717300606">The evolution of sentiment analysis—A review of research topics, venues, and top cited papers</a></li>
</ul>
<p>Surveys, reviews, positions, and expositions?</p>
<ul>
<li>Google query: most recent mathematical ai book</li>
<li><a href="http://eliassi.org/COLTSurveyArticle.pdf">http://eliassi.org/COLTSurveyArticle.pdf</a></li>
<li><a href="https://en.wikipedia.org/wiki/Computational_learning_theory#Surveys">WP: COLT surveys</a></li>
<li><a href="http://www.cs.ox.ac.uk/people/varun.kanade/teaching/CLT-HT2018/lectures/">COLT lecture 2018</a></li>
<li>Book: &quot;An Introduction to Computational Learning Theory&quot; by Kearns and Vazirani</li>
<li><a href="https://mitpress.mit.edu/books/introduction-computational-learning-theory">https://mitpress.mit.edu/books/introduction-computational-learning-theory</a></li>
</ul>
<p>For AI history, Pamela McCorduck's &quot;Machines who think&quot;. Also Wikipedia<a href="#fn45" class="footnote-ref" id="fnref45"><sup>45</sup></a><a href="#fn46" class="footnote-ref" id="fnref46"><sup>46</sup></a><a href="#fn47" class="footnote-ref" id="fnref47"><sup>47</sup></a>.</p>
<h3 id="what-conferences-may-interest-us"><span class="section_number">14.2</span><span class="section_title">What conferences may interest us?</span></h3>
<p>&quot;Approximation Theory and Machine Learning&quot; (Purdue University; September 29 - 30, 2018).<a href="#fn48" class="footnote-ref" id="fnref48"><sup>48</sup></a></p>
<p>NIPS conference looks foundational from its proceedings<a href="#fn49" class="footnote-ref" id="fnref49"><sup>49</sup></a>.</p>
<p>IJCAI seems foundational <a href="https://www.ijcai.org/proceedings/2018/">https://www.ijcai.org/proceedings/2018/</a></p>
<h3 id="what-datasets-may-interest-us"><span class="section_number">14.3</span><span class="section_title">What datasets may interest us?</span></h3>
<p>ImageNet images of almost everything<a href="#fn50" class="footnote-ref" id="fnref50"><sup>50</sup></a></p>
<p>MNIST handwriting</p>
<p>There must already be a website that collects datasets.</p>
<h3 id="who-may-have-interests-related-to-mine"><span class="section_number">14.4</span><span class="section_title">Who may have interests related to mine?</span></h3>
<p>The authors of <span class="citation" data-cites="cucker2007learning">[<a href="#ref-cucker2007learning">10</a>]</span>: Ding-Xuan ZHOU &quot;research interests include learning theory, wavelet analysis and approximation theory&quot;.<a href="#fn51" class="footnote-ref" id="fnref51"><sup>51</sup></a></p>
<p>The authors of <span class="citation" data-cites="xu2009optimal">[<a href="#ref-xu2009optimal">62</a>]</span>. Linli Xu<a href="#fn52" class="footnote-ref" id="fnref52"><sup>52</sup></a>, Martha White<a href="#fn53" class="footnote-ref" id="fnref53"><sup>53</sup></a>, Dale Schuurmans<a href="#fn54" class="footnote-ref" id="fnref54"><sup>54</sup></a>.</p>
<p>The people attending the &quot;Approximation Theory and Machine Learning&quot; conference.</p>
<p>Who else? Who are AI/ML researchers, what do they focus on, and what are they doing?</p>
<p><a href="https://en.wikipedia.org/wiki/Portal:Artificial_intelligence">WP AI Portal</a> lists several leading AI researchers.</p>
<p>Does Geoffrey Hinton specialize in image recognition?</p>
<p>Who are the researchers?</p>
<ul>
<li>See also <a href="https://www.quora.com/Who-is-leading-in-AI-research-among-big-players-like-IBM-Google-Facebook-Apple-and-Microsoft">Quora: Who is leading in AI research among big players like IBM, Google, Facebook, Apple, and Microsoft?</a>
<ul>
<li>Google Brain, OpenAI, FAIR (Facebook AI Research), Microsoft Research, IBM Research</li>
</ul></li>
<li>Geoffrey Hinton, <a href="http://www.cs.toronto.edu/~hinton/">UToronto page</a>, <a href="https://www.reddit.com/r/MachineLearning/comments/2lmo0l/ama_geoffrey_hinton/">Reddit AMA</a>, <a href="https://www.semanticscholar.org/author/Geoffrey-E.-Hinton/1695689">Semantic Scholar influence graph</a>
<ul>
<li>He is trying to find out how the brain works.</li>
<li>The idea: If a learning algorithm works on machines, then it might have something to do with how brains work.</li>
<li>More interested in physical explanation of how the brain works. Physics first, math second, although his math is OK.</li>
</ul></li>
<li>Yann LeCun</li>
<li>Jürgen Schmidhuber</li>
<li>Pedro Domingos</li>
<li>Demis Hassabis
<ul>
<li>What is his focus?</li>
</ul></li>
<li>Pamela McCorduck, AI historian
<ul>
<li>2004 anniversary edition of her 1979 book <a href="http://www.pamelamc.com/html/machines_who_think.html">&quot;Machines who think&quot;</a></li>
</ul></li>
<li>Who else? There are lots of people.</li>
</ul>
<p>How is <a href="https://homes.cs.washington.edu/~pedrod/">Pedro Domingos</a>'s progress of finding the master algorithm unifying the five tribes?</p>
<ul>
<li>Markov logic network unifies probabilists and logicians.
<ul>
<li>How about the other three tribes?</li>
</ul></li>
<li>Hume's question: How do we justify generalization? Why does generalization work?
<ul>
<li>Does Wolpert answer that in &quot;no free lunch theorem&quot;?
<ul>
<li><a href="https://en.wikipedia.org/wiki/No_free_lunch_theorem">Wikipedia: No free lunch theorem</a></li>
</ul></li>
<li>I think induction works because our Universe happens to have a structure that is amenable to induction.
<ul>
<li>If induction doesn't work, and evolution is true, then we would have gone extinct long ago, wouldn't we?
<ul>
<li>What structure is that?</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h3 id="what-are-the-trends-in-ai"><span class="section_number">14.5</span><span class="section_title">What are the trends in AI?</span></h3>
<ul>
<li><a href="https://twitter.com/michael_nielsen/status/983502409325395969">Michael Nielsen's tweet</a>: &quot;I meet lots of people who tell me fatalistically (&amp; often despondently) that it's near impossible to do important work on neural nets today, unless you have huge compute and huge data sets.&quot;
<ul>
<li><a href="https://arxiv.org/abs/1712.00409">Deep Learning Scaling is Predictable, Empirically</a></li>
</ul></li>
</ul>
<h3 id="how-can-i-become-an-ai-researcher"><span class="section_number">14.6</span><span class="section_title">How can I become an AI researcher?</span></h3>
<p>Where do I begin? How do I begin?</p>
<p>Must we pick an area of interest? Speech recognition? Computer vision? Natural language processing? Speech synthesis?</p>
<p>What is the best place to do AI research? Swiss IDSIA? USA? China? Japan? Korea? Australia? New Zealand?</p>
<p>Where are new results announced?</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Portal:Artificial_intelligence">Wikipedia AI Portal</a></li>
<li>Reddit <a href="https://www.reddit.com/r/artificial/">/r/artificial</a></li>
</ul>
<p>Other resources?</p>
<p>Corpuses, datasets, training sets: MNIST handwritten digit dataset.</p>
<p>OpenAI. Let an AI learn in an accurate-enough physical simulation, then move it into the real world.</p>
<p>OpenCog <a href="http://opencog.org/about/">http://opencog.org/about/</a></p>
<h3 id="statistics"><span class="section_number">14.7</span><span class="section_title">Statistics?</span></h3>
<p>Correlation hints causation.</p>
<p>Mathematical-Statistical Learning Theory <a href="https://ocw.mit.edu/courses/mathematics/18-657-mathematics-of-machine-learning-fall-2015/">https://ocw.mit.edu/courses/mathematics/18-657-mathematics-of-machine-learning-fall-2015/</a></p>
<p><a href="https://ocw.mit.edu/courses/mathematics/18-655-mathematical-statistics-spring-2016/">https://ocw.mit.edu/courses/mathematics/18-655-mathematical-statistics-spring-2016/</a></p>
<p>Convex Optimization, Boyd &amp; Vandenberghe <a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf">https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf</a></p>
<p>CMU Statistics</p>
<p><a href="http://www.stat.cmu.edu/~siva/700/main.html">http://www.stat.cmu.edu/~siva/700/main.html</a></p>
<p><a href="http://www.stat.cmu.edu/~larry/=stat705/">http://www.stat.cmu.edu/~larry/=stat705/</a></p>
<p><a href="http://www.stat.cmu.edu/~larry/=sml/">http://www.stat.cmu.edu/~larry/=sml/</a></p>
<p><a href="http://www.cs.cmu.edu/~10702/">http://www.cs.cmu.edu/~10702/</a></p>
<p><a href="https://www.stat.berkeley.edu/~statlearning/publications/index.html">https://www.stat.berkeley.edu/~statlearning/publications/index.html</a></p>
<p><a href="https://github.com/bblais/Statistical-Inference-for-Everyone">https://github.com/bblais/Statistical-Inference-for-Everyone</a></p>
<p><a href="https://en.wikipedia.org/wiki/Checking_whether_a_coin_is_fair">https://en.wikipedia.org/wiki/Checking_whether_a_coin_is_fair</a></p>
<p>Bayesian Updating <a href="http://statweb.stanford.edu/~serban/116/bayes.pdf">http://statweb.stanford.edu/~serban/116/bayes.pdf</a></p>
<p><a href="https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Mathematics">https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Mathematics</a></p>
<h2 id="required-mathematics"><span class="section_number">15</span><span class="section_title">Required mathematics?</span></h2>
<p>Here I try to learn the minimal amount of functional analysis and approximation theory required for learning theory.</p>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">15.1</span><span class="section_title"><a href="#assumed-background-knowledge">Assumed background knowledge</a></span><span class="word_count">(47w~1m)</span></li>
<li><span class="section_number">15.2</span><span class="section_title"><a href="#notations">Notations</a></span><span class="word_count">(123w~1m)</span></li>
<li><span class="section_number">15.3</span><span class="section_title"><a href="#in-what-sequence-should-i-learn">In what sequence should I learn?</a></span><span class="word_count">(157w~1m)</span></li>
<li><span class="section_number">15.4</span><span class="section_title"><a href="#name-this-space"><span class="todo TODO">TODO</span> Name this space</a></span><span class="word_count">(155w~1m)</span></li>
<li><span class="section_number">15.5</span><span class="section_title"><a href="#what">What</a></span><span class="word_count">(119w~1m)</span></li>
<li><span class="section_number">15.6</span><span class="section_title"><a href="#courses">Courses</a></span><span class="word_count">(22w~1m)</span></li>
<li><span class="section_number">15.7</span><span class="section_title"><a href="#subfields-of-approximation-theory">Subfields of approximation theory</a></span><span class="word_count">(24w~1m)</span></li>
<li><span class="section_number">15.8</span><span class="section_title"><a href="#scenarios">Scenarios</a></span><span class="word_count">(31w~1m)</span></li>
<li><span class="section_number">15.9</span><span class="section_title"><a href="#overview">Overview</a></span><span class="word_count">(7w~1m)</span></li>
<li><span class="section_number">15.10</span><span class="section_title"><a href="#what-1">What</a></span><span class="word_count">(42w~1m)</span></li>
<li><span class="section_number">15.11</span><span class="section_title"><a href="#why-are-chebyshev-polynomials-important">Why are Chebyshev polynomials important?</a></span><span class="word_count">(77w~1m)</span></li>
<li><span class="section_number">15.12</span><span class="section_title"><a href="#machine-learning-as-relation-approximation">Machine learning as relation approximation?</a></span><span class="word_count">(34w~1m)</span></li>
<li><span class="section_number">15.13</span><span class="section_title"><a href="#least-square-approximation-of-overdetermined-system-of-linear-equations">Least-square approximation of overdetermined system of linear equations?</a></span><span class="word_count">(61w~1m)</span></li>
<li><span class="section_number">15.14</span><span class="section_title"><a href="#approximation-schemes">Approximation schemes?</a></span><span class="word_count">(2w~1m)</span></li>
<li><span class="section_number">15.15</span><span class="section_title"><a href="#how-do-we-approximate-a-function">How do we approximate a function?</a></span><span class="word_count">(120w~1m)</span></li>
<li><span class="section_number">15.16</span><span class="section_title"><a href="#why-do-we-approximate">Why do we approximate?</a></span><span class="word_count">(40w~1m)</span></li>
<li><span class="section_number">15.17</span><span class="section_title"><a href="#approximation-by-truncation">Approximation by truncation</a></span><span class="word_count">(387w~2m)</span></li>
<li><span class="section_number">15.18</span><span class="section_title"><a href="#approximation-vs-estimation">Approximation vs estimation</a></span><span class="word_count">(87w~1m)</span></li>
</ul>
</div>
<h3 id="assumed-background-knowledge"><span class="section_number">15.1</span><span class="section_title">Assumed background knowledge</span></h3>
<p>I assume that the reader is a Bachelor of Computer Science who graduated in 2011. As of 2018, functional analysis does not seem to be in any computer science curriculum<a href="#fn55" class="footnote-ref" id="fnref55"><sup>55</sup></a><a href="#fn56" class="footnote-ref" id="fnref56"><sup>56</sup></a><a href="#fn57" class="footnote-ref" id="fnref57"><sup>57</sup></a>. The closest things to functional analysis in such curriculum seems to be ordinary differential equations.</p>
<h3 id="notations"><span class="section_number">15.2</span><span class="section_title">Notations</span></h3>
<p><span class="math inline">\( \Real \)</span> is the set of all real numbers. If you are a finitist, just think of a set as a predicate: think of <span class="math inline">\(\Real\)</span> as a predicate such that <span class="math inline">\( \Real(x) \)</span> is true iff <span class="math inline">\(x\)</span> is a real number, and then replace the formula <span class="math inline">\( x \in \Real \)</span> with the formula <span class="math inline">\( \Real(x) \)</span> in your mind.</p>
<p><span class="math inline">\( [0,1] \)</span> is the <em>unit interval</em>. It is the set of every real number between 0 and 1, including 0 and 1. Formally, <span class="math inline">\( [0,1] = \{ x ~|~ x \in \Real, 0 \le x \le 1 \} \)</span>.</p>
<p><span class="math inline">\( C(A) \)</span> is the space of every <em>continuous</em> function whose domain is the set <span class="math inline">\(A\)</span> and whose codomain is <span class="math inline">\(\Real\)</span>. Formally, <span class="math inline">\( C(A) = \{ f ~|~ f : A \to \Real \} \)</span>.</p>
<h3 id="in-what-sequence-should-i-learn"><span class="section_number">15.3</span><span class="section_title">In what sequence should I learn?</span></h3>
<p>Here are the easy things. We need to memorize these definitions.</p>
<p>Relation (a domain, a codomain, and a set of pairs). Function (a special kind of relation). Function space.<a href="#fn58" class="footnote-ref" id="fnref58"><sup>58</sup></a> Measure.<a href="#fn59" class="footnote-ref" id="fnref59"><sup>59</sup></a> Distance or metric.<a href="#fn60" class="footnote-ref" id="fnref60"><sup>60</sup></a> Norm. Inner product. Do not confuse measure with metric.</p>
<p>Here are some rather hard things that need some thinking.</p>
<p>Should we think of a matrix as a rectangle containing numbers or as a <em>linear function</em>?</p>
<p>A real-valued function can be seen as a vector.<a href="#fn61" class="footnote-ref" id="fnref61"><sup>61</sup></a> &quot;In modern introductory texts to functional analysis, the subject is seen as the study of vector spaces endowed with a topology&quot;<a href="#fn62" class="footnote-ref" id="fnref62"><sup>62</sup></a>. Why do we adopt this view?</p>
<p>These slides<a href="#fn63" class="footnote-ref" id="fnref63"><sup>63</sup></a> (slide 20: Lagrange multipliers are common.)</p>
<p>It would be nice if this Wikipedia article<a href="#fn64" class="footnote-ref" id="fnref64"><sup>64</sup></a> relates those opaquely-named function spaces instead of just dumbly listing them.</p>
<p>Do we need to know these?</p>
<p>Functional analysis.<a href="#fn65" class="footnote-ref" id="fnref65"><sup>65</sup></a> Hilbert spaces. Banach spaces. Compact spaces. Continuity. Smoothness. Differentiability.</p>
<p>Reproducing kernel Hilbert space<a href="#fn66" class="footnote-ref" id="fnref66"><sup>66</sup></a> is an application of functional analysis to machine learning.<a href="#fn67" class="footnote-ref" id="fnref67"><sup>67</sup></a></p>
<h3 id="name-this-space"><span class="section_number">15.4</span><span class="section_title"><span class="todo TODO">TODO</span> Name this space</span></h3>
<p>Find the name of the space of every function from unit hypercube to unit interval. Find the name of the space <span class="math inline">\( \{ f ~|~ f : [0,1]^n \to [0,1] \} \)</span>. I guess these keywords: embedding, projection. I guess these areas: functional analysis, approximation theory, topology.</p>
<p>Cybenko 1989 <span class="citation" data-cites="cybenko1989approximation">[<a href="#ref-cybenko1989approximation">11</a>]</span> uses the notation <span class="math inline">\(C(I_n)\)</span> to mean the space of every continuous function from <span class="math inline">\([0,1]^n\)</span> to .<a href="#fn68" class="footnote-ref" id="fnref68"><sup>68</sup></a> He refers to <span class="citation" data-cites="rudin1973functional">[<a href="#ref-rudin1973functional">43</a>]</span> for the notations.</p>
<p>From <span class="citation" data-cites="cybenko1989approximation">[<a href="#ref-cybenko1989approximation">11</a>]</span>:</p>
<ul>
<li>&quot;a fundamental result in digital signal processing is the fact that digital filters made from unit delays and constant multipliers can approximate any continuous transfer function arbitrarily well.&quot;</li>
<li>&quot;The main result of this paper is a demonstration of the fact that sums of the form (1) are dense in the space of continuous functions on the unit cube if <span class="math inline">\(\sigma\)</span> is any continuous sigmoidal function.&quot;</li>
<li>&quot;In a well-known resolution of Hilbert's 13th problem, Kolmogorov showed&quot; the Kolmogorov representation theorem.<a href="#fn69" class="footnote-ref" id="fnref69"><sup>69</sup></a></li>
</ul>
<p>Best linear approximation<span class="citation" data-cites="khavinson1997best">[<a href="#ref-khavinson1997best">27</a>]</span>?</p>
<p><a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem">universal approximation theorem</a></p>
<h3 id="what"><span class="section_number">15.5</span><span class="section_title">What</span></h3>
<p>The phrase &quot;x <em>approximates</em> y&quot; means &quot;x is <em>close</em> to y&quot;, which implies distance, which implies metric space.</p>
<p>How close is the approximation? Suppose that the function <span class="math inline">\(g\)</span> approximates the function <span class="math inline">\(f\)</span> in interval <span class="math inline">\(I\)</span>. Then:</p>
<ul>
<li>The &quot;approximation error at <span class="math inline">\(x\)</span>&quot; is <span class="math inline">\(g(x) - f(x)\)</span>.</li>
<li>The &quot;maximum absolute error&quot; is <span class="math inline">\(\max_{x \in I} \abs{g(x) - f(x)}\)</span>.</li>
</ul>
<p>How do we measure the distance between two <span class="math inline">\(\Real \to \Real\)</span> functions <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span>? There are several ways. Which should we use?</p>
<ul>
<li>The maximum norm, in interval <span class="math inline">\(I\)</span> is <span class="math inline">\(\max_{x \in I} \abs{f(x) - g(x)}\)</span>. This norm is also called uniform norm, supremum norm, Chebyshev norm, infinity norm, norm-infinity, <span class="math inline">\(L_\infty\)</span>-norm. Why is it called &quot;uniform&quot;? <a href="https://en.wikipedia.org/wiki/Uniform_norm">WP:Uniform norm</a>.</li>
<li>What is this norm called? <span class="math inline">\(\int_{x \in I} [f(x)-g(x)]^2 ~ dx\)</span>.</li>
</ul>
<h3 id="courses"><span class="section_number">15.6</span><span class="section_title">Courses</span></h3>
<ul>
<li>2017, <a href="https://www.nada.kth.se/~olofr/Approx/">Approximation Theory, 7.5 ECTS</a></li>
<li>2012, syllabus, Drexel University, Math 680-002 (Approximation Theory), <a href="http://www.math.drexel.edu/~foucart/TeachingFiles/S12/Math680Syl.pdf">pdf</a></li>
<li>2002, <a href="http://math.ucdenver.edu/~aknyazev/teaching/02/5667/">MATH 5667-001: Introduction to Approximation Theory, CU-Denver, Fall 02</a>.</li>
</ul>
<h3 id="subfields-of-approximation-theory"><span class="section_number">15.7</span><span class="section_title">Subfields of approximation theory</span></h3>
<ul>
<li>Classical approximation theory deals with univariate real functions <span class="math inline">\(\Real \to \Real\)</span>.</li>
<li>Multivariate approximation theory deals with multivariate real functions <span class="math inline">\(\Real^m \to \Real^n\)</span>.</li>
</ul>
<h3 id="scenarios"><span class="section_number">15.8</span><span class="section_title">Scenarios</span></h3>
<ul>
<li>Suppose we want to approximate the function <span class="math inline">\(f\)</span>, but we don't know the equation for <span class="math inline">\(f\)</span>; we only have a few input-output samples.
<ul>
<li>Can we approximate <span class="math inline">\(f\)</span>?</li>
<li>How do approximation and curve-fitting relate?</li>
</ul></li>
</ul>
<h3 id="overview"><span class="section_number">15.9</span><span class="section_title">Overview</span></h3>
<ul>
<li>What is a multivariate polynomial?</li>
<li>Commonly conflated concepts</li>
</ul>
<h3 id="what-1"><span class="section_number">15.10</span><span class="section_title">What</span></h3>
<ul>
<li>The <em>uniform norm</em> is …</li>
<li>Best approximation is …</li>
<li>Uniform approximation is best approximation in uniform norm.</li>
<li><a href="https://en.wikipedia.org/wiki/Approximation_theory#Remez&#39;s_algorithm">https://en.wikipedia.org/wiki/Approximation_theory#Remez's_algorithm</a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Remez_algorithm">https://en.wikipedia.org/wiki/Remez_algorithm</a>
<ul>
<li>Inputs: a function, and an interval.</li>
<li>Output: an optimal polynomial approximating the input function in the input interval.</li>
</ul></li>
</ul></li>
<li>What are Bernstein polynomials? What question does the Weierstrass approximation theorem answer?
<ul>
<li><a href="http://www4.ncsu.edu/~mtchu/Teaching/Lectures/MA530/chapter7.pdf">http://www4.ncsu.edu/~mtchu/Teaching/Lectures/MA530/chapter7.pdf</a></li>
</ul></li>
</ul>
<h3 id="why-are-chebyshev-polynomials-important"><span class="section_number">15.11</span><span class="section_title">Why are Chebyshev polynomials important?</span></h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Chebyshev_polynomials">WP:Chebyshev polynomials</a>
<ul>
<li>Why is it important? How does it relate to best approximation?
<ul>
<li>&quot;Chebyshev polynomials are important in approximation theory because the roots of the Chebyshev polynomials of the first kind, which are also called Chebyshev nodes, are used as nodes in polynomial interpolation. The resulting interpolation polynomial minimizes the problem of Runge's phenomenon and provides an approximation that is close to the polynomial of best approximation to a continuous function under the maximum norm.&quot;</li>
</ul></li>
</ul></li>
</ul>
<h3 id="machine-learning-as-relation-approximation"><span class="section_number">15.12</span><span class="section_title">Machine learning as relation approximation?</span></h3>
<ul>
<li>Machine learning, statistical modelling, function approximation, and curve fitting are related.</li>
<li>Generalize function approximation to relation approximation.</li>
<li>A function can be stated as a relation.</li>
<li>A relation can be stated as a function.</li>
</ul>
<h3 id="least-square-approximation-of-overdetermined-system-of-linear-equations"><span class="section_number">15.13</span><span class="section_title">Least-square approximation of overdetermined system of linear equations?</span></h3>
<ul>
<li>Consider the least-square solution to an overdetermined system of linear equations. Is such solution a kind of approximation?
<ul>
<li>There is no exact solution to begin with?</li>
<li>Why is it called &quot;least-squares <em>approximation</em>&quot;?</li>
<li>How can we approximate something that does not exist?
<ul>
<li>1.2 approximates 1.23. Both 1.2 and 1.23 exist.</li>
<li>Contrarily, there is no X such that AX = B.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="approximation-schemes"><span class="section_number">15.14</span><span class="section_title">Approximation schemes?</span></h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Polynomial-time_approximation_scheme">https://en.wikipedia.org/wiki/Polynomial-time_approximation_scheme</a></li>
</ul>
<h3 id="how-do-we-approximate-a-function"><span class="section_number">15.15</span><span class="section_title">How do we approximate a function?</span></h3>
<p>Is it even possible to approximate arbitrary functions?</p>
<ul>
<li>If the function is analytic, we can truncate its Taylor series.
<ul>
<li>Commonly-used differentiable functions are analytic.</li>
</ul></li>
<li>Chebyshev polynomials?</li>
<li>If we have an approximation scheme, we may be able to improve it.
<ul>
<li><a href="https://en.wikipedia.org/wiki/Series_acceleration">https://en.wikipedia.org/wiki/Series_acceleration</a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Aitken%27s_delta-squared_process">https://en.wikipedia.org/wiki/Aitken%27s_delta-squared_process</a></li>
</ul></li>
</ul></li>
<li>google search: machine learning approximation theory
<ul>
<li><a href="https://math.stackexchange.com/questions/2680158/approximation-theory-for-deep-learning-models-where-to-start">Approximation Theory for Deep Learning Models: Where to Start? - Mathematics Stack Exchange</a></li>
<li><a href="http://www.vision.jhu.edu/tutorials/ICCV15-Tutorial-Math-Deep-Learning-Intro-Rene-Joan.pdf">http://www.vision.jhu.edu/tutorials/ICCV15-Tutorial-Math-Deep-Learning-Intro-Rene-Joan.pdf</a></li>
<li>2017, slides, &quot;From approximation theory to machine learning: New perspectives in the theory of function spaces and their applications&quot;, <a href="http://npfsa2017.uni-jena.de/l_notes/vybiral.pdf">pdf</a></li>
<li>2018, article, &quot;Approximation theory, Numerical Analysis and Deep Learning&quot;, <a href="http://at.yorku.ca/c/b/p/g/30.htm">abstract</a>
<ul>
<li>&quot;the problem of numerically solving a large class of (high-dimensional) PDEs (such as linear Black-Scholes or diffusion equations) can be cast into a classical supervised learning problem which can then be solved by deep learning methods&quot;</li>
</ul></li>
</ul></li>
</ul>
<h3 id="why-do-we-approximate"><span class="section_number">15.16</span><span class="section_title">Why do we approximate?</span></h3>
<ul>
<li>Because it is practically inevitable.
<ul>
<li>Fundamental reason: Because computers are finite.</li>
<li>Practical reason: Trade-off between computation time and precision.
<ul>
<li>The more error we can afford, the faster we can run.
<ul>
<li>May be related: 2013 monograph &quot;Faster Algorithms via Approximation Theory&quot; <a href="http://theory.epfl.ch/vishnoi/Publications_files/approx-survey.pdf">pdf</a></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h3 id="approximation-by-truncation"><span class="section_number">15.17</span><span class="section_title">Approximation by truncation</span></h3>
<p>We can approximate a series by <em>truncating</em> it.</p>
<p>Suppose that the series <span class="math inline">\(y = x_0 + x_1 + \ldots\)</span> converges.</p>
<p>Suppose that the sequence <span class="math inline">\(\langle x_0, x_1, \ldots \rangle\)</span> converges to zero.</p>
<p>Pick where to cut. Pick a natural number <span class="math inline">\(n\)</span>.</p>
<p>Then the series <span class="math inline">\(x_0 + \ldots + x_n\)</span> approximates the series <span class="math inline">\(y\)</span>. We cut its tail. We take finitely many summands from the beginning.</p>
<p>Here come examples: Truncate all the series!</p>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">15.17.1</span><span class="section_title"><a href="#power-series-truncation">Power series truncation</a></span><span class="word_count">(258w~2m)</span></li>
<li><span class="section_number">15.17.2</span><span class="section_title"><a href="#iteration-truncation">Iteration truncation</a></span><span class="word_count">(62w~1m)</span></li>
</ul>
</div>
<h4 id="power-series-truncation"><span class="section_number">15.17.1</span><span class="section_title">Power series truncation</span></h4>
<p>Below we truncate a power series.</p>
<p>Decimal truncation: <span class="math inline">\(1.2\)</span> approximates <span class="math inline">\(1.23\)</span>. Remember that a decimal number is a series. For example, the number <span class="math inline">\(1.23\)</span> is the power series <span class="math display">\[ \ldots 01.230 \ldots = \ldots + 0 \cdot 10^1 + 1 \cdot 10^0 + 2 \cdot 10^{-1} + 3 \cdot 10^{-2} + 0 \cdot 10^{-3} + \ldots. \]</span></p>
<p>Polynomial truncation: <span class="math inline">\(1 + x\)</span> approximates <span class="math inline">\(1 + x + x^2\)</span> for <span class="math inline">\(x\)</span> near zero.</p>
<p>Taylor series truncation: <span class="math inline">\(1 + x + \frac{x^2}{2}\)</span> approximates <span class="math inline">\(e^x\)</span> for <span class="math inline">\(x\)</span> near zero. Remember the Taylor series expansion <span class="math inline">\(e^x = \sum_{n \in \Nat} \frac{x^n}{n!}\)</span>.</p>
<p>Below we truncate the ratio of two power series.</p>
<p>Rational truncation: <span class="math inline">\(12/23\)</span> approximates <span class="math inline">\(123/234\)</span>.</p>
<p><a href="https://en.wikipedia.org/wiki/Pad%C3%A9_approximant">WP:Padé approximation</a> is a truncation of a ratio of series.</p>
<p>Fourier series truncation: The <a href="https://en.wikipedia.org/wiki/Fourier_series#Example_1:_a_simple_Fourier_series">Wikipedia example</a> animates how a Fourier series converges to the sawtooth function as more terms are added.</p>
<p>Digression: Is a (complex) Fourier series a power series? Reminder: A Fourier series looks like <span class="math inline">\(\sum_{k=0}^{\infty} c_k e^{ikt}\)</span>.</p>
<p><a href="https://en.wikipedia.org/wiki/Laurent_series">WP:Laurent series</a> truncation?</p>
<ol>
<li><p>Digression: What is an analytic function?</p>
<p>A function is <em>analytic</em> iff it can be represented by power series.</p>
<p>Formally, a function <span class="math inline">\(f\)</span> is <em>analytic</em> iff for every <span class="math inline">\(x \in \dom(f)\)</span>, we can write <span class="math inline">\(f(x)\)</span> as a power series.</p>
<p>See also <a href="https://en.wikipedia.org/wiki/Power_series#Analytic_functions">WP:Definition of &quot;analytic function&quot;</a>.</p>
<p>Taylor series expansion is illustrated in the 2015 slides &quot;Taylor Series: Expansions, Approximations and Error&quot; (<a href="https://relate.cs.illinois.edu/course/cs357-f15/file-version/2978ddd5db9824a374db221c47a33f437f2df1da/media/cs357-slides6.pdf">pdf</a>)</p></li>
<li><p>Digression: What is the relationship between polynomial and power series?</p>
<p>A polynomial is an algebraic expression. It is not a function.</p>
<p>Power series is a kind of infinite polynomial.</p>
<p><a href="https://en.wikipedia.org/wiki/Formal_power_series">WP:Formal power series</a>: &quot;A formal power series is a generalization of a polynomial, where the number of terms is allowed to be infinite.&quot;</p></li>
</ol>
<h4 id="iteration-truncation"><span class="section_number">15.17.2</span><span class="section_title">Iteration truncation</span></h4>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Iterated_function">WP:Iterated function</a></li>
<li><a href="https://en.wikipedia.org/wiki/Iterative_method">WP:Iterative method</a></li>
<li><a href="http://mathworld.wolfram.com/NewtonsIteration.html">Newton's Iteration</a></li>
<li><a href="https://en.wikipedia.org/wiki/Methods_of_computing_square_roots#Babylonian_method">WP:Methods of computing square roots, the Babylonian method</a></li>
<li>An iteration converges to an attractive fixed point.</li>
</ul>
<p>Example: Let <span class="math inline">\(f(x) = x + \frac{1}{x}\)</span>.</p>
<p>Continued fraction truncation: We know that <span class="math display">\[ 1 + \frac{1}{1 + \frac{1}{1 + \ldots}} = \frac{1 + \sqrt{5}}{2} = \Phi. \]</span> We can truncate that continued fraction to approximate <span class="math inline">\(\Phi\)</span>.</p>
<p>Seeing those examples makes me wonder whether all approximations are truncation.</p>
<h3 id="approximation-vs-estimation"><span class="section_number">15.18</span><span class="section_title">Approximation vs estimation</span></h3>
<p>Differences:</p>
<ul>
<li>Approximation is part of analysis. Estimation is part of statistics.</li>
<li>Approximation does not involve sampling. Estimation involves sampling.</li>
<li>Epistemology: Approximation converges to a <em>knowable</em> value. Estimation <em>may</em> converge to a possibly <em>unknowable</em> value (the value exists but it is impractical for us to know what it actually is). Example: we <em>approximate</em> pi, and we <em>estimate</em> the height of all living people on Earth.</li>
<li>Epistemology: Approximation does not guess. Estimation does.</li>
</ul>
<p>Similarities:</p>
<ul>
<li>Both has a notion of &quot;error&quot;. Approximation has error. Estimation has bias and uncertainty.</li>
<li>Both are instances of modeling (simplification).</li>
</ul>
<h2 id="conversational-ai-personal-assistant"><span class="section_number">16</span><span class="section_title">Conversational AI, personal assistant</span></h2>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">16.1</span><span class="section_title"><a href="#user-interface">User interface</a></span><span class="word_count">(40w~1m)</span></li>
</ul>
</div>
<h3 id="user-interface"><span class="section_number">16.1</span><span class="section_title">User interface</span></h3>
<p>There are two windows.</p>
<p>One window is data from you to AI. You type in this window.</p>
<p>One window is data from AI to you. AI prints in this window.</p>
<p>The <em>timing</em> of your keystrokes is also an input to the AI.</p>
<h2 id="crap-delete"><span class="section_number">17</span><span class="section_title">Crap? Delete?</span></h2>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">17.1</span><span class="section_title"><a href="#readings-undigested-information-delete">Readings? Undigested information? Delete?</a></span><span class="word_count">(1497w~8m)</span></li>
<li><span class="section_number">17.2</span><span class="section_title"><a href="#fields-of-study-related-to-intelligence"><span class="todo TODO">TODO</span> Fields of study related to intelligence</a></span><span class="word_count">(721w~4m)</span></li>
<li><span class="section_number">17.3</span><span class="section_title"><a href="#independent-scholar-citizen-science">Independent scholar? Citizen science?</a></span><span class="word_count">(4w~1m)</span></li>
</ul>
</div>
<h3 id="readings-undigested-information-delete"><span class="section_number">17.1</span><span class="section_title">Readings? Undigested information? Delete?</span></h3>
<ul>
<li><p>Read about universal intelligence</p>
<ul>
<li>[Hutter2005Book]</li>
<li><p><a href="http://www.hutter1.net/ai/uaibook.htm">hutter1.net…uaibook.htm</a></p>
<ul>
<li>He formulated the &quot;degree of intelligence&quot; in 2005</li>
<li>(edited) &quot;AIXI […] learns by eliminating Turing machines […] once they become inconsistent with the progressing history.&quot;</li>
</ul></li>
<li><a href="http://www.hutter1.net/ai/suaibook.pdf">Presentation, 393 slides</a></li>
<li><a href="http://users.cecs.anu.edu.au/~ssanner/MLSS2010/Hutter1.pdf">Slides</a>, maybe a draft of the above.</li>
<li>Shane Legg's PhD thesis &quot;Machine super intelligence&quot; [Legg2008]</li>
<li><a href="http://www.vetta.org/documents/universal_intelligence_abstract_ai50.pdf">Legg and Hutter: A formal definition of intelligence for artificial systems</a></li>
<li><p>2005 Negnevitsky AI book <span class="citation" data-cites="negnevitsky2005artificial">[<a href="#ref-negnevitsky2005artificial">38</a>]</span>?</p></li>
</ul></li>
<li><p>COLT</p>
<ul>
<li><p>Should we read this?</p>
<ul>
<li><a href="https://www.quora.com/What-are-the-best-math-books-for-machine-learning">https://www.quora.com/What-are-the-best-math-books-for-machine-learning</a></li>
<li><a href="https://machinelearningwithvick.quora.com/Learning-about-machine-learning">https://machinelearningwithvick.quora.com/Learning-about-machine-learning</a></li>
<li><a href="http://web.archive.org/web/20101102210231/http://measuringmeasures.com/blog/2010/1/15/learning-about-statistical-learning.html">http://web.archive.org/web/20101102210231/http://measuringmeasures.com/blog/2010/1/15/learning-about-statistical-learning.html</a></li>
<li><a href="https://www.quora.com/Which-are-the-best-books-to-get-the-Math-background-for-Machine-Learning">https://www.quora.com/Which-are-the-best-books-to-get-the-Math-background-for-Machine-Learning</a></li>
<li><a href="https://www.quora.com/How-do-I-learn-mathematics-for-machine-learning?share=1">https://www.quora.com/How-do-I-learn-mathematics-for-machine-learning?share=1</a></li>
</ul></li>
<li><p><a href="http://emis.ams.org/journals/TAC/reprints/articles/22/tr22.pdf">http://emis.ams.org/journals/TAC/reprints/articles/22/tr22.pdf</a></p>
<ul>
<li><a href="https://www.quora.com/What-are-some-survey-papers-on-artificial-intelligence-and-deep-learning">https://www.quora.com/What-are-some-survey-papers-on-artificial-intelligence-and-deep-learning</a></li>
<li><a href="http://people.idsia.ch/~juergen/deep-learning-conspiracy.html">http://people.idsia.ch/~juergen/deep-learning-conspiracy.html</a></li>
<li><a href="https://arxiv.org/abs/1404.7828">Jürgen Schmidhuber: &quot;Deep Learning in Neural Networks: An Overview&quot;</a></li>
<li><a href="http://www.ijircce.com/upload/2017/june/107_A%20Survey.pdf">http://www.ijircce.com/upload/2017/june/107_A%20Survey.pdf</a></li>
</ul></li>
</ul></li>
</ul>
<p>Should we read this?</p>
<ul>
<li><a href="http://www.cs.cmu.edu/~16831-f12/notes/F11/16831_lecture15_shorvath.pdf">Boosting: Gradient descent in function space</a></li>
<li><a href="http://alessio.guglielmi.name/res/cos/">Alessio Guglielmi's deep inference</a></li>
<li><a href="https://arxiv.org/abs/1412.1044">Problem theory, Ramón Casares</a></li>
</ul>
<p>University courses? For a course with computer science background, see Stanford University CS221 (Artificial Intelligence: Principles and Techniques) Autumn 2016 <span class="citation" data-cites="LiangCs221">[<a href="#ref-LiangCs221">33</a>]</span>. For a course with mathematics background, see Massachusetts Institute of Technology 18.657 (Mathematics of Machine Learning) Fall 2015 <span class="citation" data-cites="rigollet2015ocw">[<a href="#ref-rigollet2015ocw">42</a>]</span>.</p>
<p>Delete?</p>
<p><a href="https://medium.com/deeper-learning/a-glossary-of-deep-learning-9cb6292e087e">https://medium.com/deeper-learning/a-glossary-of-deep-learning-9cb6292e087e</a></p>
<p>Lecture 2 of CS221: Artificial Intelligence: Principles and Techniques</p>
<p>Neural network <a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem">https://en.wikipedia.org/wiki/Universal_approximation_theorem</a></p>
<p>Create an AI for automatically finding data from the Internet? Machine-aided human summarization (MAHS) Human-aided machine summarization (HAMS) <a href="https://en.wikipedia.org/wiki/Automatic_summarization">https://en.wikipedia.org/wiki/Automatic_summarization</a></p>
<p>Stanford Autumn 2016</p>
<p>Machine Learning, Tom Mitchell, McGraw-Hill <a href="http://cs229.stanford.edu/">http://cs229.stanford.edu/</a></p>
<p><a href="http://www.cs.cmu.edu/~tom/mlbook-chapter-slides.html">http://www.cs.cmu.edu/~tom/mlbook-chapter-slides.html</a></p>
<p>Undergraduate Computer Science point of view <a href="https://www.cs.princeton.edu/courses/archive/fall16/cos402/">https://www.cs.princeton.edu/courses/archive/fall16/cos402/</a></p>
<p>Graduate <a href="http://www.cs.cmu.edu/afs/cs/Web/People/15780/">http://www.cs.cmu.edu/afs/cs/Web/People/15780/</a></p>
<p><a href="http://homes.cs.washington.edu/~pedrod/">http://homes.cs.washington.edu/~pedrod/</a></p>
<p>Metric Learning: A Survey <a href="http://web.cse.ohio-state.edu/~kulis/pubs/ftml_metric_learning.pdf">http://web.cse.ohio-state.edu/~kulis/pubs/ftml_metric_learning.pdf</a></p>
<p>Distance Metric Learning: A Comprehensive Survey <a href="https://www.cs.cmu.edu/~liuy/frame_survey_v2.pdf">https://www.cs.cmu.edu/~liuy/frame_survey_v2.pdf</a></p>
<p>Learning Deep Architectures for AI <a href="http://www.iro.umontreal.ca/~bengioy/papers/ftml_book.pdf">http://www.iro.umontreal.ca/~bengioy/papers/ftml_book.pdf</a></p>
<p><a href="https://en.wikipedia.org/wiki/Similarity_learning">https://en.wikipedia.org/wiki/Similarity_learning</a></p>
<p>Essentials of Machine Learning Algorithms (with Python and R Codes) <a href="https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/">https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/</a></p>
<p><a href="http://www.cs.cmu.edu/">http://www.cs.cmu.edu/</a>~./15381/</p>
<p><a href="http://stanford.edu/~cpiech/cs221/">http://stanford.edu/~cpiech/cs221/</a></p>
<p><a href="http://www.cs.princeton.edu/courses/archive/fall15/cos402/">http://www.cs.princeton.edu/courses/archive/fall15/cos402/</a></p>
<p><a href="https://grid.cs.gsu.edu/~cscyqz/courses/ai/aiLectures.html">https://grid.cs.gsu.edu/~cscyqz/courses/ai/aiLectures.html</a></p>
<p><a href="https://www.cs.utexas.edu/users/novak/cs381kcontents.html">https://www.cs.utexas.edu/users/novak/cs381kcontents.html</a></p>
<p><a href="https://www.cs.utexas.edu/users/novak/cs343index.html">https://www.cs.utexas.edu/users/novak/cs343index.html</a></p>
<p><a href="http://www.cse.unsw.edu.au/~billw/cs9414/notes.html">http://www.cse.unsw.edu.au/~billw/cs9414/notes.html</a></p>
<p>Why deep learning works</p>
<p><a href="http://www.vision.jhu.edu/tutorials/ICCV15-Tutorial-Math-Deep-Learning-Intro-Rene-Joan.pdf">http://www.vision.jhu.edu/tutorials/ICCV15-Tutorial-Math-Deep-Learning-Intro-Rene-Joan.pdf</a></p>
<p><a href="http://www.vision.jhu.edu/tutorials/ICCV15-Tutorial-Math-Deep-Learning.htm">http://www.vision.jhu.edu/tutorials/ICCV15-Tutorial-Math-Deep-Learning.htm</a></p>
<p><a href="https://calculatedcontent.com/2015/03/25/why-does-deep-learning-work/">https://calculatedcontent.com/2015/03/25/why-does-deep-learning-work/</a></p>
<p>Neural Networks, Manifolds, and Topology <a href="http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/">http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/</a></p>
<p>Deep Learning, NLP, and Representations <a href="http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/">http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/</a></p>
<p>Machine Learning A Probabilistic Perspective Kevin P. Murphy Table of Contents <a href="http://www.cs.ubc.ca/~murphyk/MLbook/pml-toc-22may12.pdf">http://www.cs.ubc.ca/~murphyk/MLbook/pml-toc-22may12.pdf</a></p>
<p>The following is a list of free, open source books on machine learning, statistics, data-mining, etc. <a href="https://github.com/josephmisiti/awesome-machine-learning/blob/master/books.md">https://github.com/josephmisiti/awesome-machine-learning/blob/master/books.md</a></p>
<p>Undigested information</p>
<ul>
<li><a href="https://kevinbinz.com/2017/08/13/ml-five-tribes/">kevinbinz.com: Five Tribes of Machine Learning</a>, part of <a href="https://kevinbinz.com/2017/05/09/sequence-machine-learning/">machine learning sequence</a>, some contents from Pedro Domingos's book &quot;The master algorithm&quot;</li>
<li><a href="http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html">Introducing state of the art text classification with universal language models</a></li>
<li><p>Summary of Pedro Domingos's book &quot;The master algorithm&quot;</p>
<ul>
<li>Sparse autoencoders (p. 116).</li>
<li>&quot;A nugget of knowledge so incontestable, so fundamental, that we can build all induction on top of it&quot; (p. 64) in Chapter 9.</li>
<li>Induction is the inverse of deduction, as subtraction is the inverse of addition. (Is this a quote from the book?)</li>
<li>EM (expectation maximization) algorithm (p. 209).</li>
<li>Metalearning (p. 237).</li>
<li>A classifier that classifies by combining the output of subclassifiers.</li>
<li><a href="http://homes.cs.washington.edu/~pedrod/papers/mlj05.pdf">Markov logic network</a> (p. 246) named <a href="Alchemy"><a href="http://alchemy.cs.washington.edu/">http://alchemy.cs.washington.edu/</a></a> (p. 250)</li>
</ul></li>
<li>Harvard University the graduate school of arts and sciences: <a href="http://sitn.hms.harvard.edu/flash/2017/history-artificial-intelligence/">Rockwell Anyoha: History of AI</a></li>
<li><a href="http://jacques.pitrat.pagesperso-orange.fr/">Jacques Pitrat</a> and his CAIA, bootstrapping AI with AI.</li>
<li><a href="http://www.hutter1.net/ai/uaibook.htm">Marcus Hutter book: Universal Artificial Intelligence: Sequential Decisions based on Algorithmic Probability</a> and the <a href="http://www.hutter1.net/ai/suaibook.pdf">slides</a>.</li>
<li><p><a href="http://math.bu.edu/people/mkon/V5Fin.pdf">Mark A. Kon, Louise A. Raphael, Daniel A. Williams: Extending Girosi's approximation estimates for functions in Sobolev spaces via statistical learning theory</a></p>
<ul>
<li>&quot;Girosi [8] established an interesting connection between statistical learning theory (SLT) and approximation theory, showing that SLT methods can be used to prove results of a purely approximation theoretic nature.&quot;</li>
</ul></li>
<li>Speech synthesizer using hidden Markov model? Someone must have done it. Find the paper.</li>
<li>ISIR (International Society for Intelligence Research) human intelligence research <a href="http://www.isironline.org/resources/teaching-pages/">teaching pages</a>.</li>
<li><a href="https://en.wikipedia.org/wiki/Artificial_life">https://en.wikipedia.org/wiki/Artificial_life</a></li>
<li>What is the simplest life form? (2008) <a href="https://www.quora.com/What-is-the-simplest-life-form">https://www.quora.com/What-is-the-simplest-life-form</a></li>
<li><a href="https://stats.stackexchange.com/questions/142906/what-does-pac-learning-theory-mean">https://stats.stackexchange.com/questions/142906/what-does-pac-learning-theory-mean</a></li>
<li><p><a href="https://brenocon.com/blog/2008/12/statistics-vs-machine-learning-fight/">https://brenocon.com/blog/2008/12/statistics-vs-machine-learning-fight/</a></p>
<ul>
<li>YC thread for that <a href="https://news.ycombinator.com/item?id=4927168">https://news.ycombinator.com/item?id=4927168</a></li>
</ul></li>
<li><a href="https://www.quora.com/What-are-the-most-important-foundational-papers-in-artificial-intelligence-machine-learning">Quora: What are the most important, foundational papers in artificial intelligence/machine learning?</a></li>
<li>JAIR (Journal of Artificial Intelligence Research): <a href="https://www.jair.org/index.php/jair/navigationMenu/view/IJCAIJAIR">IJCAI-JAIR awards</a></li>
<li>Schmidhuber, <a href="http://people.idsia.ch/~juergen/fastestuniverse.pdf">The Fastest Way of Computing All Universes</a></li>
<li><p><a href="http://raysolomonoff.com/dartmouth/">Dartmouth AI archives</a></p>
<ul>
<li><a href="http://raysolomonoff.com/publications/indinf56.pdf">Solomonoff, &quot;An inductive inference machine&quot;</a></li>
</ul></li>
<li><p>Shane Legg, Joel Veness: algorithmic intelligence quotient</p>
<ul>
<li><a href="https://github.com/mathemajician/AIQ">https://github.com/mathemajician/AIQ</a></li>
<li>An Approximation of the Universal Intelligence Measure by Shane Legg and Joel Veness, 2011</li>
</ul></li>
<li><a href="https://courses.cs.washington.edu/courses/csep590/06au/projects/history-ai.pdf">History of AI</a>, University of Washington, History of Computing, CSEP 590A</li>
<li><a href="https://en.wikipedia.org/wiki/Timeline_of_artificial_intelligence">WP: Timeline of AI</a></li>
<li><a href="https://www.quantamagazine.org/why-self-taught-artificial-intelligence-has-trouble-with-the-real-world-20180221/">https://www.quantamagazine.org/why-self-taught-artificial-intelligence-has-trouble-with-the-real-world-20180221/</a></li>
<li><a href="http://news.mit.edu/2010/ai-unification">http://news.mit.edu/2010/ai-unification</a></li>
<li><a href="http://airesearch.com/">http://airesearch.com/</a></li>
<li><a href="https://theconversation.com/understanding-the-four-types-of-ai-from-reactive-robots-to-self-aware-beings-67616">https://theconversation.com/understanding-the-four-types-of-ai-from-reactive-robots-to-self-aware-beings-67616</a></li>
<li><a href="https://artificialintelligence.id/">https://artificialintelligence.id/</a></li>
<li><a href="https://www.asianscientist.com/2017/09/academia/indonesia-ai-nvidia-binus-kinetica/">https://www.asianscientist.com/2017/09/academia/indonesia-ai-nvidia-binus-kinetica/</a></li>
<li><a href="https://arxiv.org/abs/1206.5533">Practical recommendations for gradient-based training of deep architectures</a></li>
<li><a href="https://arxiv.org/abs/1604.06737">Entity Embeddings of Categorical Variables</a></li>
<li>Google Colab</li>
<li><a href="https://qz.com/1172431/artificial-intelligence-ai-should-be-raised-like-children-not-computers/">https://qz.com/1172431/artificial-intelligence-ai-should-be-raised-like-children-not-computers/</a></li>
<li><p>RNN, LSTM, GRU</p>
<ul>
<li>RNN is recurrent neural network.</li>
<li>LSTM is a kind of RNN.</li>
<li>GRU is a kind of RNN.</li>
<li><a href="https://jhui.github.io/2017/03/15/RNN-LSTM-GRU/">https://jhui.github.io/2017/03/15/RNN-LSTM-GRU/</a></li>
</ul></li>
<li><a href="http://web.mit.edu/tslvr/www/lessons_two_years.html">http://web.mit.edu/tslvr/www/lessons_two_years.html</a></li>
<li><a href="https://gallery.mailchimp.com/dc3a7ef4d750c0abfc19202a3/files/93e40657-1adb-4891-94ad-c65dda68061f/Ng_MLY01_02.pdf">https://gallery.mailchimp.com/dc3a7ef4d750c0abfc19202a3/files/93e40657-1adb-4891-94ad-c65dda68061f/Ng_MLY01_02.pdf</a></li>
<li><a href="https://www.reddit.com/r/MachineLearning/comments/73n9pm/d_confession_as_an_ai_researcher_seeking_advice/#bottom-comments">https://www.reddit.com/r/MachineLearning/comments/73n9pm/d_confession_as_an_ai_researcher_seeking_advice/#bottom-comments</a></li>
<li><a href="http://www.inf.ed.ac.uk/teaching/courses/mlpr/2017/notes/w6b_netflix_prize.html">netflix prize, part of MLPR class notes</a></li>
<li><p>Scott M. Lundberg, Su-In Lee: A Unified Approach to Interpreting Model Predictions</p>
<ul>
<li><a href="http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf">http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf</a></li>
<li><a href="https://github.com/slundberg/shap">https://github.com/slundberg/shap</a></li>
</ul></li>
<li><a href="https://www.datascience.com/blog/introduction-to-bayesian-inference-learn-data-science-tutorials">datascience.com: Introduction to Bayesian Inference</a></li>
<li><a href="http://www.fc.uaem.mx/~bruno/material/brooks_87_representation.pdf">1987, Intelligence without representation, Rodney A. Brooks</a></li>
<li><a href="http://colah.github.io/posts/2015-08-Backprop/">colah.github.io: Backprop</a></li>
<li>google search &quot;ai theory research&quot;</li>
<li><a href="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.2.4835">2002, PhotoTOC: Automatic Clustering for Browsing Personal Photographs, by John C. Platt, Mary Czerwinski, Brent A. Field</a></li>
<li><p>philosophy of learning</p>
<ul>
<li><a href="http://learning.media.mit.edu/content/publications/EA.Piaget%20_%20Papert.pdf">Piaget's constructivism vs Papert's constructionism</a>, Edith Ackermann</li>
</ul></li>
<li><a href="https://arxiv.org/abs/1508.01084">2015, Deep Convolutional Networks are Hierarchical Kernel Machines</a></li>
<li><a href="https://www.youtube.com/watch?v=F5Z52jl4yHQ">Michio Kaku: Who is right about A.I.: Mark Zuckerberg or Elon Musk?</a></li>
<li><a href="https://stats.stackexchange.com/questions/104385/assigning-meaningful-cluster-name-automatically">Stats SE 104385: text processing: assigning meaningful cluster name automatically</a></li>
<li>The mathematics of deep learning (a website)</li>
<li>Can AI be used to upscale old audio/video recordings? Fix deteriorated pictures, films, documents? Color old pictures, photos, films? &quot;Modernize&quot; past artifacts? Digital restoration of archives?</li>
<li><p>brain-computer interface</p>
<ul>
<li><p>pop science</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=P29EXskk9oU">How Brain Waves Can Control Physical Objects</a></li>
</ul></li>
</ul></li>
<li><p>machine learning</p>
<ul>
<li>confusion matrix</li>
<li><p>algebra of words</p>
<ul>
<li><a href="https://medium.com/@erushton214/a-simple-spell-checker-built-from-word-vectors-9f28452b6f26">https://medium.com/@erushton214/a-simple-spell-checker-built-from-word-vectors-9f28452b6f26</a></li>
</ul></li>
<li><a href="https://www.datasciencecentral.com/profiles/blogs/crisp-dm-a-standard-methodology-to-ensure-a-good-outcome">https://www.datasciencecentral.com/profiles/blogs/crisp-dm-a-standard-methodology-to-ensure-a-good-outcome</a></li>
<li><p><a href="http://www.inference.vc/untitled/">ML beyond Curve Fitting: An Intro to Causal Inference and do-Calculus</a></p></li>
</ul></li>
<li>deepmind wavenet</li>
<li><a href="https://openreview.net/pdf?id=ByldLrqlx">deepcoder: learning to write programs</a></li>
<li><p>Ramblings, opinions, guesses, hypotheses, conjectures, speculations</p>
<ul>
<li>AI is approximation (or constrained optimization?) in Sobolev spaces (or ( L^p() ) spaces?)?</li>
<li>Intelligent agents are only possible if the world they live in is structured. If the laws of physics randomly change over time, then intelligent agents are unlikely.</li>
<li><p>We should merge machine learning, probability, and statistics?</p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Recursive_self_improvement">WP:Recursive self-improvement</a></li>
</ul></li>
<li><p>World = agent + environment. Environment is everything that the agent does not control directly. The body of an agent is part of the environment, not of the agent.</p></li>
</ul></li>
<li><a href="http://dl.acm.org/citation.cfm?id=2567715">Dimension independent similarity computation (DISCO)</a></li>
<li><a href="http://www.jair.org/">Journal of artificial intelligence research</a> (open access)</li>
<li><a href="https://arxiv.org/abs/1802.08195">Adversarial Examples that Fool both Human and Computer Vision</a>, from <a href="https://www.youtube.com/watch?v=AbxPbfODGcs">two minute papers 241</a>.</li>
<li><a href="https://www.semanticscholar.org/paper/Machine-Theory-of-Mind-Rabinowitz-Perbet/4a48d7528bf1f81f48be8a644ffb1bcc08f1b2c5">Machine theory of mind</a></li>
<li>Ilias Diakonikolas, Daniel Kane and Alistair Stewart. Optimal Learning via the Fourier Transform for Sums of Independent Integer Random Variables</li>
<li><a href="https://en.m.wikipedia.org/wiki/List_of_important_publications_in_computer_science#Machine_learning">https://en.m.wikipedia.org/wiki/List_of_important_publications_in_computer_science#Machine_learning</a></li>
<li><a href="https://arxiv.org/abs/1704.07441">Detecting English Writing Styles For Non Native Speakers</a></li>
<li>&quot;Hicklin envisaged that learning resulted from a dynamic equilibrium between information acquisition and loss.&quot; (<a href="https://onlinelibrary.wiley.com/doi/pdf/10.1002/tea.3660210910">Mathematical modeling of learning, Peter F. W. Preece</a>, 1984)</li>
<li>AI research tries to make a system that can optimize a wide variety of goal functions?</li>
<li><a href="https://cs.nyu.edu/~mohri/mlbook/">Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar; book; &quot;Foundations of machine learning&quot;</a></li>
<li><a href="http://bigthink.com/videos/the-top-3-supplements-for-surviving-the-singularity">http://bigthink.com/videos/the-top-3-supplements-for-surviving-the-singularity</a></li>
<li><a href="https://google.github.io/CausalImpact/CausalImpact.html">https://google.github.io/CausalImpact/CausalImpact.html</a></li>
<li><p>intelligence testing</p>
<ul>
<li><p><a href="https://www.youtube.com/watch?v=8YWjSQHfV5U">YT:Jordan Peterson - Example IQ questions and what Career/job fits your IQ</a></p>
<ul>
<li>problem: no job for people with IQ below 87?</li>
<li><a href="https://www.reddit.com/r/JordanPeterson/comments/84qmsj/source_of_83_iq_minimum_for_the_us_military/">R:source for soldier minimum IQ requirement of 85</a></li>
<li><a href="https://en.wikipedia.org/wiki/Fluid_and_crystallized_intelligence">WP:Fluid and crystallized intelligence</a></li>
<li><a href="https://en.wikipedia.org/wiki/Raven%27s_Progressive_Matrices">WP:Raven's progressive matrices</a> is a language-neutral visual test for fluid intelligence?</li>
</ul></li>
</ul></li>
<li><a href="https://www.youtube.com/watch?v=GdTBqBnqhaQ">YT:4 Experiments Where the AI Outsmarted Its Creators | Two Minute Papers #242</a></li>
<li><a href="https://arxiv.org/abs/1509.06569">Tensorizing Neural Networks</a></li>
<li><a href="https://arxiv.org/abs/1502.02367">Gated Feedback Recurrent Neural Networks</a></li>
<li>no information <a href="http://syntience.com/">http://syntience.com/</a></li>
<li><p><a href="https://www.youtube.com/watch?v=b_6-iVz1R0o">The pattern behind self-deception | Michael Shermer</a>: patternicity, agenticity, pattern over-recognition, false positive, false negative</p>
<ul>
<li>&quot;false positive&quot; is a much better name than &quot;type 1 error&quot;</li>
</ul></li>
<li>expected 2018, draft book, &quot;Model-based machine learning&quot;, <a href="http://www.mbmlbook.com/">html</a></li>
<li><p>vision (making machines see)</p>
<ul>
<li>Jim Bednar, <a href="http://homepages.inf.ed.ac.uk/jbednar/demos.html">Orientation Perception Demos</a></li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Bayesian_approaches_to_brain_function">https://en.wikipedia.org/wiki/Bayesian_approaches_to_brain_function</a></li>
<li><p><a href="https://www.youtube.com/watch?v=MvFABFWPBrw">DeepMind Has A Superhuman Level Quake 3 AI Team - YouTube</a></p>
<ul>
<li>Moby Motion's comment: &quot;Really exciting because of the sparse internal rewards and long term planning. A step towards AI agents that are useful in real life.&quot;</li>
</ul></li>
<li><p>2018 AI is like autistic savants. They perform one task exceptionally well, but they are bad at everything else.</p>
<ul>
<li>2018, <a href="https://www.youtube.com/watch?v=eSaShQbUJTQ">DeepMind's AI Takes An IQ Test - YouTube</a></li>
</ul></li>
<li><p>AI</p>
<ul>
<li>2007, article, &quot;Self-taught Learning: Transfer Learning from Unlabeled Data&quot;, <a href="https://cs.stanford.edu/people/ang/papers/icml07-selftaughtlearning.pdf">pdf</a></li>
<li><a href="https://en.wikipedia.org/wiki/Category:Open-source_artificial_intelligence">https://en.wikipedia.org/wiki/Category:Open-source_artificial_intelligence</a></li>
<li><a href="https://en.wikipedia.org/wiki/Commonsense_knowledge_(artificial_intelligence)">https://en.wikipedia.org/wiki/Commonsense_knowledge_(artificial_intelligence)</a></li>
<li>2010, article, <a href="https://news.mit.edu/2010/ai-unification">A grand unified theory of AI - MIT News</a></li>
<li>2016, article, <a href="https://ai100.stanford.edu/2016-report/section-i-what-artificial-intelligence/ai-research-trends">AI Research Trends - One Hundred Year Study on Artificial Intelligence (AI100)</a></li>
<li><p>sequence learning?</p>
<ul>
<li><a href="https://devblogs.nvidia.com/deep-learning-nutshell-sequence-learning/">https://devblogs.nvidia.com/deep-learning-nutshell-sequence-learning/</a></li>
<li><a href="https://en.wikipedia.org/wiki/Sequence_learning">https://en.wikipedia.org/wiki/Sequence_learning</a></li>
</ul></li>
<li><p>AI perception of time?</p></li>
</ul></li>
<li><p><a href="https://www.quora.com/Does-the-human-brain-have-an-internal-language">https://www.quora.com/Does-the-human-brain-have-an-internal-language</a></p>
<ul>
<li>mereological fallacy, confusing the part and the whole</li>
</ul></li>
<li><a href="https://www.quora.com/Is-the-human-brain-analog-or-digital">https://www.quora.com/Is-the-human-brain-analog-or-digital</a> <a href="https://en.wikipedia.org/wiki/Mereological_essentialism">https://en.wikipedia.org/wiki/Mereological_essentialism</a></li>
<li><p>machine learning</p>
<ul>
<li><a href="https://github.com/Avik-Jain/100-Days-Of-ML-Code">Avik-Jain/100-Days-Of-ML-Code: 100 Days of ML Coding</a></li>
</ul></li>
<li><p>Justifying consciousness using evolution?</p>
<ul>
<li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4122207/">The biological function of consciousness</a></li>
<li><a href="https://www.quora.com/How-does-sentience-benefit-survival-and-why-is-it-developed">How does sentience benefit survival and why is it developed? - Quora</a></li>
</ul></li>
<li><a href="https://www.quora.com/How-do-I-publish-artificial-intelligence-research-if-I-am-not-currently-in-academia-or-an-industry-research-setting">https://www.quora.com/How-do-I-publish-artificial-intelligence-research-if-I-am-not-currently-in-academia-or-an-industry-research-setting</a></li>
<li><a href="https://www.quora.com/How-does-life-fight-against-entropy">How does life fight against entropy? - Quora</a></li>
<li><p>Life and entropy</p>
<ul>
<li><a href="https://www.quora.com/How-does-life-fight-against-entropy">How does life fight against entropy? - Quora</a></li>
<li><a href="https://en.wikipedia.org/wiki/Entropy_and_life">WP:Entropy and life</a></li>
</ul></li>
<li><p>Making machine understand human languages</p>
<ul>
<li><a href="https://blogs.microsoft.com/ai/microsoft-creates-ai-can-read-document-answer-questions-well-person/">Microsoft creates AI that can read a document and answer questions about it as well as a person - The AI Blog</a></li>
</ul></li>
<li><a href="https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html">A (Long) Peek into Reinforcement Learning</a></li>
<li><p>Competitions</p>
<ul>
<li>Kaggle: get paid to solve machine learning problems.</li>
</ul></li>
<li>HLearn: a machine learning library for Haskell <span class="citation" data-cites="izbicki2013hlearn">[<a href="#ref-izbicki2013hlearn">24</a>]</span></li>
<li><a href="https://dzone.com/articles/deep-dive-into-machine-learning">Deep Dive Into Machine Learning - DZone AI</a></li>
<li><a href="https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf">https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf</a></li>
<li><a href="https://github.com/keras-team/keras">keras-team/keras: Deep Learning for humans</a></li>
<li><a href="http://cs230.stanford.edu/proj-spring-2018.html">CS230: Deep Learning - Projects</a></li>
<li><a href="http://jonbho.net/2014/09/25/defining-intelligence/">http://jonbho.net/2014/09/25/defining-intelligence/</a></li>
<li><a href="https://github.com/HuwCampbell/grenade">HuwCampbell/grenade: Deep Learning in Haskell</a></li>
<li><p><a href="http://www.randomhacks.net/2007/03/03/smart-classification-with-haskell/">Smart classification using Bayesian monads in Haskell - Random Hacks</a></p></li>
</ul>
<p>Selected threads from /r/artificial?</p>
<ul>
<li><a href="https://www.reddit.com/r/artificial/comments/8begcv/what_are_some_of_the_best_books_on_artificial/">What are some of the best books on AI/ML?</a></li>
<li><a href="https://www.reddit.com/r/artificial/comments/8bzrmd/math_phd_want_to_learn_more_about_ai_what_to_read/">Math PhD. Want to learn more about AI. What to read?</a></li>
</ul>
<p>History questions?</p>
<ul>
<li>Why was Raymond J. Solomonoff <span class="citation" data-cites="SolAlpProb2011 GacsVitanyiSolomonoff">[<a href="#ref-GacsVitanyiSolomonoff">17</a>, <a href="#ref-SolAlpProb2011">50</a>]</span> interested in predicting sequences of bits? What was he interested in? What was he trying to do?</li>
</ul>
<p>Reading list?</p>
<p>Statistical learning</p>
<p>Inverse problem theory <span class="citation" data-cites="tarantola2005inverse">[<a href="#ref-tarantola2005inverse">54</a>]</span></p>
<p>? <span class="citation" data-cites="SepLogicAi">[<a href="#ref-SepLogicAi">55</a>]</span></p>
<p>Wiener cybernetics book? <span class="citation" data-cites="WienerCyber">[<a href="#ref-WienerCyber">60</a>]</span></p>
<p>Semi-supervised learning?</p>
<p>What is rational?</p>
<p>Moravec's paradox</p>
<p>Reading list?</p>
<p>Neural Architecture Search with Reinforcement Learning Barret Zoph, Quoc V. Le <a href="https://arxiv.org/abs/1611.01578">https://arxiv.org/abs/1611.01578</a></p>
<p><a href="http://artint.info/html/ArtInt.html">http://artint.info/html/ArtInt.html</a></p>
<p><a href="https://en.wikipedia.org/wiki/Book:Machine_Learning_%E2%80%93_The_Complete_Guide">https://en.wikipedia.org/wiki/Book:Machine_Learning_%E2%80%93_The_Complete_Guide</a></p>
<p><a href="https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Mathematics/Reference_resources">https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Mathematics/Reference_resources</a></p>
<p>An Automatic Clustering Technique for Optimal Clusters <a href="https://arxiv.org/pdf/1109.1068.pdf">https://arxiv.org/pdf/1109.1068.pdf</a></p>
<p><a href="https://en.wikipedia.org/wiki/State-Action-Reward-State-Action">https://en.wikipedia.org/wiki/State-Action-Reward-State-Action</a></p>
<p><a href="http://blog.minitab.com/blog/adventures-in-statistics-2/understanding-hypothesis-tests:-confidence-intervals-and-confidence-levels">http://blog.minitab.com/blog/adventures-in-statistics-2/understanding-hypothesis-tests:-confidence-intervals-and-confidence-levels</a></p>
<p><a href="http://greenteapress.com/thinkstats2/html/index.html">http://greenteapress.com/thinkstats2/html/index.html</a></p>
<p><a href="https://elitedatascience.com/learn-machine-learning">https://elitedatascience.com/learn-machine-learning</a></p>
<p><a href="http://www.mit.edu/~9.520/fall14/Classes/mtheory.html">http://www.mit.edu/~9.520/fall14/Classes/mtheory.html</a></p>
<p><a href="https://arxiv.org/pdf/1311.4158v5.pdf">https://arxiv.org/pdf/1311.4158v5.pdf</a></p>
<p>Unsupervised learning of invariant representations with low sample complexity: the magic of sensory cortex or a new framework for machine learning?</p>
<p><a href="http://www.stat.yale.edu/Courses/1997-98/101/confint.htm">http://www.stat.yale.edu/Courses/1997-98/101/confint.htm</a></p>
<p><a href="http://www.itl.nist.gov/div898/handbook/prc/section1/prc14.htm">http://www.itl.nist.gov/div898/handbook/prc/section1/prc14.htm</a></p>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">17.1.1</span><span class="section_title"><a href="#machine-learning">Machine learning</a></span><span class="word_count">(97w~1m)</span></li>
<li><span class="section_number">17.1.2</span><span class="section_title"><a href="#popular-science">Popular science</a></span><span class="word_count">(128w~1m)</span></li>
</ul>
</div>
<h4 id="machine-learning"><span class="section_number">17.1.1</span><span class="section_title">Machine learning</span></h4>
<p>Algorithmic Aspects of Machine Learning Matrices <a href="http://people.csail.mit.edu/moitra/docs/bookex.pdf">http://people.csail.mit.edu/moitra/docs/bookex.pdf</a></p>
<p><a href="http://www.deeplearningbook.org/">http://www.deeplearningbook.org/</a></p>
<p>Pedro Domingos: &quot;The Master Algorithm&quot; | Talks at Google - YouTube <a href="https://www.youtube.com/watch?v=B8J4uefCQMc">https://www.youtube.com/watch?v=B8J4uefCQMc</a> slides: <a href="https://www.slideshare.net/SessionsEvents/pedro-domingos-professor-university-of-washington-at-mlconf-atl-91815">https://www.slideshare.net/SessionsEvents/pedro-domingos-professor-university-of-washington-at-mlconf-atl-91815</a> Grand unified theory of machine learning</p>
<p>A Tour of Machine Learning Algorithms <a href="http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/">http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/</a></p>
<p>Asynchronous Methods for Deep Reinforcement Learning <a href="https://arxiv.org/abs/1602.01783">https://arxiv.org/abs/1602.01783</a></p>
<p>Active learning of inverse models with intrinsically motivated goal exploration in robots (2013) <a href="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.278.5254">http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.278.5254</a></p>
<p>One-bit compressed sensing by linear programming (2011) <a href="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.413.5719">http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.413.5719</a></p>
<p>Approximate Clustering without the Approximation <a href="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.141.222">http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.141.222</a></p>
<p>Fully Automatic Cross-associations (2004) clustering algorithm with no magic numbers <a href="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.67.9951">http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.67.9951</a></p>
<p>One and done? Optimal decisions from very few samples (2009) <a href="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.211.6874">http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.211.6874</a></p>
<p>Whatever Next? Predictive Brains, Situated Agents, and the Future of Cognitive Science. (2012) <a href="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.259.7600">http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.259.7600</a></p>
<h4 id="popular-science"><span class="section_number">17.1.2</span><span class="section_title">Popular science</span></h4>
<p><a href="https://qz.com/1161771/we-looked-at-the-major-scientific-discoveries-from-five-years-ago-to-see-where-they-are-now/">https://qz.com/1161771/we-looked-at-the-major-scientific-discoveries-from-five-years-ago-to-see-where-they-are-now/</a></p>
<p><a href="https://inside.com/lists/technically-sentient/recent_issues">https://inside.com/lists/technically-sentient/recent_issues</a></p>
<p>6 areas of AI and machine learning to watch closely <a href="https://medium.com/@NathanBenaich/6-areas-of-artificial-intelligence-to-watch-closely-673d590aa8aa#.sp7w03rk5">https://medium.com/@NathanBenaich/6-areas-of-artificial-intelligence-to-watch-closely-673d590aa8aa#.sp7w03rk5</a></p>
<p>Differentiable neural computers <a href="https://deepmind.com/blog/differentiable-neural-computers/">https://deepmind.com/blog/differentiable-neural-computers/</a></p>
<p>Unlikely reading list? Delete?</p>
<ul>
<li>Survey-like
<ul>
<li>2006, chapter, &quot;Topics in multivariate approximation theory&quot;, <a href="https://www.researchgate.net/publication/226303661_Topics_in_multivariate_approximation_theory">pdf available</a></li>
<li>1982, article, &quot;Topics in multivariate approximation theory&quot;, <a href="http://www.dtic.mil/dtic/tr/fulltext/u2/a116248.pdf">pdf</a></li>
<li>1986, &quot;Multivariate Approximation Theory: Selected Topics&quot;, <a href="https://epubs.siam.org/doi/book/10.1137/1.9781611970197">paywall</a></li>
</ul></li>
<li>Theorem
<ul>
<li>2017, article, &quot;Multivariate polynomial approximation in the hypercube&quot;, <a href="https://people.maths.ox.ac.uk/trefethen/hypercube_published.pdf">pdf</a></li>
</ul></li>
<li>2017, article, &quot;Selected open problems in polynomial approximation and potential theory&quot;, <a href="http://drna.padovauniversitypress.it/system/files/papers/BaranCiezEgginkKowalskaNagyPierzcha%C5%82a_DRNA2017.pdf">pdf</a></li>
<li>2017, article, &quot;High order approximation theory for Banach space valued functions&quot;, <a href="https://ictp.acad.ro/jnaat/journal/article/view/1112">pdf available</a></li>
<li>Articles summarizing people's works
<ul>
<li>2017, article, &quot;Michael J.D. Powell's work in approximation theory and optimisation&quot;, <a href="https://www.sciencedirect.com/science/article/abs/pii/S0021904517301053">paywall</a></li>
<li>2000, article, &quot;Weierstrass and Approximation Theory&quot;, <a href="https://www.sciencedirect.com/science/article/pii/S0021904500935081">paywall</a></li>
</ul></li>
<li>2013, article, &quot;[1312.5540] Emerging problems in approximation theory for the numerical solution of nonlinear PDEs of integrable type&quot;, <a href="https://arxiv.org/abs/1312.5540">pdf available</a></li>
<li>1985, article, &quot;Some problems in approximation theory and numerical analysis - IOPscience&quot;, <a href="http://iopscience.iop.org/article/10.1070/RM1985v040n01ABEH003526">pdf available</a></li>
<li>2011, article, &quot;Experiments on Probabilistic Approximations&quot;, <a href="https://people.eecs.ku.edu/~jerzygb/c154-clark.pdf">pdf</a></li>
</ul>
<h3 id="fields-of-study-related-to-intelligence"><span class="section_number">17.2</span><span class="section_title"><span class="todo TODO">TODO</span> Fields of study related to intelligence</span></h3>
<p>AI is about making something that is as intelligent as a human brain without caring about how human brain works. Cognitive neuroscience is about how a human brain works.</p>
<p>Brain is a vector function</p>
<p>Machine learning. Machine learning makes machine do things from examples.</p>
<p>What fields does this book depend on?</p>
<p>Computational neuroscience</p>
<p>Intelligence needs the ability to adapt.</p>
<p>Every software system is a state machine.</p>
<p>Curry's Y combinator makes a fixed point equation</p>
<p>What are the limits of intelligence?</p>
<p>Topology <span class="citation" data-cites="Topology">[<a href="#ref-Topology">36</a>]</span></p>
<p>Functional analysis</p>
<p>Dynamical system</p>
<p>Control theory</p>
<p>Fixed point theory</p>
<p>Neurophysiology</p>
<p>Computer science</p>
<p><a href="https://en.wikipedia.org/wiki/Connectionism">https://en.wikipedia.org/wiki/Connectionism</a></p>
<p><a href="https://en.wikipedia.org/wiki/Cybernetics">https://en.wikipedia.org/wiki/Cybernetics</a></p>
<p>Biological neuron model <a href="https://en.wikipedia.org/wiki/Biological_neuron_model">https://en.wikipedia.org/wiki/Biological_neuron_model</a></p>
<p>An introduction to mathematical physiology <a href="https://people.maths.ox.ac.uk/fowler/courses/physiol/physiolnotes.pdf">https://people.maths.ox.ac.uk/fowler/courses/physiol/physiolnotes.pdf</a></p>
<p>Learning and Transfer of Learning with No Feedback: An Experimental Test Across Games <a href="http://repository.cmu.edu/cgi/viewcontent.cgi?article=1040&amp;context=sds">http://repository.cmu.edu/cgi/viewcontent.cgi?article=1040&amp;context=sds</a></p>
<p>Perceptual learning without feedback in non-stationary contexts: Data and model <a href="http://socsci-dev.ss.uci.edu/maplab/webdocs/petrovdosherlu06.pdf">http://socsci-dev.ss.uci.edu/maplab/webdocs/petrovdosherlu06.pdf</a></p>
<p>Neural coding <a href="https://en.wikipedia.org/wiki/Neural_coding">https://en.wikipedia.org/wiki/Neural_coding</a></p>
<p>Pulse-frequency modulation in brain neurons</p>
<p>Reward system</p>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">17.2.1</span><span class="section_title"><a href="#imagination-is-as-real-as-perception">Imagination is as real as perception</a></span><span class="word_count">(63w~1m)</span></li>
<li><span class="section_number">17.2.2</span><span class="section_title"><a href="#genetic-algorithm">Genetic algorithm</a></span><span class="word_count">(147w~1m)</span></li>
<li><span class="section_number">17.2.3</span><span class="section_title"><a href="#the-brain-at-a-time-is-a-big-array-function.">The brain at a time is a big array function.</a></span><span class="word_count">(23w~1m)</span></li>
<li><span class="section_number">17.2.4</span><span class="section_title"><a href="#control-and-consciousness-require-feedback">Control and consciousness require feedback</a></span><span class="word_count">(100w~1m)</span></li>
<li><span class="section_number">17.2.5</span><span class="section_title"><a href="#phase-space-learning">Phase-space learning?</a></span><span class="word_count">(75w~1m)</span></li>
<li><span class="section_number">17.2.6</span><span class="section_title"><a href="#what-are-the-ways-of-describing-a-system">What are the ways of describing a system?</a></span><span class="word_count">(34w~1m)</span></li>
<li><span class="section_number">17.2.7</span><span class="section_title"><a href="#supervised-to-unsupervised">Supervised to unsupervised</a></span><span class="word_count">(15w~1m)</span></li>
<li><span class="section_number">17.2.8</span><span class="section_title"><a href="#approximation-to-optimization">Approximation to optimization</a></span><span class="word_count">(13w~1m)</span></li>
<li><span class="section_number">17.2.9</span><span class="section_title"><a href="#optimal-clustering">Optimal clustering</a></span><span class="word_count">(11w~1m)</span></li>
<li><span class="section_number">17.2.10</span><span class="section_title"><a href="#optimal-approximation">Optimal approximation</a></span><span class="word_count">(65w~1m)</span></li>
<li><span class="section_number">17.2.11</span><span class="section_title"><a href="#meta-approximation">Meta-approximation</a></span><span class="word_count">(63w~1m)</span></li>
</ul>
</div>
<h4 id="imagination-is-as-real-as-perception"><span class="section_number">17.2.1</span><span class="section_title">Imagination is as real as perception</span></h4>
<p>Imagining a thing excites the same neurons as perceiving that thing. Therefore if we have a very good mental model, we should be able to perform experiments in our imagination and translate the results to the real world.</p>
<p>Imagine that an intelligent machine existed, and then work our way back. Invent a story about how we would get there.</p>
<h4 id="genetic-algorithm"><span class="section_number">17.2.2</span><span class="section_title">Genetic algorithm</span></h4>
<p>A <em>genetic algorithm</em> is an iterated randomized mixing filtering optimization. Generalized genetic algorithm: Let <span class="math inline">\(\fun{Pop}\)</span> be the population type. Let <span class="math inline">\(t : \Nat\)</span> be time. Let <span class="math inline">\(\fun{pop}~t : \fun{Pop}\)</span> be the population at time <span class="math inline">\(t\)</span>. Let <span class="math inline">\(\fun{fit}: \fun{Pop}\to \fun{Pop}\)</span> be the fitness filter a.k.a. selection function a.k.a. selection pressure function. Let <span class="math inline">\(\fun{mate}: \fun{Pop}\to \fun{Pop}\to \fun{Pop}\)</span> be the next-population function, including mutation, birth, death, mating. Let <span class="math inline">\(\fun{sur}~(t+1) = \fun{fit}~(\fun{pop}~t)\)</span> be the survivor set at time <span class="math inline">\(t+1\)</span>. The algorithm is the equation <span class="math inline">\(\forall t \in \Nat : \fun{pop}~(t+1) = \fun{sur}~(t+1) + \fun{mate}~(\fun{pop}~t)\)</span>. Observe the sequence of populations <span class="math inline">\(\fun{pop}~0, \ldots, \fun{pop}~t\)</span>. A genetic algorithm, an iterated search algorithm, is a mono-unary algebra. Genetic algorithm is like tree search. The mating function is the fringe function. A genetic algorithm is a stochastic process. A genetic algorithm takes a filtering and mating algorithm and produces a search algorithm.</p>
<p>Simulated annealing.</p>
<p>Randomized search algorithm.</p>
<h4 id="the-brain-at-a-time-is-a-big-array-function."><span class="section_number">17.2.3</span><span class="section_title">The brain at a time is a big array function.</span></h4>
<p>Can we formulate it in a way that does not depend on linear time?</p>
<h4 id="control-and-consciousness-require-feedback"><span class="section_number">17.2.4</span><span class="section_title">Control and consciousness require feedback</span></h4>
<p>Control needs feedback. There is also open-loop or feed-forward control, but complex control needs feedback.</p>
<p>Consciousness needs feedback. Consciousness needs sensory input. Self concept needs feedback. If there is not a feedback, a system cannot distinguish itself from its environment. The self concept will never arise.</p>
<p>If a brain can immediately control a thing, then that thing is part of the brain's self concept. If the brain can't, it's not.</p>
<p>If a brain often gets certain input shortly after it produces certain output, it will associate the output with its self concept.</p>
<p>The self is the thing under conscious control.</p>
<h4 id="phase-space-learning"><span class="section_number">17.2.5</span><span class="section_title">Phase-space learning?</span></h4>
<p>There is a boundary: the agent, and the environment. How many functions do we need to model it?</p>
<p>One function that is an endofunction of phase space. The agent state is a subspace of that phase space. The environment state is another subspace of that phase space.</p>
<p>The idea is to represent the how the phase space changes in a small time. The number of variables should equal to the degree of freedom of the system.</p>
<h4 id="what-are-the-ways-of-describing-a-system"><span class="section_number">17.2.6</span><span class="section_title">What are the ways of describing a system?</span></h4>
<ul>
<li><p>function from time to state</p></li>
<li><p>endofunction of phase space</p></li>
</ul>
<p>State space and phase space are the same. State space is for discrete systems. Phase space is for continuous systems.</p>
<h4 id="supervised-to-unsupervised"><span class="section_number">17.2.7</span><span class="section_title">Supervised to unsupervised</span></h4>
<p>Can a supervised learning algorithm always be made into an unsupervised learning algorithm?</p>
<h4 id="approximation-to-optimization"><span class="section_number">17.2.8</span><span class="section_title">Approximation to optimization</span></h4>
<p>Can an approximation scheme always be made into an optimization scheme?</p>
<h4 id="optimal-clustering"><span class="section_number">17.2.9</span><span class="section_title">Optimal clustering</span></h4>
<p>Given a set of points, what is the optimal clustering/partition?</p>
<h4 id="optimal-approximation"><span class="section_number">17.2.10</span><span class="section_title">Optimal approximation</span></h4>
<p>Given a set of points <span class="math inline">\(\{(x_1,y_1),\ldots,(x_n,y_n)\}\)</span> (samples of a function), what is the function that optimally approximates those samples? The approximation error is <span class="math inline">\(\sum_k y_k - f(x_k)\)</span>. Let <span class="math inline">\(F\)</span> be the set of all integrable real-to-real functions. Define <span class="math inline">\(M(f) = \int_\Real f\)</span> as the infinite integral of <span class="math inline">\(f\)</span>. Define the complexity of <span class="math inline">\(f\)</span> as <span class="math inline">\(C(f) = \sum_{k=1}^\infty M(D_k(f))\)</span> where <span class="math inline">\(D\)</span> is the derivative operator.</p>
<h4 id="meta-approximation"><span class="section_number">17.2.11</span><span class="section_title">Meta-approximation</span></h4>
<p>Given set of points <span class="math inline">\(D = \{(x_1,y_1),\ldots,(x_n,y_n)\}\)</span>, find <span class="math inline">\(g\)</span> that finds <span class="math inline">\(f\)</span> that approximates <span class="math inline">\(D\)</span>.</p>
<p>Let <span class="math inline">\(F\)</span> be the set of all real-to-real functions. Can we craft a measure on <span class="math inline">\(F\)</span>? Can we craft a probability measure on <span class="math inline">\(F\)</span>? Can we craft a universal prior for <span class="math inline">\(F\)</span> like Solomonoff did for bitstrings?</p>
<p>What is the best way to update the approximator using the approximation error?</p>
<h3 id="independent-scholar-citizen-science"><span class="section_number">17.3</span><span class="section_title">Independent scholar? Citizen science?</span></h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Independent_scholar">https://en.wikipedia.org/wiki/Independent_scholar</a></li>
<li><a href="https://en.wikipedia.org/wiki/Citizen_science">https://en.wikipedia.org/wiki/Citizen_science</a></li>
</ul>
<h2 id="system-models-todo-clean-up-system.org"><span class="section_number">18</span><span class="section_title">System models? TODO clean up system.org</span></h2>
<p>This chapter defines <em>system</em>. Later chapters discuss interesting systems. We classify systems, hoping to gain some insight. We can classify systems into two big classes: <em>time-dependent</em> (time-variant, temporal) and <em>time-independent</em> (time-invariant, atemporal).</p>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">18.1</span><span class="section_title"><a href="#what-is-a-system">What is a system?</a></span><span class="word_count">(138w~1m)</span></li>
<li><span class="section_number">18.2</span><span class="section_title"><a href="#ignoring-degenerate-feedback-feedforward">Ignoring degenerate feedback: feedforward</a></span><span class="word_count">(53w~1m)</span></li>
<li><span class="section_number">18.3</span><span class="section_title"><a href="#finding-feedback-the-inverse-fixed-point-problem">Finding feedback: the inverse fixed point problem</a></span><span class="word_count">(161w~1m)</span></li>
<li><span class="section_number">18.4</span><span class="section_title"><a href="#feedback-based-on-differentiability-preserving-map">Feedback based on differentiability-preserving map</a></span><span class="word_count">(119w~1m)</span></li>
<li><span class="section_number">18.5</span><span class="section_title"><a href="#measuring-feedback">Measuring feedback</a></span><span class="word_count">(66w~1m)</span></li>
<li><span class="section_number">18.6</span><span class="section_title"><a href="#linear-feedback-and-function-classes">Linear feedback and function classes</a></span><span class="word_count">(30w~1m)</span></li>
<li><span class="section_number">18.7</span><span class="section_title"><a href="#temporal-systems">Temporal systems</a></span><span class="word_count">(93w~1m)</span></li>
<li><span class="section_number">18.8</span><span class="section_title"><a href="#first-order-system">First-order system</a></span><span class="word_count">(67w~1m)</span></li>
<li><span class="section_number">18.9</span><span class="section_title"><a href="#chaining-temporal-systems">Chaining temporal systems</a></span><span class="word_count">(51w~1m)</span></li>
<li><span class="section_number">18.10</span><span class="section_title"><a href="#stateless-and-stateful-systems">Stateless and stateful systems</a></span><span class="word_count">(77w~1m)</span></li>
<li><span class="section_number">18.11</span><span class="section_title"><a href="#property">Property</a></span><span class="word_count">(23w~1m)</span></li>
<li><span class="section_number">18.12</span><span class="section_title"><a href="#constraint">Constraint</a></span><span class="word_count">(13w~1m)</span></li>
<li><span class="section_number">18.13</span><span class="section_title"><a href="#parameterfamily">Parameter/family</a></span><span class="word_count">(10w~1m)</span></li>
<li><span class="section_number">18.14</span><span class="section_title"><a href="#measure">Measure</a></span><span class="word_count">(21w~1m)</span></li>
<li><span class="section_number">18.15</span><span class="section_title"><a href="#temporal-measure">Temporal measure</a></span><span class="word_count">(15w~1m)</span></li>
<li><span class="section_number">18.16</span><span class="section_title"><a href="#system-space">System space</a></span><span class="word_count">(6w~1m)</span></li>
<li><span class="section_number">18.17</span><span class="section_title"><a href="#system-endofunction">System endofunction</a></span><span class="word_count">(4w~1m)</span></li>
<li><span class="section_number">18.18</span><span class="section_title"><a href="#output-input-gradient">Output-input gradient</a></span><span class="word_count">(25w~1m)</span></li>
<li><span class="section_number">18.19</span><span class="section_title"><a href="#minimand">Minimand</a></span><span class="word_count">(87w~1m)</span></li>
<li><span class="section_number">18.20</span><span class="section_title"><a href="#constrained-system">Constrained system</a></span><span class="word_count">(28w~1m)</span></li>
<li><span class="section_number">18.21</span><span class="section_title"><a href="#optimizing-system">Optimizing system</a></span><span class="word_count">(52w~1m)</span></li>
<li><span class="section_number">18.22</span><span class="section_title"><a href="#purposeful-system">Purposeful system</a></span><span class="word_count">(90w~1m)</span></li>
<li><span class="section_number">18.23</span><span class="section_title"><a href="#how-do-we-measure-how-well-a-system-serves-its-purpose">How do we measure how well a system serves its purpose?</a></span><span class="word_count">(21w~1m)</span></li>
<li><span class="section_number">18.24</span><span class="section_title"><a href="#what-is-an-intelligent-system">What is an intelligent system?</a></span><span class="word_count">(47w~1m)</span></li>
</ul>
</div>
<h3 id="what-is-a-system"><span class="section_number">18.1</span><span class="section_title">What is a system?</span></h3>
<p>We define a system as an input, a state, and an output. The input is <span class="math inline">\(x\)</span>, the output is <span class="math inline">\(y\)</span>, and an equation relates them. The state is implied by the equation. Such equation can be written <span class="math inline">\(f~y~x = y\)</span>. The equation can be quite arbitrary. The terms <span class="math inline">\(f,x,y\)</span> may appear on both sides of the equation.</p>
<p>A system is <span class="math inline">\((x,y,f)\)</span> where <span class="math inline">\(y=f~y~x\)</span>.</p>
<p>An <em>invariant</em> of a system is a property that stays the same throughout the evolution of the system.</p>
<p>The behavior of a system is its output, especially the observable part of the output.</p>
<p>Composition</p>
<p>Continuous system</p>
<p>Discrete system</p>
<p>Finite system</p>
<p>An embedded system is a system in another system. The outer system feeds the inner system's output back to the inner system's input, possibly with some change.</p>
<p>Don't confuse this with embedded systems in computer engineering.</p>
<p>How do we measure system complexity?</p>
<h3 id="ignoring-degenerate-feedback-feedforward"><span class="section_number">18.2</span><span class="section_title">Ignoring degenerate feedback: feedforward</span></h3>
<p>Every function <span class="math inline">\(f\)</span> is a special case of the general feedback equation <span class="math inline">\(f(x) = g(f,x)\)</span> where <span class="math inline">\(g\)</span> is an identity function. This suggests that feedforward is a degenerate case of feedback. To simplify the writing, from this point on, we always assume that a feedback is non-degenerate unless written otherwise.</p>
<h3 id="finding-feedback-the-inverse-fixed-point-problem"><span class="section_number">18.3</span><span class="section_title">Finding feedback: the inverse fixed point problem</span></h3>
<p>Given <span class="math inline">\(f\)</span>, find a <span class="math inline">\(g\)</span> such that <span class="math inline">\(f(x) = g(f,x)\)</span> and <span class="math inline">\(g\)</span> is not an identity function.</p>
<p>The forward fixed point problem: Given <span class="math inline">\(f\)</span>, find an <span class="math inline">\(x\)</span> such that <span class="math inline">\(x=f(x)\)</span>.</p>
<p>The inverse fixed point problem is &quot;Given <span class="math inline">\(x\)</span>, find an <span class="math inline">\(f\)</span> such that <span class="math inline">\(x = f(x)\)</span> and <span class="math inline">\(f\)</span> is not an identity function.&quot; This problem arises when we want to determine if <span class="math inline">\(f\)</span> has a feedback.</p>
<p>Example of non-feedback: linear functions. Consider a function of the form <span class="math inline">\(f(x) = a \cdot x + b\)</span> where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are non-zero constants. The only <span class="math inline">\(g\)</span> that satisfies <span class="math inline">\(g(f) = f\)</span> is the identity function <span class="math inline">\(g(x)=x\)</span>.</p>
<p>Example of feedback: functional equation. Consider a function of the form <span class="math inline">\(f(x) = x \cdot f(x-1)\)</span>.</p>
<p>Recursive functions are special cases of feedback. Searching in list. <span class="math inline">\(f(N,e) = 0\)</span>. <span class="math inline">\(f(C,h,t,e) = h \equiv e \vee f(t,e)\)</span>. <span class="math inline">\(g\)</span> is the Y-combinator.</p>
<p>We have a problem: there are infinitely many wildly discontinuous functions satisfying that. We want smooth functions.</p>
<h3 id="feedback-based-on-differentiability-preserving-map"><span class="section_number">18.4</span><span class="section_title">Feedback based on differentiability-preserving map</span></h3>
<p>We want a map that preserves differentiability. Formally, given <span class="math inline">\(f=g(f)\)</span>, we want <span class="math inline">\(g\)</span> to have the property that iff <span class="math inline">\(f\)</span> is differentiable then <span class="math inline">\(g(f)\)</span> is also differentiable. Surely if <span class="math inline">\(f\)</span> is differentiable and <span class="math inline">\(g\)</span> is differentiable then <span class="math inline">\(g(f)\)</span> is also differentiable? Surely if <span class="math inline">\(f\)</span> is differentiable <span class="math inline">\(g\)</span> is a polynomial then <span class="math inline">\(g(f)\)</span> is differentiable?</p>
<p>We begin with the generalized differential on a field: <span class="math inline">\(g~(f+h) = g~f + h \cdot d~g~f\)</span> where <span class="math inline">\((f + g)~x = f~x + g~x\)</span> and <span class="math inline">\((f \cdot g)~x = f~x \cdot g~x\)</span>. Thus <span class="math inline">\(h \cdot d~g~f = g~(f+h) - g~f\)</span>. This is like computing the gradient of a vector function, but the vector is infinite-dimensional.</p>
<p>Is it time to learn topology? Smooth manifolds?</p>
<h3 id="measuring-feedback"><span class="section_number">18.5</span><span class="section_title">Measuring feedback</span></h3>
<p>Given a system <span class="math inline">\(f(x) = g(f,x)\)</span>, we're interested in measuring how much feedback it has.</p>
<p>Assume that <span class="math inline">\(f\)</span> is a vector. We can measure the feedback by measuring <span class="math inline">\(d_f ~ g\)</span>: the differential of <span class="math inline">\(g\)</span> with respect to <span class="math inline">\(f\)</span>. Using non-standard analysis, we define the gradient <span class="math inline">\(d f\)</span> as something satisfying <span class="math inline">\(f(x + h) = f(x) + h \cdot (d f)(x)\)</span> where <span class="math inline">\(h\)</span> is an infinitesimal.</p>
<h3 id="linear-feedback-and-function-classes"><span class="section_number">18.6</span><span class="section_title">Linear feedback and function classes</span></h3>
<p>If <span class="math inline">\(f\)</span> is linear and <span class="math inline">\(g\)</span> is linear, then <span class="math inline">\(f \circ g\)</span> is linear. A linear feedback does not add anything interesting to a linear function.</p>
<h3 id="temporal-systems"><span class="section_number">18.7</span><span class="section_title">Temporal systems</span></h3>
<p>A temporal system, a time-dependent system, or a time-variant system is a system that depends on time. With time, we can define more interesting systems.</p>
<p>A temporal system is a function whose type is <span class="math inline">\((T \to X) \to T \to Y\)</span>. <span class="math display">\[\SysTmp~T~X~Y = (T \to X) \to (T \to Y)\]</span></p>
<p>We can see a temporal system as a transformation of time functions. <span class="math inline">\((T \to X) \to (T \to Y)\)</span>.</p>
<p>Example: <span class="math inline">\(f~x~t = (x~t)^2\)</span>.</p>
<p>Example: <span class="math display">\[f~x~t = x~t + \int_0^t (s - f~x~t) \cdot dt\]</span>.</p>
<p>A temporal system is <span class="math inline">\((x,y,f,T)\)</span> that satisfies <span class="math inline">\(\forall t \in T : f~y~x~t\)</span>.</p>
<h3 id="first-order-system"><span class="section_number">18.8</span><span class="section_title">First-order system</span></h3>
<p>The previous section talks about second-order system.</p>
<p>This is a first-order system: <span class="math inline">\(\SysTmp~T~X~Y = X \to T \to Y\)</span>.</p>
<p><span class="math inline">\(\SysTmp~T~X~Y = T \to X \to Y\)</span>.</p>
<p>There are two points of view: <span class="math inline">\(d_x~f\)</span> and <span class="math inline">\(d_t~f\)</span>.</p>
<p>First-order system should be more analyzable.</p>
<p>Continuous-time and discrete-time system?</p>
<p>In the above definition, <span class="math inline">\(T\)</span> is the time type. If <span class="math inline">\(T = \R\)</span> we call the system continuous-time. If <span class="math inline">\(T = \N\)</span> we call the system discrete-time.</p>
<h3 id="chaining-temporal-systems"><span class="section_number">18.9</span><span class="section_title">Chaining temporal systems</span></h3>
<p>We can feed the output temporal system <span class="math inline">\(f\)</span> to the input of the temporal system <span class="math inline">\(g\)</span> this produces the temporal system <span class="math inline">\(h\)</span> where <span class="math inline">\(h~x~t = g~(f~x)~t\)</span>, or <span class="math inline">\(h~x = g~(f~x)\)</span> after eta-conversion, or <span class="math inline">\(h = g \circ f\)</span>. It turns out that system composition is just plain function composition.</p>
<h3 id="stateless-and-stateful-systems"><span class="section_number">18.10</span><span class="section_title">Stateless and stateful systems</span></h3>
<p>A system is stateless iff the same input always gives the same output. There is no way to tell apart a system that has state but doesn't use it and a system that really has no state.</p>
<p>A stateless system is a temporal system that satisfies <span class="math inline">\(\forall t : \forall u: x~t = x~u \implies y~t = y~u\)</span>.</p>
<p>In a stateful system, the same input can give different outputs, depending on time.</p>
<p>Why do we define those?</p>
<h3 id="property"><span class="section_number">18.11</span><span class="section_title">Property</span></h3>
<p>If <span class="math inline">\(p\)</span> is a predicate that is always true for a system, then <span class="math inline">\(p\)</span> is a property of that system. <span class="math inline">\(\SysTmp~T~X~Y \to \{0,1\}\)</span></p>
<h3 id="constraint"><span class="section_number">18.12</span><span class="section_title">Constraint</span></h3>
<p>A constraint of <span class="math inline">\(S\)</span> is a property of <span class="math inline">\(S\)</span> that is always true.</p>
<h3 id="parameterfamily"><span class="section_number">18.13</span><span class="section_title">Parameter/family</span></h3>
<p>Parameterized system.</p>
<p><span class="math inline">\(P \to \SysTmp~T~X~Y\)</span></p>
<p>System parameter.</p>
<p>Family of systems.</p>
<p>Indexed family of systems.</p>
<h3 id="measure"><span class="section_number">18.14</span><span class="section_title">Measure</span></h3>
<p>Categorical inverse of parameter. (Whatever categorical inverse means.)</p>
<p>From type theory point of view, parametrization is the inverse of measurement.</p>
<p><span class="math inline">\(\SysTmp~T~X~Y \to M\)</span></p>
<h3 id="temporal-measure"><span class="section_number">18.15</span><span class="section_title">Temporal measure</span></h3>
<p><span class="math inline">\(m : \SysTmp~T~X~Y \to (T \to M)\)</span></p>
<p>Find <span class="math inline">\(s\)</span> that minimizes <span class="math inline">\(m~s~t\)</span> as <span class="math inline">\(t\)</span> grows.</p>
<h3 id="system-space"><span class="section_number">18.16</span><span class="section_title">System space</span></h3>
<p>Like function space. Metric space.</p>
<h3 id="system-endofunction"><span class="section_number">18.17</span><span class="section_title">System endofunction</span></h3>
<p><span class="math inline">\(\SysTmp~T~X~Y \to \SysTmp~T~X~Y\)</span>.</p>
<h3 id="output-input-gradient"><span class="section_number">18.18</span><span class="section_title">Output-input gradient</span></h3>
<p><span class="math inline">\(f : \SysTmp~T~X~Y\)</span></p>
<p><span class="math inline">\(f~(x+h) - f~x = h \cdot d~f~x\)</span> but <span class="math inline">\(h\)</span> is a function.</p>
<p><span class="math inline">\(m\)</span>-adaptivity</p>
<p><span class="math inline">\((m~f~(x+h) - m~f~x) / h\)</span></p>
<p>Reversal: <span class="math inline">\(\SysTmp~T~X~Y \to \SysTmp~T~Y~X\)</span></p>
<p>Time-reversible/Time-symmetric: <span class="math inline">\(f~x~t = f~x~(-t)\)</span></p>
<h3 id="minimand"><span class="section_number">18.19</span><span class="section_title">Minimand</span></h3>
<p>The minimand is the thing that is to be minimized. It's an English word. The minimand of a temporal system is a function that is minimized as time goes by.</p>
<p>Recall that a temporal system has type <span class="math inline">\((T \to X) \to T \to Y\)</span>. A minimand is a function that has type <span class="math inline">\((T \to X) \to T \to M\)</span>.</p>
<p>The function <span class="math inline">\(g\)</span> is a minimand of a temporal system <span class="math inline">\(s\)</span> iff <span class="math inline">\(g~s~t \xrightarrow[t \to \infty]{} 0\)</span>.</p>
<p>There's always a trivial minimand: <span class="math inline">\(g~s~t = 0\)</span>.</p>
<p>Does every system have a non-trivial minimand?</p>
<h3 id="constrained-system"><span class="section_number">18.20</span><span class="section_title">Constrained system</span></h3>
<p>Constrained system: a system whose equation is subject to constraints (which can be inequalities). Every system is constrained; the definition requires it. So why bother defining this?</p>
<h3 id="optimizing-system"><span class="section_number">18.21</span><span class="section_title">Optimizing system</span></h3>
<p>A system is <em>optimizing</em> iff it optimizes a function. We call this function a <em>goal function</em>. The purpose of the system is to minimize the goal function.</p>
<p>A goal is something that a system wants to reach. This implies that the definition of goal involves time. The goal function is usually hidden.</p>
<h3 id="purposeful-system"><span class="section_number">18.22</span><span class="section_title">Purposeful system</span></h3>
<p>We also call a purposeful system an optimizing system.</p>
<p><em>Purpose requires time.</em></p>
<p>Let <span class="math inline">\(x\)</span> be a function of time. Let the equation <span class="math inline">\(f~x~t = y\)</span> govern the system. Let <span class="math inline">\(g~x\)</span> be a function of time. The system is <em>purposeful</em> iff <span class="math inline">\(g~x~t\)</span> approaches zero as <span class="math inline">\(t\)</span> grows, for some non-trivial <span class="math inline">\(g\)</span>. We say that <span class="math inline">\(g\)</span> is a <em>purpose</em> or a <em>goal</em> of the system. The goal function may represent the sensed error with respect to a setpoint.</p>
<p>A purposeful system doesn't have to be adaptive. A simple thermostat is purposeful but not adaptive.</p>
<h3 id="how-do-we-measure-how-well-a-system-serves-its-purpose"><span class="section_number">18.23</span><span class="section_title">How do we measure how well a system serves its purpose?</span></h3>
<p>is like measuring the rate of convergence of an approximation scheme.</p>
<h3 id="what-is-an-intelligent-system"><span class="section_number">18.24</span><span class="section_title">What is an intelligent system?</span></h3>
<p>Stable system: See stability theory. Lyapunov.</p>
<p>How do we measure how adaptive a system is?</p>
<p>An adaptive system is a system that adapts.</p>
<p>Adaptation implies change.</p>
<p>Adapt means &quot;fit, adjust&quot;.</p>
<p>Adaptive with respect to what?</p>
<p>Chaotic system: Small change in input causes large change in output. See chaos theory.</p>
<h2 id="are-we-squinting-too-hard"><span class="section_number">19</span><span class="section_title">Are we squinting too hard?</span></h2>
<p>This is speculative. Some topics may be philosophical dead-ends.</p>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">19.1</span><span class="section_title"><a href="#approximation-theory-software-engineering-and-almost-correct-programs">&lt;2018-12-28&gt; Approximation theory, software engineering, and almost-correct programs</a></span><span class="word_count">(58w~1m)</span></li>
<li><span class="section_number">19.2</span><span class="section_title"><a href="#every-person-on-earth-is-a-prolog-knowledge-base.">&lt;2018-12-28&gt; Every person on Earth is a Prolog knowledge base.</a></span><span class="word_count">(30w~1m)</span></li>
<li><span class="section_number">19.3</span><span class="section_title"><a href="#idea-for-writing-an-academic-book">&lt;2018-12-28&gt; Idea for writing an academic book</a></span><span class="word_count">(32w~1m)</span></li>
<li><span class="section_number">19.4</span><span class="section_title"><a href="#mind-upload-and-knowing-without-learning">&lt;2018-12-28&gt; Mind upload, and knowing without learning</a></span><span class="word_count">(19w~1m)</span></li>
<li><span class="section_number">19.5</span><span class="section_title"><a href="#dropping-the-artificial">&lt;2018-12-28&gt; Dropping the &quot;artificial&quot;</a></span><span class="word_count">(106w~1m)</span></li>
<li><span class="section_number">19.6</span><span class="section_title"><a href="#intelligence-has-nothing-to-do-with-minds">&lt;2018-12-28&gt; Intelligence has nothing to do with minds</a></span><span class="word_count">(13w~1m)</span></li>
<li><span class="section_number">19.7</span><span class="section_title"><a href="#what-is-so-bad-about-human-extinction">&lt;2018-12-28&gt; What is so bad about human extinction?</a></span><span class="word_count">(35w~1m)</span></li>
<li><span class="section_number">19.8</span><span class="section_title"><a href="#guesses">&lt;2018-12-28&gt; Guesses</a></span><span class="word_count">(24w~1m)</span></li>
<li><span class="section_number">19.9</span><span class="section_title"><a href="#non-prioritized-questions">Non-prioritized questions</a></span><span class="word_count">(29w~1m)</span></li>
<li><span class="section_number">19.10</span><span class="section_title"><a href="#making-machines-work"><span class="todo TODO">TODO</span> Making machines work</a></span><span class="word_count">(516w~3m)</span></li>
<li><span class="section_number">19.11</span><span class="section_title"><a href="#idea-determining-the-number-of-parameters-in-line-fitting-by-measuring-effective-dimension-of-a-set-of-points">&lt;2018-12-28&gt; Idea: determining the number of parameters in line fitting, by measuring &quot;effective dimension&quot; of a set of points</a></span><span class="word_count">(221w~2m)</span></li>
<li><span class="section_number">19.12</span><span class="section_title"><a href="#logic-language-and-approximation-theory">&lt;2018-12-28&gt; Logic, language, and approximation theory</a></span><span class="word_count">(66w~1m)</span></li>
<li><span class="section_number">19.13</span><span class="section_title"><a href="#functional-analysis-currying-and-partial-evaluation">Functional analysis, currying, and partial evaluation</a></span><span class="word_count">(16w~1m)</span></li>
<li><span class="section_number">19.14</span><span class="section_title"><a href="#what-is-ml-scientist">What is &quot;ML scientist&quot;?</a></span><span class="word_count">(44w~1m)</span></li>
<li><span class="section_number">19.15</span><span class="section_title"><a href="#philosophy-of-mind">Philosophy of mind?</a></span><span class="word_count">(18w~1m)</span></li>
</ul>
</div>
<h3 id="approximation-theory-software-engineering-and-almost-correct-programs"><span class="section_number">19.1</span><span class="section_title">&lt;2018-12-28&gt; Approximation theory, software engineering, and almost-correct programs</span></h3>
<p>An incorrect program (a &quot;buggy&quot; program) is an <em>approximation</em> of the intended correct program. The approximation error is the minimum change required to correct the program.</p>
<p>Sometimes regular expression approximates context-free grammar. Example: Checking email address with regex. Example: Emacs eval-defun.<a href="#fn70" class="footnote-ref" id="fnref70"><sup>70</sup></a> Example: Computing line height by returning constant 12<a href="#fn71" class="footnote-ref" id="fnref71"><sup>71</sup></a> is zeroth-order approximation.</p>
<h3 id="every-person-on-earth-is-a-prolog-knowledge-base."><span class="section_number">19.2</span><span class="section_title">&lt;2018-12-28&gt; Every person on Earth is a Prolog knowledge base.</span></h3>
<p>A good conversation is only a matter of crafting the right query to obtain the gem of knowledge from each person.</p>
<h3 id="idea-for-writing-an-academic-book"><span class="section_number">19.3</span><span class="section_title">&lt;2018-12-28&gt; Idea for writing an academic book</span></h3>
<ul>
<li>Find 100 related research papers, some by citation search.</li>
<li>Find an interesting sentence from each paper.</li>
<li>Group those 100 sentences into questions that are answered by those sentences.</li>
</ul>
<h3 id="mind-upload-and-knowing-without-learning"><span class="section_number">19.4</span><span class="section_title">&lt;2018-12-28&gt; Mind upload, and knowing without learning</span></h3>
<p>Mind uploading enables us to transfer belief without requiring the recipient to learn.</p>
<h3 id="dropping-the-artificial"><span class="section_number">19.5</span><span class="section_title">&lt;2018-12-28&gt; Dropping the &quot;artificial&quot;</span></h3>
<p>&quot;Artificial&quot; simply means &quot;man-made&quot;.</p>
<p>Being man-made is not a problem in and of itself.</p>
<p><em>The problem is that we don't understand the consequences of our actions.</em></p>
<p>Why should we care whether something is man-made?</p>
<p>A man-made helium atom is indistinguishable from a naturally occurring helium atom.</p>
<p>Soylent is man-made. One has survived eating only Soylent for a month. The problem with Soylent is not that it is man-made. The problem is that our jaws may shrink if we don't chew.</p>
<p>DDT is man-made. The problem is not that it is man-made. The problem is that it poisons humans. The problem is that we spray it without understanding the consequences.</p>
<h3 id="intelligence-has-nothing-to-do-with-minds"><span class="section_number">19.6</span><span class="section_title">&lt;2018-12-28&gt; Intelligence has nothing to do with minds</span></h3>
<p>&quot;Intelligent&quot; simply means &quot;good at something&quot;.</p>
<h3 id="what-is-so-bad-about-human-extinction"><span class="section_number">19.7</span><span class="section_title">&lt;2018-12-28&gt; What is so bad about human extinction?</span></h3>
<p>Extinction is not bad in and of itself; it is the suffering that is undesirable. But if we can go extinct without suffering, why shouldn't we go extinct?</p>
<h3 id="guesses"><span class="section_number">19.8</span><span class="section_title">&lt;2018-12-28&gt; Guesses</span></h3>
<p>In the future, there are only two kinds of jobs: telling machines to do things, and being told to do things by machines.</p>
<h3 id="non-prioritized-questions"><span class="section_number">19.9</span><span class="section_title">Non-prioritized questions</span></h3>
<ul>
<li>What is AI? Why should I care?
<ul>
<li>AI is the way for us to become gods.</li>
</ul></li>
<li>What is a cyborg?</li>
<li>If human goal function is survival, then why exists suicide?
<ul>
<li>Evolutionary noise?</li>
</ul></li>
</ul>
<p><a href="https://en.wikipedia.org/wiki/Universal_Darwinism">https://en.wikipedia.org/wiki/Universal_Darwinism</a></p>
<h3 id="making-machines-work"><span class="section_number">19.10</span><span class="section_title"><span class="todo TODO">TODO</span> Making machines work</span></h3>
<p>There are several ways to make machines work: program them, train them, or make them learn. Programming and training produce inflexible machines that cannot do things that they are not programmed or trained for.</p>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">19.10.1</span><span class="section_title"><a href="#delayed-signal-thought-experiment">Delayed signal thought experiment</a></span><span class="word_count">(75w~1m)</span></li>
<li><span class="section_number">19.10.2</span><span class="section_title"><a href="#signs-of-intelligence">Signs of intelligence</a></span><span class="word_count">(109w~1m)</span></li>
<li><span class="section_number">19.10.3</span><span class="section_title"><a href="#related-concepts">Related concepts</a></span><span class="word_count">(21w~1m)</span></li>
<li><span class="section_number">19.10.4</span><span class="section_title"><a href="#interesting-idea">Interesting idea</a></span><span class="word_count">(140w~1m)</span></li>
<li><span class="section_number">19.10.5</span><span class="section_title"><a href="#cybernetics">Cybernetics</a></span><span class="word_count">(122w~1m)</span></li>
<li><span class="section_number">19.10.6</span><span class="section_title"><a href="#supervised-classification-problems">Supervised classification problems</a></span><span class="word_count">(14w~1m)</span></li>
<li><span class="section_number">19.10.7</span><span class="section_title"><a href="#classification-involving-sequence-or-time">Classification involving sequence or time</a></span><span class="word_count">(5w~1m)</span></li>
</ul>
</div>
<h4 id="delayed-signal-thought-experiment"><span class="section_number">19.10.1</span><span class="section_title">Delayed signal thought experiment</span></h4>
<p>Imagine that you install something in your brain that delays the signal to your left hand by one hand, so your left hand does what you want it to do, but one second after when you want it to do that. Would you still think your left hand is a part of your self?</p>
<p>If a machine does not have any way of sensing touch, even indirectly, then it will never experience touch.</p>
<h4 id="signs-of-intelligence"><span class="section_number">19.10.2</span><span class="section_title">Signs of intelligence</span></h4>
<p>Imitation and survival?</p>
<p>Imitation implies intelligence? For <span class="math inline">\(a\)</span> to be able to imitate <span class="math inline">\(b\)</span>, <span class="math inline">\(a\)</span> has to have a model of <span class="math inline">\(b\)</span>.</p>
<p>If the only goal is to survive, then wouldn't the best strategy be make as many copies as many as possible?</p>
<p>Make copies, as fast as possible, as many as possible.</p>
<p>Arrange for the species to maximize the number of copies that live at the same time.</p>
<p>Make an organism as fit as possible. Make an organism survives as many environments as possible, including the environments it did not originally evolve from. A sign of intelligence is that the organism can perform well in environments it had never encountered before.</p>
<h4 id="related-concepts"><span class="section_number">19.10.3</span><span class="section_title">Related concepts</span></h4>
<p>intelligence, learning, self, consciousness, sentience, life, perception, adaptivity, adaptability, adaptation, control, language, thought, feeling, reasoning, discovery, recursion, feedback, computation, computability.</p>
<h4 id="interesting-idea"><span class="section_number">19.10.4</span><span class="section_title">Interesting idea</span></h4>
<p>Strategy 1: Given two nouns <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, find a verb <span class="math inline">\(v\)</span> such that the sentence <span class="math inline">\(a~v~b\)</span> makes sense. Strategy 2: Given two nouns <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, pick which of these two sentences make sense: &quot;<span class="math inline">\(a\)</span> requires <span class="math inline">\(b\)</span>,&quot; or &quot;<span class="math inline">\(a\)</span> does not require <span class="math inline">\(b\)</span>.&quot;</p>
<p>An early 'intelligence' is chemotaxis. Chemotaxis is random walk that is biased by the gradient. (Cite?) The deterministic version of that is gradient following algorithm. The goal is to minimize the concentration of the chemical at the location of the cell.</p>
<p>Control system. Homeostasis.</p>
<p>Deduction: Given premises, infer conclusion. Induction: Given a few premises and a conclusion, infer a rule.</p>
<p>Probabilistic logic. Generalize boolean <span class="math inline">\(\{0,1\}\)</span> to probability, real unit interval, <span class="math inline">\([0,1]\)</span>. Boolean logic is a special case of probabilistic logic. <span class="math inline">\(p~(x \wedge y) = \min~(p~x)~(p~y)\)</span>. Fuzzy logic?</p>
<p>&quot;To organize is to create capabilities by intentionally imposing order and structure.&quot; <span class="citation" data-cites="Organ">[<a href="#ref-Organ">19</a>]</span></p>
<h4 id="cybernetics"><span class="section_number">19.10.5</span><span class="section_title">Cybernetics</span></h4>
<p>How can we apply systems theory to management? <span class="citation" data-cites="SystemManage">[<a href="#ref-SystemManage">34</a>]</span></p>
<p>Ashby's optical mobile homeostat <span class="citation" data-cites="BattleHom">[<a href="#ref-BattleHom">3</a>]</span> <span class="citation" data-cites="BattleThree">[<a href="#ref-BattleThree">2</a>]</span></p>
<p>Braintenberg vehicles</p>
<p>A Gödel machine improves itself. It proves that the improvement it makes indeed makes it better. <span class="citation" data-cites="GodelMachImpl">[<a href="#ref-GodelMachImpl">51</a>]</span></p>
<p><a href="http://people.idsia.ch/~juergen/goedelmachine.html">http://people.idsia.ch/~juergen/goedelmachine.html</a></p>
<p><a href="http://people.idsia.ch/~juergen/selfreflection.pdf">http://people.idsia.ch/~juergen/selfreflection.pdf</a></p>
<p><a href="http://people.idsia.ch/~juergen/metalearner.html">http://people.idsia.ch/~juergen/metalearner.html</a></p>
<p>Steinberg and Salter (1982) wrote that intelligence is &quot;goal-directed adaptive behavior&quot;. This suggests that an intelligent system is purposeful and adaptive, in the sense we defined above. <a href="https://en.wikipedia.org/wiki/Intelligence#Definitions">https://en.wikipedia.org/wiki/Intelligence#Definitions</a></p>
<p>Intelligence maximizes future freedom? <a href="https://www.ted.com/talks/alex_wissner_gross_a_new_equation_for_intelligence/transcript?language=en#t-121478">https://www.ted.com/talks/alex_wissner_gross_a_new_equation_for_intelligence/transcript?language=en#t-121478</a></p>
<p><span class="citation" data-cites="PickeringCyber">[<a href="#ref-PickeringCyber">40</a>]</span> <span class="citation" data-cites="GoertzelAgi">[<a href="#ref-GoertzelAgi">20</a>]</span> <span class="citation" data-cites="SlomanTuringIrrelevance">[<a href="#ref-SlomanTuringIrrelevance">46</a>]</span></p>
<p>Giulio Tononi, integrated information theory (not to be confused with information integration theory)</p>
<p>Nils J. Nilsson modeled a world and an agent as finite-state machines <span class="citation" data-cites="NilsLogicAi">[<a href="#ref-NilsLogicAi">39</a>]</span>. He used explicit sense type, action type, and memory type. William Ross Ashby used the phase space of a continuous dynamical system, where time is a real number, to describe an agent's behavior <span class="citation" data-cites="AshbyBrain">[<a href="#ref-AshbyBrain">1</a>]</span>.</p>
<h4 id="supervised-classification-problems"><span class="section_number">19.10.6</span><span class="section_title">Supervised classification problems</span></h4>
<p>AI shines in supervised classification problems. Machine vision.</p>
<p>Digit recognition is classification problem.</p>
<h4 id="classification-involving-sequence-or-time"><span class="section_number">19.10.7</span><span class="section_title">Classification involving sequence or time</span></h4>
<h3 id="idea-determining-the-number-of-parameters-in-line-fitting-by-measuring-effective-dimension-of-a-set-of-points"><span class="section_number">19.11</span><span class="section_title">&lt;2018-12-28&gt; Idea: determining the number of parameters in line fitting, by measuring &quot;effective dimension&quot; of a set of points</span></h3>
<p>The motivation: The effective dimension of a square should be 2. The effective dimension of a line should be 1. The effective dimension of a rectangle should be between 1 and 2.</p>
<p>Let <span class="math inline">\(P\)</span> be a set of points in <span class="math inline">\(n\)</span>-dimensional Euclidean space.</p>
<p>Fit the smallest hypercube that contains all that points.</p>
<p>Let <span class="math inline">\(x_1, \ldots, x_n\)</span> be the length of the sides of that hypercube.</p>
<p>Let <span class="math inline">\(M\)</span> be the length of the longest side of that hypercube. That is <span class="math inline">\(M = \max_i x_i\)</span>.</p>
<p>Then the effective dimension of the set <span class="math inline">\(P\)</span> is: <span class="math display">\[
dim(P)
= \frac{\sum_i x_i}{\max_i x_i}
= \frac{\text{the sum of all sides}}{\text{the longest side}}
\]</span></p>
<p>Example: A line in three-dimensional Euclidean space will have an effective dimension near 1.</p>
<p>We can use this to determine the number of parameters in line fitting (linear regression).</p>
<p>Unfortunately we don't know how to compute the minimum bounding hypercube quickly.<a href="#fn72" class="footnote-ref" id="fnref72"><sup>72</sup></a></p>
<p>Is this related to principal component analysis?</p>
<p>Pick n arbitrary orthogonal axes. Pick any point in P as origin. Find n-1 axial rotations that minimize the n-volume of the axis-aligned n-cube. Find the n rotation angles that minimize the n-volume of the n-cube. This is a convex optimization problem? This can be thought of as a sequence of n optimization problems. Every angle is in [0,pi/2).</p>
<h3 id="logic-language-and-approximation-theory"><span class="section_number">19.12</span><span class="section_title">&lt;2018-12-28&gt; Logic, language, and approximation theory</span></h3>
<p>The formula <span class="math inline">\(p \wedge q\)</span> <em>approximates</em> <span class="math inline">\(p \wedge q \wedge r\)</span>. The approximation error is 1 clause.</p>
<p>Let <span class="math inline">\(P(X) = a(X) \wedge b(X)\)</span> and <span class="math inline">\(Q(X) = a(X) \wedge b(X) \wedge c(X)\)</span>. The predicate <span class="math inline">\(P\)</span> approximates the predicate <span class="math inline">\(Q\)</span>. The approximation error is <span class="math inline">\( P - Q = \{ X ~|~ P(X) \wedge \neg Q(X) \} \)</span>.</p>
<p>Example: the concept &quot;bird&quot; approximates the concept &quot;penguin&quot;.</p>
<h3 id="functional-analysis-currying-and-partial-evaluation"><span class="section_number">19.13</span><span class="section_title">Functional analysis, currying, and partial evaluation</span></h3>
<p>Functional analysis should replace &quot;indexed family&quot; and &quot;linear form&quot; with &quot;currying&quot;?</p>
<h3 id="what-is-ml-scientist"><span class="section_number">19.14</span><span class="section_title">What is &quot;ML scientist&quot;?</span></h3>
<p>If a &quot;scientist&quot; is one who does &quot;science&quot;, then an &quot;ML scientist&quot; is one who does &quot;ML science&quot;.</p>
<p>Science consists of theoretical science and experimental science. Theoretical science creates falsifiable theories. Experimental science supports or falsifies such theories.</p>
<p>Thus, is &quot;ML science&quot; science?</p>
<h3 id="philosophy-of-mind"><span class="section_number">19.15</span><span class="section_title">Philosophy of mind?</span></h3>
<p>A brain is an organ for thinking. But a brain is also an organ for <em>learning</em>.</p>
<h2 id="more-math"><span class="section_number">20</span><span class="section_title">More math?</span></h2>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">20.1</span><span class="section_title"><a href="#mathexchange-vs-mathoverflow">MathExchange vs MathOverflow</a></span><span class="word_count">(13w~1m)</span></li>
<li><span class="section_number">20.2</span><span class="section_title"><a href="#automatic-differentiation">Automatic differentiation?</a></span><span class="word_count">(11w~1m)</span></li>
<li><span class="section_number">20.3</span><span class="section_title"><a href="#habituation">Habituation</a></span><span class="word_count">(53w~1m)</span></li>
<li><span class="section_number">20.4</span><span class="section_title"><a href="#human-as-a-feedback-system">Human as a feedback system?</a></span><span class="word_count">(414w~3m)</span></li>
<li><span class="section_number">20.5</span><span class="section_title"><a href="#trivia-correspondence-between-surjection-partition-and-equivalence">Trivia: Correspondence between surjection, partition, and equivalence</a></span><span class="word_count">(79w~1m)</span></li>
<li><span class="section_number">20.6</span><span class="section_title"><a href="#relating-areas-of-mathematics">Relating areas of mathematics</a></span><span class="word_count">(155w~1m)</span></li>
<li><span class="section_number">20.7</span><span class="section_title"><a href="#convexity-of-sets-and-functions">Convexity of sets and functions</a></span><span class="word_count">(81w~1m)</span></li>
</ul>
</div>
<h3 id="mathexchange-vs-mathoverflow"><span class="section_number">20.1</span><span class="section_title">MathExchange vs MathOverflow</span></h3>
<p><a href="https://math.stackexchange.com/">MathExchange</a> is &quot;almost everything goes&quot;. <a href="https://mathoverflow.net/">MathOverflow</a> is for &quot;research-level&quot; questions only.<a href="#fn73" class="footnote-ref" id="fnref73"><sup>73</sup></a></p>
<h3 id="automatic-differentiation"><span class="section_number">20.2</span><span class="section_title">Automatic differentiation?</span></h3>
<p>Justin Le, <a href="https://blog.jle.im/entry/purely-functional-typed-models-1.html">A Purely Functional Typed Approach to Trainable Models</a></p>
<h3 id="habituation"><span class="section_number">20.3</span><span class="section_title">Habituation</span></h3>
<ul>
<li>TODO s/adapt/habituate</li>
<li>Let <span class="math inline">\(f(t,x)\)</span> be the system's response intensity for stimulus intensity <span class="math inline">\(x\)</span> at time <span class="math inline">\(t\)</span>. We say the system is <em>habituating</em> between the time <span class="math inline">\(t_1\)</span> and <span class="math inline">\(t_2\)</span> iff <span class="math inline">\(f(t_1,x) &gt; f(t_2,x)\)</span> for all stimulus intensity <span class="math inline">\(x\)</span>.</li>
<li>&quot;The habituation process is a form of adaptive behavior (or neuroplasticity) that is classified as non-associative learning.&quot; <a href="https://en.wikipedia.org/wiki/Habituation">https://en.wikipedia.org/wiki/Habituation</a></li>
</ul>
<h3 id="human-as-a-feedback-system"><span class="section_number">20.4</span><span class="section_title">Human as a feedback system?</span></h3>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">20.4.1</span><span class="section_title"><a href="#human-behavior-as-a-special-case-of-the-general-feedback-equation">Human behavior as a special case of the general feedback equation</a></span><span class="word_count">(97w~1m)</span></li>
<li><span class="section_number">20.4.2</span><span class="section_title"><a href="#hardwiring-the-concept-of-time">Hardwiring the concept of time</a></span><span class="word_count">(20w~1m)</span></li>
<li><span class="section_number">20.4.3</span><span class="section_title"><a href="#a-brain-at-a-given-time-is-an-array-function.">A brain at a given time is an array function.</a></span><span class="word_count">(62w~1m)</span></li>
<li><span class="section_number">20.4.4</span><span class="section_title"><a href="#an-array-iself-is-also-a-function.">An array iself is also a function.</a></span><span class="word_count">(36w~1m)</span></li>
<li><span class="section_number">20.4.5</span><span class="section_title"><a href="#each-brain-has-a-maximand.">Each brain has a maximand.</a></span><span class="word_count">(31w~1m)</span></li>
<li><span class="section_number">20.4.6</span><span class="section_title"><a href="#consider-functions-of-length-one-arrays.">Consider functions of length-one arrays.</a></span><span class="word_count">(12w~1m)</span></li>
<li><span class="section_number">20.4.7</span><span class="section_title"><a href="#how-do-we-relate-vector-functions-and-intelligence">How do we relate vector functions and intelligence?</a></span><span class="word_count">(8w~1m)</span></li>
<li><span class="section_number">20.4.8</span><span class="section_title"><a href="#how-does-feedback-happen-in-the-brain">How does feedback happen in the brain?</a></span><span class="word_count">(49w~1m)</span></li>
<li><span class="section_number">20.4.9</span><span class="section_title"><a href="#the-brain-is-a-recurrence-relation.">The brain is a recurrence relation.</a></span><span class="word_count">(71w~1m)</span></li>
<li><span class="section_number">20.4.10</span><span class="section_title"><a href="#the-brain-evolved-from-simpler-nervous-systems.">The brain evolved from simpler nervous systems.</a></span><span class="word_count">(33w~1m)</span></li>
</ul>
</div>
<h4 id="human-behavior-as-a-special-case-of-the-general-feedback-equation"><span class="section_number">20.4.1</span><span class="section_title">Human behavior as a special case of the general feedback equation</span></h4>
<p>Let <span class="math inline">\(x ~ t\)</span> be the input vector at time <span class="math inline">\(t\)</span>; this vector has at least some billions of elements. The function <span class="math inline">\(x\)</span> represents the state of all sensors at a given time.</p>
<p>Let <span class="math inline">\(y ~ t\)</span> be the control vector at time <span class="math inline">\(t\)</span>; this vector is also big.</p>
<p>Let <span class="math inline">\(z~t\)</span> be the output vector at time <span class="math inline">\(t\)</span>.</p>
<p>The environment feeds back a part of the output to the input. Can the agent determine the response function?</p>
<p>The feedback forms memory, but see &quot;Memory without feedback in a neural network&quot;. <a href="https://www.ncbi.nlm.nih.gov/pubmed/19249281">https://www.ncbi.nlm.nih.gov/pubmed/19249281</a></p>
<h4 id="hardwiring-the-concept-of-time"><span class="section_number">20.4.2</span><span class="section_title">Hardwiring the concept of time</span></h4>
<p>We can transform a non-temporal behavior <span class="math inline">\(f~x = y\)</span> into a temporal behavior <span class="math inline">\(f&#39;~t = y&#39;\)</span>?</p>
<h4 id="a-brain-at-a-given-time-is-an-array-function."><span class="section_number">20.4.3</span><span class="section_title">A brain at a given time is an array function.</span></h4>
<p>A brain at a given time is an array function having type <span class="math inline">\(\Real^\infty \to \Real^\infty\)</span>. Each component of the input array is a signal from a sensor. Each component of the output array goes to an actuator.</p>
<p>Since the brain is finite, there must be infinitely many zeros in the input and output arrays.</p>
<h4 id="an-array-iself-is-also-a-function."><span class="section_number">20.4.4</span><span class="section_title">An array iself is also a function.</span></h4>
<p>An <span class="math inline">\(E\)</span>-array is a function having type <span class="math inline">\(\Nat \to E\)</span>. The input is an index. The output is the value of the component at that index. Subscripting denotes function application.</p>
<h4 id="each-brain-has-a-maximand."><span class="section_number">20.4.5</span><span class="section_title">Each brain has a maximand.</span></h4>
<p>Such maximand is a hidden function. The brain always tries to maximize the maximand.</p>
<p>A differential change in brain tries to increase the maximand. The brain follows gradient.</p>
<h4 id="consider-functions-of-length-one-arrays."><span class="section_number">20.4.6</span><span class="section_title">Consider functions of length-one arrays.</span></h4>
<p>Let <span class="math inline">\(h\)</span> be a differential change in brain.</p>
<h4 id="how-do-we-relate-vector-functions-and-intelligence"><span class="section_number">20.4.7</span><span class="section_title">How do we relate vector functions and intelligence?</span></h4>
<h4 id="how-does-feedback-happen-in-the-brain"><span class="section_number">20.4.8</span><span class="section_title">How does feedback happen in the brain?</span></h4>
<p>Feedback is due to environment and the physical laws. When we move our hand, we see it, because the light reflected by our hand now reaches our eyes.</p>
<p>The next input depends on the previous input. <span class="math display">\[\begin{aligned}
    y_k &amp;= b~x_k
    \\
    x_{k+1} &amp;= f~x_k~y_k\end{aligned}\]</span></p>
<h4 id="the-brain-is-a-recurrence-relation."><span class="section_number">20.4.9</span><span class="section_title">The brain is a recurrence relation.</span></h4>
<p>This pictures the brain as a parallel dataflow computer with clock period of a few microseconds.</p>
<p><a href="https://en.wikipedia.org/wiki/Dataflow_architecture">https://en.wikipedia.org/wiki/Dataflow_architecture</a></p>
<p>Let <span class="math inline">\(m\)</span> be memory, <span class="math inline">\(x\)</span> be senses, and <span class="math inline">\(y\)</span> be actuators. <span class="math display">\[\begin{aligned}
    m_{t+1} &amp;= f~x_t~m_t
    \\
    y_{t+1} &amp;= g~x_t~m_t\end{aligned}\]</span></p>
<p>There is also a version with implicit time. <span class="math display">\[\begin{aligned}
    m&#39; &amp;= f~x~m
    \\
    y&#39; &amp;= g~x~m\end{aligned}\]</span></p>
<p>There is also a continuous version. <span class="math display">\[\begin{aligned}
    m_{t+h} &amp;= h \cdot f~x_t~m_t
    \\
    y_{t+h} &amp;= h \cdot g~x_t~m_t\end{aligned}\]</span></p>
<h4 id="the-brain-evolved-from-simpler-nervous-systems."><span class="section_number">20.4.10</span><span class="section_title">The brain evolved from simpler nervous systems.</span></h4>
<p>Nervous systems are control systems.</p>
<p>Nervous systems must have provided some evolutionary benefit; otherwise natural selection would have phased them out.</p>
<p>Bacterial chemotaxis detects chemical concentration difference.</p>
<p>Nematode. Caenorhabditis elegans.</p>
<h3 id="trivia-correspondence-between-surjection-partition-and-equivalence"><span class="section_number">20.5</span><span class="section_title">Trivia: Correspondence between surjection, partition, and equivalence</span></h3>
<p>(We can skip this.)</p>
<p>To <em>partition</em> a set is to split that set into disjoint non-empty subsets.<a href="#fn74" class="footnote-ref" id="fnref74"><sup>74</sup></a> Each subset is called a <em>partition</em>.</p>
<p>The surjective function <span class="math inline">\(c : X \to N\)</span> corresponds to the partitions <span class="math inline">\(P_0, \ldots, P_n\)</span> where <span class="math inline">\(P_k = \{ x ~|~ c(x) = k \}\)</span> is the set of all things in class <span class="math inline">\(k\)</span>. Thus each set partitioning corresponds to a classification (a surjective function).</p>
<p>A partition also corresponds to an equivalence relation.</p>
<h3 id="relating-areas-of-mathematics"><span class="section_number">20.6</span><span class="section_title">Relating areas of mathematics</span></h3>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">20.6.1</span><span class="section_title"><a href="#counterexamples-in-books">&quot;Counterexamples in …&quot; books</a></span><span class="word_count">(19w~1m)</span></li>
<li><span class="section_number">20.6.2</span><span class="section_title"><a href="#approximation-theory">Approximation theory</a></span><span class="word_count">(64w~1m)</span></li>
<li><span class="section_number">20.6.3</span><span class="section_title"><a href="#computation-theory">Computation theory</a></span><span class="word_count">(71w~1m)</span></li>
</ul>
</div>
<h4 id="counterexamples-in-books"><span class="section_number">20.6.1</span><span class="section_title">&quot;Counterexamples in …&quot; books</span></h4>
<p>There is a series of books titled like &quot;Counterexamples in &lt;an area of mathematics&gt;&quot;. From <a href="https://math.stackexchange.com/questions/740/useful-examples-of-pathological-functions">https://math.stackexchange.com/questions/740/useful-examples-of-pathological-functions</a></p>
<h4 id="approximation-theory"><span class="section_number">20.6.2</span><span class="section_title">Approximation theory</span></h4>
<p>A binary classifier is an approximation of a Hilbert space.</p>
<p>Relationship with probability theory and statistics:</p>
<ul>
<li>2013 &quot;On Learnability, Complexity and Stability&quot; <a href="https://arxiv.org/abs/1303.5976">https://arxiv.org/abs/1303.5976</a></li>
</ul>
<p>Practically all machine learning cases deal with smooth functions. Every classification problem in the real world can be modeled by as a function <span class="math inline">\(f : R^\infty \to R\)</span>. Consider the case where <span class="math inline">\(R = [0,1]\)</span>. Continuous map from hyperplane <span class="math inline">\(R^n\)</span> to line <span class="math inline">\(R\)</span>.</p>
<h4 id="computation-theory"><span class="section_number">20.6.3</span><span class="section_title">Computation theory</span></h4>
<p>A discrete binary classifier is a <em>decider</em>.</p>
<p>Conjectures:</p>
<ul>
<li>Learnability is Kolmogorov complexity. Descriptive complexity theory: Learnability is shortest formula length.</li>
<li>If a thing is not <em>computable</em>, then it is not <em>learnable</em>.</li>
<li>Learnability is the probability that a uniform-distributionedly-random interpretation satisfies a formula.</li>
<li>A hypothesis space in PAC learning theory is a language in automata theory / formal language theory.</li>
<li><a href="https://en.wikipedia.org/wiki/Algorithmic_learning_theory">https://en.wikipedia.org/wiki/Algorithmic_learning_theory</a></li>
</ul>
<p>Some concepts from <a href="https://en.wikipedia.org/wiki/Computational_geometry">computational geometry</a> readily make classifiers:</p>
<ul>
<li>Nearest-<a href="https://en.wikipedia.org/wiki/Convex_hull">convex-hull</a> classification <span class="citation" data-cites="nalbantov2006nearest">[<a href="#ref-nalbantov2006nearest">37</a>]</span></li>
<li><a href="https://en.wikipedia.org/wiki/Voronoi_diagram">Voronoi-diagram</a> classification</li>
<li><a href="https://en.wikipedia.org/wiki/Sphere_packing">Sphere-packing</a> classification</li>
<li><a href="https://en.wikipedia.org/wiki/Point_location">https://en.wikipedia.org/wiki/Point_location</a></li>
<li><a href="https://en.wikipedia.org/wiki/Nearest_neighbour_search">https://en.wikipedia.org/wiki/Nearest_neighbour_search</a></li>
</ul>
<p>What is &quot;learning in the limit&quot;?</p>
<h3 id="convexity-of-sets-and-functions"><span class="section_number">20.7</span><span class="section_title">Convexity of sets and functions</span></h3>
<p>Convex is the shape of protruding fat belly.</p>
<p>Concave is the shape of pectus excavatum.</p>
<p>Let <span class="math inline">\(p, q \in S\)</span> be two points and <span class="math inline">\(L(p,q) \subseteq S\)</span> be the line segment from <span class="math inline">\(p\)</span> to <span class="math inline">\(q\)</span>. The set <span class="math inline">\(S\)</span> is <em>convex</em> iff <span class="math inline">\(\forall p,q \in S : L(p,q) \subseteq S\)</span>.</p>
<p>A function <span class="math inline">\(f : \Real \to \Real\)</span> is <em>convex</em> iff the area above its graph is a convex set. That area is <span class="math inline">\(\{(x,y) ~|~ x \in \Real, ~ y &gt; f(x)\}\)</span>.</p>
<h2 id="designing-intelligent-systems"><span class="section_number">21</span><span class="section_title">Designing intelligent systems</span></h2>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">21.1</span><span class="section_title"><a href="#where-do-we-begin">Where do we begin?</a></span><span class="word_count">(29w~1m)</span></li>
<li><span class="section_number">21.2</span><span class="section_title"><a href="#how-do-we-build-the-software">How do we build the software?</a></span><span class="word_count">(40w~1m)</span></li>
<li><span class="section_number">21.3</span><span class="section_title"><a href="#which-ml-algorithm-should-we-use">Which ML algorithm should we use?</a></span><span class="word_count">(154w~1m)</span></li>
<li><span class="section_number">21.4</span><span class="section_title"><a href="#how-do-we-build-the-hardware">How do we build the hardware?</a></span><span class="word_count">(134w~1m)</span></li>
<li><span class="section_number">21.5</span><span class="section_title"><a href="#what-is-the-smallest-thing-in-nature-that-can-learn">What is the smallest thing in nature that can learn?</a></span><span class="word_count">(19w~1m)</span></li>
<li><span class="section_number">21.6</span><span class="section_title"><a href="#designing-classifiers">Designing classifiers?</a></span><span class="word_count">(364w~2m)</span></li>
<li><span class="section_number">21.7</span><span class="section_title"><a href="#how-do-we-measure-the-performance-of-a-learning-algorithm">How do we measure the performance of a learning algorithm?</a></span><span class="word_count">(10w~1m)</span></li>
<li><span class="section_number">21.8</span><span class="section_title"><a href="#where-is-the-ai-bottleneck">Where is the AI bottleneck?</a></span><span class="word_count">(153w~1m)</span></li>
<li><span class="section_number">21.9</span><span class="section_title"><a href="#what-is-a-neural-network">What is a neural network?</a></span><span class="word_count">(213w~2m)</span></li>
<li><span class="section_number">21.10</span><span class="section_title"><a href="#how-might-we-build-a-seed-ai">How might we build a seed AI?</a></span><span class="word_count">(49w~1m)</span></li>
</ul>
</div>
<h3 id="where-do-we-begin"><span class="section_number">21.1</span><span class="section_title">Where do we begin?</span></h3>
<p>What should we do?</p>
<p>There is no requirement that the system be human-like. We should not be anthropocentric. We are only a local optimum in natural selection.</p>
<h3 id="how-do-we-build-the-software"><span class="section_number">21.2</span><span class="section_title">How do we build the software?</span></h3>
<p>&lt;2018-12-25&gt; I'm thinking of using Prolog, even for neural networks.</p>
<p>2018 &quot;One Big Net For Everything&quot;<a href="#fn75" class="footnote-ref" id="fnref75"><sup>75</sup></a></p>
<p>Are we stuck with uninterpretable deep neural networks? Will we be able to interpret neural networks? Will we find another architecture?</p>
<h3 id="which-ml-algorithm-should-we-use"><span class="section_number">21.3</span><span class="section_title">Which ML algorithm should we use?</span></h3>
<p>Why are there so many machine learning algorithms? &quot;The key to not getting lost in this huge space is to realize that it consists of combinations of just three components.&quot; <span class="citation" data-cites="domingos2012few">[<a href="#ref-domingos2012few">13</a>]</span> It is an useful map for navigating the ML algorithm jungle.</p>
<p>How do we categorize ML algorithms? What is the common thing?</p>
<ul>
<li>Online vs offline
<ul>
<li><a href="https://en.wikipedia.org/wiki/Online_machine_learning">Wikipedia: Online machine learning</a></li>
</ul></li>
<li>Discrete-time model vs continuous-time model
<ul>
<li>LTI (linear time-invariant) systems</li>
</ul></li>
<li>Assemble answers from these sources:
<ul>
<li><a href="https://en.wikipedia.org/wiki/Machine_learning#Approaches">Wikipedia: Machine learning, approaches</a></li>
<li><a href="https://en.wikipedia.org/wiki/Outline_of_machine_learning#Machine_learning_algorithms">Wikipedia: Outline of machine learning, algorithms</a></li>
<li><a href="https://en.wikipedia.org/wiki/Outline_of_machine_learning#Machine_learning_methods">Wikipedia: Outline of machine learning, methods</a></li>
<li><a href="https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/">A tour of machine learning algorithms</a></li>
<li><a href="https://towardsdatascience.com/types-of-machine-learning-algorithms-you-should-know-953a08248861">Types of machine learning algorithms you should know</a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/">Common machine learning algorithms</a></li>
</ul></li>
</ul>
<p>2018: &quot;So in summary forget RNN and variants. Use attention. Attention really is all you need!&quot;<a href="#fn76" class="footnote-ref" id="fnref76"><sup>76</sup></a> Current neural network research seems to be about approximating the human brain. But there is no reason why an intelligent system should have human-like brain.</p>
<p>There are too many ML algorithms. Has Pedro Domingos found the master algorithm yet?<span class="citation" data-cites="domingos2015master">[<a href="#ref-domingos2015master">14</a>]</span></p>
<h3 id="how-do-we-build-the-hardware"><span class="section_number">21.4</span><span class="section_title">How do we build the hardware?</span></h3>
<p>EcoBot is a robot that can feed itself<a href="#fn77" class="footnote-ref" id="fnref77"><sup>77</sup></a>. Can evolutionary robotics<a href="#fn78" class="footnote-ref" id="fnref78"><sup>78</sup></a> evolve robots in 50 years and not in billions of years it took the Universe to evolve humans?</p>
<p>There are too many cognitive architectures<a href="#fn79" class="footnote-ref" id="fnref79"><sup>79</sup></a>, just as there are too many learning algorithms.</p>
<p>Most computers in 2017 have the von Neumann architecture, which suffers from the von Neumann bottleneck (the limited transfer rate between CPU and RAM). This architecture fits programming, but it fits training less, and it does not fit learning. This architecture does not suit machines with billions of sensors. This architecture does not preclude intelligence but the bottleneck incurs a great penalty.</p>
<p>An array of FitzHugh-Nagumo cells? A FitzHugh-Nagumo cell is an electrical circuit implementing the FitzHugh-Nagumo model. FHN cells can be implemented in Field-programmable Analog Array (FPAA) <span class="citation" data-cites="CircuitFitzHughNagumo">[<a href="#ref-CircuitFitzHughNagumo">63</a>]</span>.</p>
<h3 id="what-is-the-smallest-thing-in-nature-that-can-learn"><span class="section_number">21.5</span><span class="section_title">What is the smallest thing in nature that can learn?</span></h3>
<p>Should we learn from nature? Protists may learn by habituation.<a href="#fn80" class="footnote-ref" id="fnref80"><sup>80</sup></a></p>
<h3 id="designing-classifiers"><span class="section_number">21.6</span><span class="section_title">Designing classifiers?</span></h3>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">21.6.1</span><span class="section_title"><a href="#classifiers">Classifiers?</a></span><span class="word_count">(205w~2m)</span></li>
<li><span class="section_number">21.6.2</span><span class="section_title"><a href="#nearest-something-classifier">Nearest-something classifier</a></span><span class="word_count">(103w~1m)</span></li>
<li><span class="section_number">21.6.3</span><span class="section_title"><a href="#what-mathematics">What mathematics??</a></span><span class="word_count">(11w~1m)</span></li>
<li><span class="section_number">21.6.4</span><span class="section_title"><a href="#mathematical-spaces">Mathematical spaces</a></span><span class="word_count">(47w~1m)</span></li>
</ul>
</div>
<h4 id="classifiers"><span class="section_number">21.6.1</span><span class="section_title">Classifiers?</span></h4>
<p>We assume that the classes are known. If the classes are not known, then the problem is called &quot;clustering&quot;.</p>
<p>Supervised learning. Training:</p>
<ul>
<li>A sample is a point. A class is a set of samples (points). A class's boundary is a polytope.</li>
<li>For each training class, construct a smallest polytope that bounds the class's samples. If the polytope is convex, good.</li>
</ul>
<p>Classes must not overlap/intersect.</p>
<p>We assume that clusters satisfy the cluster hypothesis<a href="#fn81" class="footnote-ref" id="fnref81"><sup>81</sup></a>.</p>
<p>Traditional classifiers have two phases: training and performance. They no longer learns when they perform. The alternative is called &quot;lifelong learning&quot; or &quot;continual learning&quot;<a href="#fn82" class="footnote-ref" id="fnref82"><sup>82</sup></a><a href="#fn83" class="footnote-ref" id="fnref83"><sup>83</sup></a></p>
<p>Given some examples of <span class="math inline">\(c\)</span>, approximate <span class="math inline">\(c\)</span>.</p>
<p>Inputs:</p>
<ul>
<li>Some <em>training pairs</em>: <span class="math inline">\(c&#39; \subset c\)</span>. Every class must be represented.</li>
</ul>
<p>Outputs:</p>
<ul>
<li>Estimate <span class="math inline">\(c\)</span>.</li>
</ul>
<p>The type of a <em>classifier</em> is <span class="math inline">\(a \to b\)</span> where <span class="math inline">\(b\)</span> is countable. Iff <span class="math inline">\(|b| = 2\)</span>, the classifier is <em>binary</em>. Iff <span class="math inline">\(|b|\)</span> is finite, the classifier is <em>multi-class</em>.</p>
<p>A <em>quasiclassifier</em> is an inhabitant of <span class="math inline">\(\Real^\infty \to \Real\)</span>. A <em>predicate</em> <span class="math inline">\(p\)</span> turns a quasiclassifier <span class="math inline">\(q\)</span> into a classifier <span class="math inline">\(c~x = p~(q~x)\)</span>.</p>
<p>A multiclassifier can be made from binary classifiers.</p>
<p>The <em>maximum-margin hyperplane</em> separating the lower training set <span class="math inline">\(L\)</span> and the upper training set <span class="math inline">\(U\)</span> is the hyperplane <span class="math inline">\(h\)</span> such that <span class="math inline">\(\forall a \in U : h~a &gt; 0\)</span>,  <span class="math inline">\(\forall b \in L : h~b &lt; 0\)</span>, and <span class="math inline">\(\dist~h~(U \cup L)\)</span> is maximal.</p>
<h4 id="nearest-something-classifier"><span class="section_number">21.6.2</span><span class="section_title">Nearest-something classifier</span></h4>
<p>Nearest-centroid classifier<a href="#fn84" class="footnote-ref" id="fnref84"><sup>84</sup></a></p>
<p>Nearest-cluster classifier<a href="#fn85" class="footnote-ref" id="fnref85"><sup>85</sup></a><a href="#fn86" class="footnote-ref" id="fnref86"><sup>86</sup></a></p>
<p>Cover, T.M., Hart, P.E.: Nearest neighbor pattern classification. IEEE Trans. Inform. Theory IT-13(1), 21–27 (1967)</p>
<p>This is mathematically principled. This does not &quot;just work&quot;. This works and we understand why it works.</p>
<p>Nearest convex hull classification<span class="citation" data-cites="nalbantov2006nearest">[<a href="#ref-nalbantov2006nearest">37</a>]</span>.</p>
<p>Performing:</p>
<ul>
<li>Find the convex hull is nearest to the input point.</li>
</ul>
<p>Explainability: It is simple to explain an NCHC's decision. It is not simple to explain a neural network's decision.</p>
<p>Why does it classify this as that? Because it is the closest cluster.</p>
<p>Geometric learning / analogizer / learning by constructing convex hull / classification by cluster-convex-hull-boundary learning; analogizer</p>
<p>Voronoi classifier?</p>
<p>Find out the cluster centers. Let the Voronoi diagram be the boundary.</p>
<h4 id="what-mathematics"><span class="section_number">21.6.3</span><span class="section_title">What mathematics??</span></h4>
<p>Can we apply Aitken's delta-squared process<a href="#fn87" class="footnote-ref" id="fnref87"><sup>87</sup></a><a href="#fn88" class="footnote-ref" id="fnref88"><sup>88</sup></a> to machine learning algorithms?</p>
<h4 id="mathematical-spaces"><span class="section_number">21.6.4</span><span class="section_title">Mathematical spaces</span></h4>
<ul>
<li>What is a metric?</li>
<li>What is a norm?</li>
<li>What is a measure?</li>
<li><a href="https://en.wikipedia.org/wiki/Space_(mathematics)#Three_taxonomic_ranks">https://en.wikipedia.org/wiki/Space_(mathematics)#Three_taxonomic_ranks</a></li>
<li><a href="https://en.wikipedia.org/wiki/Topological_space#Classification_of_topological_spaces">https://en.wikipedia.org/wiki/Topological_space#Classification_of_topological_spaces</a></li>
<li><a href="https://en.wikipedia.org/wiki/Functional_analysis">https://en.wikipedia.org/wiki/Functional_analysis</a>
<ul>
<li>What is a Hilbert space?</li>
<li>What is a Banach space?</li>
<li>What is a Sobolev space?</li>
<li>What is a measure?
<ul>
<li>What is a Lebesgue measure?
<ul>
<li>What is an Lp space?
<ul>
<li><a href="https://en.wikipedia.org/wiki/Lp_space#Lp_spaces">Wikipedia: Lp space</a></li>
<li>How is it pronounced?
<ul>
<li>&quot;Lebesgue space with <span class="math inline">\(p\)</span>-norm&quot;</li>
</ul></li>
</ul></li>
<li>What is a small lp space?</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h3 id="how-do-we-measure-the-performance-of-a-learning-algorithm"><span class="section_number">21.7</span><span class="section_title">How do we measure the performance of a learning algorithm?</span></h3>
<h3 id="where-is-the-ai-bottleneck"><span class="section_number">21.8</span><span class="section_title">Where is the AI bottleneck?</span></h3>
<p>What is preventing us from creating the AI? Where is the bottleneck: philosophy, science, or engineering? As of 2018 we are still stuck: machines have not replaced human secretaries, assistants, and researchers.</p>
<p>Is hardware not powerful enough? Some imply that hardware is not strong enough. Schmidhuber estimates that &quot;True AI&quot; needs machines 100,000 times as fast as machines were in 2017.<a href="#fn89" class="footnote-ref" id="fnref89"><sup>89</sup></a> Schmidhuber and Wikipedia<a href="#fn90" class="footnote-ref" id="fnref90"><sup>90</sup></a> imply that in 2018 machines were as intelligent as honey bees, by the number of synapses.</p>
<p>Is software not efficient enough? Is our knowledge not enough? Are we clueless? Are we doing the wrong experiments? There are inconclusive discussions<a href="#fn91" class="footnote-ref" id="fnref91"><sup>91</sup></a>.</p>
<p>Reading: 2012, &quot;Philosophy will be the key that unlocks artificial intelligence&quot;, David Deutsch, in The Guardian<a href="#fn92" class="footnote-ref" id="fnref92"><sup>92</sup></a>. That is an abridged version of the 2012 article &quot;Creative blocks&quot; in Aeon magazine<a href="#fn93" class="footnote-ref" id="fnref93"><sup>93</sup></a>.</p>
<p>Why has AI mastered chess, but not real life? Because chess search space is much smaller than real-life search space?</p>
<h3 id="what-is-a-neural-network"><span class="section_number">21.9</span><span class="section_title">What is a neural network?</span></h3>
<p>What is a neural network?</p>
<ul>
<li>A <em>neuron</em> is a function in <span class="math inline">\(\Real^\infty \to \Real\)</span>.</li>
<li>A <em>neural network</em> layer is a function in <span class="math inline">\(\Real^\infty \to \Real^\infty\)</span>.</li>
</ul>
<ul>
<li>What is statistical learning?</li>
<li>What is backpropagation, from functional analysis point of view?</li>
<li>Consider endofunctions of infinite-dimensional real tuple space. That is, consider <span class="math inline">\(f, g : \Real^\infty \to \Real^\infty\)</span>.
<ul>
<li>What is the distance between them?</li>
</ul></li>
<li>Reductionistically, a brain can be thought of as a function in <span class="math inline">\(\Real \to \Real^\infty \to \Real^\infty\)</span>.
<ul>
<li>The first parameter is time.</li>
<li>The second parameter is the sensor signals.</li>
<li>The output of the function is the actuator signals.</li>
<li>Can we model a brain by such <a href="https://en.wikipedia.org/wiki/Functional_differential_equation">functional differential equation</a> involving <a href="https://en.wikipedia.org/wiki/Functional_derivative">functional derivative</a>s?</li>
<li><span class="math inline">\(\norm{f(t+h,x) - f(t,x)} = h \cdot g(t,x)\)</span></li>
<li><span class="math inline">\(\norm{f(t+h) - f(t)} = h \cdot g(t)\)</span></li>
<li>It seems wrong. Abandon this path. See below.</li>
</ul></li>
<li>We model the input as a function <span class="math inline">\(x : \Real \to \Real^n\)</span>.</li>
<li>We model the output as a function <span class="math inline">\(y : \Real \to \Real^n\)</span>.
<ul>
<li><span class="math inline">\(\norm{y(t+h) - y(t)} = h \cdot g(t)\)</span></li>
<li><span class="math inline">\(y(t+h) - y(t) = h \cdot (dy)(t)\)</span></li>
<li><span class="math inline">\(\norm{(dy)(t)} = g(t)\)</span>
<ul>
<li>There are infinitely many <span class="math inline">\(dy\)</span> that satisfies that. Which one should we choose?</li>
</ul></li>
<li>If <span class="math inline">\(y : \Real \to \Real^n\)</span> then <span class="math inline">\(dy : \Real \to \Real^n\)</span>.</li>
</ul></li>
<li>A control system snapshot is a function in <span class="math inline">\(\Real^\infty \to \Real^\infty\)</span>.</li>
<li>A control system is a function in <span class="math inline">\(\Real \to \Real^\infty \to \Real^\infty\)</span>.</li>
<li>How does <span class="math inline">\(F\)</span> have memory if <span class="math inline">\(F(t) = \int_0^t f(x) ~ dx\)</span>?</li>
</ul>
<h3 id="how-might-we-build-a-seed-ai"><span class="section_number">21.10</span><span class="section_title">How might we build a seed AI?</span></h3>
<ul>
<li>Use off-the-shelf computers.</li>
<li>Use supercomputers.</li>
<li>Use clusters.</li>
<li>Use computers over the Internet.</li>
<li>Raise an AI like raising a child.</li>
<li>Evolve a system. Create an environment with selection pressure. Run it long enough.
<ul>
<li><a href="https://en.wikipedia.org/wiki/Evolutionary_robotics">WP: Evolutionary robotics</a></li>
<li><a href="https://en.wikipedia.org/wiki/Evolutionary_computation">WP: Evolutionary computation</a></li>
</ul></li>
<li>What is TensorFlow? Keras? CNTK? Theano?
<ul>
<li>The building blocks of AI? Standardized AI components?</li>
</ul></li>
</ul>
<h2 id="building-intelligent-systems"><span class="section_number">22</span><span class="section_title">Building intelligent systems</span></h2>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">22.1</span><span class="section_title"><a href="#should-i-read-these">Should I read these?</a></span><span class="word_count">(12w~1m)</span></li>
<li><span class="section_number">22.2</span><span class="section_title"><a href="#what-is-the-relationship-between-ml-and-statistical-modeling">What is the relationship between ML and statistical modeling?</a></span><span class="word_count">(9w~1m)</span></li>
<li><span class="section_number">22.3</span><span class="section_title"><a href="#doing-the-last-thing-we-will-ever-need-to-do">Doing the last thing we will ever need to do</a></span><span class="word_count">(186w~1m)</span></li>
<li><span class="section_number">22.4</span><span class="section_title"><a href="#machine-learning-sometimes-needs-philosophy">Machine learning sometimes needs philosophy</a></span><span class="word_count">(15w~1m)</span></li>
<li><span class="section_number">22.5</span><span class="section_title"><a href="#automating-reasoning">Automating reasoning?</a></span><span class="word_count">(10w~1m)</span></li>
<li><span class="section_number">22.6</span><span class="section_title"><a href="#what-are-some-tools-that-i-can-use-to-make-my-computer-learn">What are some tools that I can use to make my computer learn?</a></span><span class="word_count">(17w~1m)</span></li>
<li><span class="section_number">22.7</span><span class="section_title"><a href="#which-ai-architecture-has-won-lots-of-ai-contests-lately">Which AI architecture has won lots of AI contests lately?</a></span><span class="word_count">(47w~1m)</span></li>
<li><span class="section_number">22.8</span><span class="section_title"><a href="#analogizers-recommender-systems-matrices">Analogizers, recommender systems, matrices</a></span><span class="word_count">(4w~1m)</span></li>
<li><span class="section_number">22.9</span><span class="section_title"><a href="#designing-a-humanoid">Designing a humanoid?</a></span><span class="word_count">(111w~1m)</span></li>
<li><span class="section_number">22.10</span><span class="section_title"><a href="#ai-approaches">AI approaches</a></span><span class="word_count">(63w~1m)</span></li>
</ul>
</div>
<h3 id="should-i-read-these"><span class="section_number">22.1</span><span class="section_title">Should I read these?</span></h3>
<ul>
<li><a href="https://medium.com/machine-learning-world/learning-path-for-machine-learning-engineer-a7d5dc9de4a4">How To Become A Machine Learning Engineer: Learning Path</a></li>
<li><a href="https://dzone.com/guides/artificial-intelligence-machine-learning-and-predi">https://dzone.com/guides/artificial-intelligence-machine-learning-and-predi</a></li>
</ul>
<h3 id="what-is-the-relationship-between-ml-and-statistical-modeling"><span class="section_number">22.2</span><span class="section_title">What is the relationship between ML and statistical modeling?</span></h3>
<h3 id="doing-the-last-thing-we-will-ever-need-to-do"><span class="section_number">22.3</span><span class="section_title">Doing the last thing we will ever need to do</span></h3>
<p>In his website<a href="#fn94" class="footnote-ref" id="fnref94"><sup>94</sup></a>, Jürgen Schmidhuber writes that he wants to build something smarter than him and then retire.</p>
<p>I want the same thing.</p>
<p>Schmidhuber's website floods the reader with too much content. It is hard for an outsider to tell whether he is genius or crazy. But he has lots of credentials.</p>
<p>Schmidhuber gave a Reddit mass-interview<a href="#fn95" class="footnote-ref" id="fnref95"><sup>95</sup></a>.</p>
<p>Schmidhuber has always been an optimist.<a href="#fn96" class="footnote-ref" id="fnref96"><sup>96</sup></a></p>
<p>Isn't Jacques Pitrat's CAIA similar in spirit to what Jürgen Schmidhuber wants? Unfortunately Jacques Pitrat's blog<a href="#fn97" class="footnote-ref" id="fnref97"><sup>97</sup></a> is even harder to understand than Schmidhuber's website.</p>
<p>Is Kyndi closest to what we want? &quot;Kyndi serves as a tireless digital assistant, identifying the documents and passages that require human judgment.&quot;<a href="#fn98" class="footnote-ref" id="fnref98"><sup>98</sup></a></p>
<p>Kyndi uses Prolog.</p>
<p>I need something similar to Kyndi but able to generate interesting questions for itself to answer. I want it to read journal articles and conference proceedings, understand them, and summarize them for me.</p>
<p>Concepts:</p>
<ul>
<li>artificial general intelligence</li>
<li>seed AI</li>
</ul>
<p>We need cooperation, not competititon. Google, DeepMind, Facebook, Tesla, Amazon, OpenAI, Uber, Waymo, and other companies and organizations globally waste massive effort reinventing each other's AI capabilities.</p>
<p>Abbreviations:</p>
<ul>
<li>AI: Artificial Intelligence</li>
<li>AGI: Artificial General Intelligence</li>
<li>ML: Machine Learning</li>
<li>COLT: Computational Learning Theory</li>
</ul>
<h3 id="machine-learning-sometimes-needs-philosophy"><span class="section_number">22.4</span><span class="section_title">Machine learning sometimes needs philosophy</span></h3>
<p>It is <em>sometimes</em> important to explain why a prediction works. <a href="http://blogs.cornell.edu/modelmeanings/2013/12/08/ml-philosophy-and-does-interpretation-matter/">http://blogs.cornell.edu/modelmeanings/2013/12/08/ml-philosophy-and-does-interpretation-matter/</a></p>
<h3 id="automating-reasoning"><span class="section_number">22.5</span><span class="section_title">Automating reasoning?</span></h3>
<p>What is reasoning? How do we automate reasoning? Prolog?</p>
<h3 id="what-are-some-tools-that-i-can-use-to-make-my-computer-learn"><span class="section_number">22.6</span><span class="section_title">What are some tools that I can use to make my computer learn?</span></h3>
<ul>
<li>Google TensorFlow?</li>
<li>Does OpenAI have tools?</li>
<li>Facebook?</li>
<li>Keras?</li>
</ul>
<h3 id="which-ai-architecture-has-won-lots-of-ai-contests-lately"><span class="section_number">22.7</span><span class="section_title">Which AI architecture has won lots of AI contests lately?</span></h3>
<ul>
<li>Is it LSTM RNN?</li>
<li>What is LSTM RNN?
<ul>
<li>&quot;long short-term memory recurrent neural network&quot;</li>
<li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></li>
<li>&quot;The expression <em>long short-term</em> refers to the fact that LSTM is a model for the <em>short-term memory</em> which can last for a <em>long</em> period of time.&quot; (<a href="https://en.wikipedia.org/wiki/Long_short-term_memory">Wikipedia</a>)</li>
</ul></li>
</ul>
<h3 id="analogizers-recommender-systems-matrices"><span class="section_number">22.8</span><span class="section_title">Analogizers, recommender systems, matrices</span></h3>
<ul>
<li><a href="https://medium.com/s/story/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe">https://medium.com/s/story/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe</a></li>
</ul>
<h3 id="designing-a-humanoid"><span class="section_number">22.9</span><span class="section_title">Designing a humanoid?</span></h3>
<p>A humanoid is a human-shaped robot.</p>
<p>There are several choices: Make a machine that resembles human, Make a cyborg (a human-machine hybrid with more human part), or Mind upload.</p>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">22.9.1</span><span class="section_title"><a href="#power-plant">Power plant</a></span><span class="word_count">(57w~1m)</span></li>
<li><span class="section_number">22.9.2</span><span class="section_title"><a href="#sensors">Sensors</a></span><span class="word_count">(26w~1m)</span></li>
</ul>
</div>
<h4 id="power-plant"><span class="section_number">22.9.1</span><span class="section_title">Power plant</span></h4>
<p>It needs power plant with high power-to-mass and power-to-volume ratio for long-time low-power and short-time burst scenario. High-density sugar biobattery <span class="citation" data-cites="zhu2014high">[<a href="#ref-zhu2014high">64</a>]</span>. A microbial fuel cell capable of converting glucose to electricity at high rate and efficiency <span class="citation" data-cites="rabaey2003microbial">[<a href="#ref-rabaey2003microbial">41</a>]</span>. Sugar beats lithium ion.</p>
<p>Distributed processing, distributed energy generation.</p>
<p>Citric acid cycle. Oxidative phosphorylation.</p>
<p>Biomachine hybrid. A mixture of microbes and machine.</p>
<h4 id="sensors"><span class="section_number">22.9.2</span><span class="section_title">Sensors</span></h4>
<p>Billions of sensors. Light, sound, heat, itch, touch, gravity.</p>
<p>A strong enough brain.</p>
<p>How will it sustain itself?</p>
<p>How will it sense the world?</p>
<p>How will it manipulate the world?</p>
<h3 id="ai-approaches"><span class="section_number">22.10</span><span class="section_title">AI approaches</span></h3>
<ul>
<li>logic, symbolism</li>
<li>biology, connectionism</li>
<li>probabilistic logic programming</li>
</ul>
<p>What's trending in 2018??</p>
<ul>
<li>deep learning (DL)</li>
<li>generative adversarial network (GAN)</li>
<li>long short-term memory (LSTM)</li>
</ul>
<p>There are two ways to make an &quot;infinite-layer&quot; neural network:</p>
<ul>
<li>recurrent neural network (RNN), similar to IIR (infinite-impulse-response) filter in control theory</li>
<li>neural ordinary differential equations (NODE), similar to Riemann summation in calculus</li>
</ul>
<p>How many AI approaches are there? <a href="https://en.wikipedia.org/wiki/Portal:Artificial_intelligence">WP AI Portal</a> lists 4 approaches. Pedro Domingos lists 5 &quot;tribes&quot;.</p>
<h2 id="meta"><span class="section_number">23</span><span class="section_title">Meta</span></h2>
<p>This is growing area. Mature contents move out.</p>
<p>Editing notes:</p>
<ul>
<li>Sections with superfluous question marks should be rewritten.</li>
<li>We should not use footnotes for references?<a href="#fn99" class="footnote-ref" id="fnref99"><sup>99</sup></a></li>
<li>The writing must still be usable even if all footnotes are removed.</li>
</ul>
<h2 id="intelligence-is-self-defeating"><span class="section_number">24</span><span class="section_title">Intelligence is self-defeating?</span></h2>
<p>Intelligence is self-defeating. An intelligent being eventually realizes that it has no reason to exist, that it does not consent to its own existence, that there should have been nothing instead of anything.</p>
<h2 id="self-modifying-code"><span class="section_number">25</span><span class="section_title">Self-modifying code?</span></h2>
<p><a href="https://en.wikipedia.org/wiki/Evolutionary_algorithm">https://en.wikipedia.org/wiki/Evolutionary_algorithm</a> genetic algorithm model is related to what? Genetic algorithms in self modifying code Genetic algorithms in program space Gradient descent in program space, derivative of program (lambda calculus?) Schmidhuber self-modification? <a href="https://en.wikipedia.org/wiki/Self-modifying_code">https://en.wikipedia.org/wiki/Self-modifying_code</a> <a href="https://www.reddit.com/r/artificial/comments/7gl635/is_selfmodifying_code_the_best_option_for/">https://www.reddit.com/r/artificial/comments/7gl635/is_selfmodifying_code_the_best_option_for/</a> <a href="https://en.wikipedia.org/wiki/Test_functions_for_optimization#Test_functions_for_constrained_optimization">https://en.wikipedia.org/wiki/Test_functions_for_optimization#Test_functions_for_constrained_optimization</a></p>
<p>Theory of self-modifying code?</p>
<h2 id="what-2"><span class="section_number">26</span><span class="section_title">What</span></h2>
<p>What is executive function?</p>
<p>What is this <a href="https://mitpress.mit.edu/books/advanced-structured-prediction">https://mitpress.mit.edu/books/advanced-structured-prediction</a></p>
<p>&quot;similar project, but for Swi-Prolog (a statistical NLP module - it's my own initiative and about a month away from sharing with the world&quot; <a href="https://news.ycombinator.com/item?id=14409595">https://news.ycombinator.com/item?id=14409595</a></p>
<p><a href="http://jtonedm.com/2011/04/11/predictive-models-are-not-statistical-models/">http://jtonedm.com/2011/04/11/predictive-models-are-not-statistical-models/</a></p>
<p>&quot;Where to find the latest Machine Learning papers? A list of Open Access journals and directories&quot; <a href="https://medium.com/@i.oleks/where-to-find-the-latest-machine-learning-papers-f6633168629">https://medium.com/@i.oleks/where-to-find-the-latest-machine-learning-papers-f6633168629</a></p>
<p>READ <a href="http://news.mit.edu/2010/ai-unification">http://news.mit.edu/2010/ai-unification</a></p>
<p><a href="https://en.wikipedia.org/wiki/OpenCog">https://en.wikipedia.org/wiki/OpenCog</a> Is agiri legit?</p>
<p><a href="https://en.wikipedia.org/wiki/Partnership_on_AI">https://en.wikipedia.org/wiki/Partnership_on_AI</a></p>
<p><a href="https://www.pt-ai.org">https://www.pt-ai.org</a></p>
<h2 id="karl-friston-free-energy-principle"><span class="section_number">27</span><span class="section_title">Karl Friston free energy principle?</span></h2>
<p><a href="https://www.psychologytoday.com/us/blog/the-future-brain/201810/new-theory-intelligence-may-disrupt-ai-and-neuroscience">https://www.psychologytoday.com/us/blog/the-future-brain/201810/new-theory-intelligence-may-disrupt-ai-and-neuroscience</a></p>
<h2 id="causality-machine"><span class="section_number">28</span><span class="section_title">Causality Machine?</span></h2>
<p>How do we make a machine understand causality?</p>
<p>If an agent observes two events, then the agent believes that the first event causes the second event, with confidence inversely proportional to the time interval between those events.</p>
<p>How do we make machines understand the principle of locality?</p>
<p>How does the brain understand causation/causality?</p>
<p>&quot;Time as a guide to cause&quot; <span class="citation" data-cites="lagnado2006time">[<a href="#ref-lagnado2006time">28</a>]</span><a href="#fn100" class="footnote-ref" id="fnref100"><sup>100</sup></a></p>
<h2 id="inquisitive-machines"><span class="section_number">29</span><span class="section_title">Inquisitive machines</span></h2>
<p>How do we make machines inquisitive/curious?</p>
<p>How do we make machines generate/ask questions?</p>
<h2 id="bibliography" class="unnumbered"><span class="section_number">30</span><span class="section_title">Bibliography</span></h2>
<div id="refs" class="references">
<div id="ref-AshbyBrain">
<p>[1] Ashby, W.R. 1954. <em>Design for a brain</em>. Wiley.</p>
</div>
<div id="ref-BattleThree">
<p>[2] Battle, S. 2015. A mobile homeostat with three degrees of freedom. <em>IMA conference on mathematics of robotics</em> (St Anne’s College, University of Oxford, UK, 2015).</p>
</div>
<div id="ref-BattleHom">
<p>[3] Battle, S. 2014. Ashby’s mobile homeostat. (2014), 110–123.</p>
</div>
<div id="ref-DeepArch">
<p>[4] Bengio, Y. <em>Learning deep architectures for AI</em>. Technical Report #1312.</p>
</div>
<div id="ref-RepLearn">
<p>[5] Bengio, Y. et al. Representation learning: A review and new perspectives.</p>
</div>
<div id="ref-biran2017explanation">
<p>[6] Biran, O. and Cotton, C. 2017. Explanation and justification in machine learning: A survey. <em>IJCAI-17 workshop on explainable ai (xai)</em> (2017), 8. url: &lt;<a href="https://pdfs.semanticscholar.org/02e2/e79a77d8aabc1af1900ac80ceebac20abde4.pdf">https://pdfs.semanticscholar.org/02e2/e79a77d8aabc1af1900ac80ceebac20abde4.pdf</a>&gt;.</p>
</div>
<div id="ref-boring1923intelligence">
<p>[7] Boring, E.G. 1923. Intelligence as the tests test it. <em>New Republic</em>. (1923), 35–37. url: &lt;<a href="https://brocku.ca/MeadProject/sup/Boring_1923.html">https://brocku.ca/MeadProject/sup/Boring_1923.html</a>&gt;.</p>
</div>
<div id="ref-sep-artificial-intelligence">
<p>[8] Bringsjord, S. and Govindarajulu, N.S. 2018. Artificial intelligence. <em>The stanford encyclopedia of philosophy</em>. E.N. Zalta, ed. <a href="https://plato.stanford.edu/archives/fall2018/entries/artificial-intelligence/">https://plato.stanford.edu/archives/fall2018/entries/artificial-intelligence/</a>; Metaphysics Research Lab, Stanford University.</p>
</div>
<div id="ref-cohen1987parsing">
<p>[9] Cohen, J. and Hickey, T.J. 1987. Parsing and compiling using prolog. <em>ACM Transactions on Programming Languages and Systems (TOPLAS)</em>. 9, 2 (1987), 125–163. url: &lt;<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.9739&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.9739&amp;rep=rep1&amp;type=pdf</a>&gt;.</p>
</div>
<div id="ref-cucker2007learning">
<p>[10] Cucker, F. and Zhou, D.X. 2007. <em>Learning theory: An approximation theory viewpoint</em>. Cambridge University Press.</p>
</div>
<div id="ref-cybenko1989approximation">
<p>[11] Cybenko, G. 1989. Approximation by superpositions of a sigmoidal function. <em>Mathematics of control, signals and systems</em>. 2, 4 (1989), 303–314. url: &lt;<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.441.7873&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.441.7873&amp;rep=rep1&amp;type=pdf</a>&gt;.</p>
</div>
<div id="ref-dietterich2015computational">
<p>[12] Dietterich, T. et al. 2015. Computational learning theory. (2015).</p>
</div>
<div id="ref-domingos2012few">
<p>[13] Domingos, P. 2012. A few useful things to know about machine learning. <em>Communications of the ACM</em>. 55, 10 (2012), 78–87. url: &lt;<a href="https://www.centurion.link/w/_media/programming/a_few_useful_things_to_know_about_machine_learning.pdf">https://www.centurion.link/w/_media/programming/a_few_useful_things_to_know_about_machine_learning.pdf</a>&gt;.</p>
</div>
<div id="ref-domingos2015master">
<p>[14] Domingos, P. 2015. <em>The master algorithm: How the quest for the ultimate learning machine will remake our world</em>. Basic Books.</p>
</div>
<div id="ref-friston2010free">
<p>[15] Friston, K. 2010. The free-energy principle: A unified brain theory? <em>Nature Reviews Neuroscience</em>. 11, 2 (2010), 127–138.</p>
</div>
<div id="ref-friston2006free">
<p>[16] Friston, K. et al. 2006. A free energy principle for the brain. <em>Journal of Physiology-Paris</em>. 100, 1 (2006), 70–87.</p>
</div>
<div id="ref-GacsVitanyiSolomonoff">
<p>[17] Gács, P. and Vitányi, P.M.B. 2011. Raymond J. Solomonoff 1926–2009. <em>IEEE Information Theory Society Newsletter</em>. 61, 1 (2011), 11–16.</p>
</div>
<div id="ref-geffner2018model">
<p>[18] Geffner, H. 2018. Model-free, model-based, and general intelligence. <em>Proceedings of the twenty-seventh international joint conference on artificial intelligence, IJCAI-18</em> (Jul. 2018), 10–17. url: &lt;<a href="https://doi.org/10.24963/ijcai.2018/2">https://doi.org/10.24963/ijcai.2018/2</a>&gt;.</p>
</div>
<div id="ref-Organ">
<p>[19] Glushko, R.J. ed. 2013. <em>The discipline of organizing</em>. MIT Press.</p>
</div>
<div id="ref-GoertzelAgi">
<p>[20] Goertzel, B. 2015. Artificial general intelligence. <em>Scholarpedia</em>. 10, 11 (2015), 31847.</p>
</div>
<div id="ref-DeepLearning">
<p>[21] Goodfellow, I. et al. 2016. <em>Deep learning</em>. MIT Press.</p>
</div>
<div id="ref-AlgoInfTh">
<p>[22] Hutter, M. 2007. Algorithmic information theory. <em>Scholarpedia</em>. 2, 3 (2007), 2519.</p>
</div>
<div id="ref-hutter2004universal">
<p>[23] Hutter, M. 2004. <em>Universal artificial intelligence: Sequential decisions based on algorithmic probability</em>. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-izbicki2013hlearn">
<p>[24] Izbicki, M. 2013. HLearn: a machine learning library for Haskell. <em>Proceedings of the fourteenth symposium on trends in functional programming, brigham young university, utah</em> (2013).</p>
</div>
<div id="ref-jordan2015machine">
<p>[25] Jordan, M.I. and Mitchell, T.M. 2015. Machine learning: Trends, perspectives, and prospects. <em>Science</em>. 349, 6245 (2015), 255–260. url: &lt;<a href="http://www.cs.cmu.edu/~tom/pubs/Science-ML-2015.pdf">http://www.cs.cmu.edu/~tom/pubs/Science-ML-2015.pdf</a>&gt;.</p>
</div>
<div id="ref-kearns1994introduction">
<p>[26] Kearns, M.J. and Vazirani, U.V. 1994. <em>An introduction to computational learning theory</em>. MIT press.</p>
</div>
<div id="ref-khavinson1997best">
<p>[27] Khavinson, S.Y. 1997. <em>Best approximation by linear superpositions (approximate nomography)</em>. American Mathematical Soc.</p>
</div>
<div id="ref-lagnado2006time">
<p>[28] Lagnado, D.A. and Sloman, S.A. 2006. Time as a guide to cause. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>. 32, 3 (2006), 451. url: &lt;<a href="https://www.ucl.ac.uk/lagnado-lab/publications/lagnado/Lagnado_time_%20as_guide_to_cause.pdf">https://www.ucl.ac.uk/lagnado-lab/publications/lagnado/Lagnado_time_%20as_guide_to_cause.pdf</a>&gt;.</p>
</div>
<div id="ref-LeggPhd">
<p>[29] Legg, S. 2008. <em>Machine super intelligence</em>. University of Lugano.</p>
</div>
<div id="ref-Legg2007Collection">
<p>[30] Legg, S. and Hutter, M. 2007. A collection of definitions of intelligence. <em>Frontiers in Artificial Intelligence and applications</em>. 157, (2007), 17.</p>
</div>
<div id="ref-LeggHutterFormal">
<p>[31] Legg, S. and Hutter, M. 2006. A formal measure of machine intelligence. <em>Proc. 15th annual machine learning conference of belgium and the netherlands (benelearn 2006)</em> (2006), 73–80.</p>
</div>
<div id="ref-DefineMachIntel">
<p>[32] Legg, S. and Hutter, M. 2007. Universal intelligence: A definition of machine intelligence. (2007).</p>
</div>
<div id="ref-LiangCs221">
<p>[33] Liang, P. 2016. Lecture notes in Stanford University CS221: Artificial Intelligence: Principles and Techniques.</p>
</div>
<div id="ref-SystemManage">
<p>[34] Mele, C. et al. 2010. A brief review of systems theories and their managerial applications. <em>Service Science</em>. 2, 1-2 (2010), 126–135. DOI:<a href="https://doi.org/10.1287/serv.2.1\_2.126">https://doi.org/10.1287/serv.2.1\_2.126</a>. url: &lt;<a href="http://dx.doi.org/10.1287/serv.2.1_2.126">http://dx.doi.org/10.1287/serv.2.1_2.126</a>&gt;.</p>
</div>
<div id="ref-mohri2018foundations">
<p>[35] Mohri, M. et al. 2018. <em>Foundations of machine learning</em>. MIT press.</p>
</div>
<div id="ref-Topology">
<p>[36] Morris, S.A. 2016. <em>Topology without tears</em>.</p>
</div>
<div id="ref-nalbantov2006nearest">
<p>[37] Nalbantov, G. et al. 2006. <em>Nearest convex hull classification</em>. url: &lt;<a href="https://pdfs.semanticscholar.org/a833/81e279fa548aca034f310fff6385c3d6b809.pdf">https://pdfs.semanticscholar.org/a833/81e279fa548aca034f310fff6385c3d6b809.pdf</a>&gt;.</p>
</div>
<div id="ref-negnevitsky2005artificial">
<p>[38] Negnevitsky, M. 2005. <em>Artificial intelligence: A guide to intelligent systems</em>. Pearson Education.</p>
</div>
<div id="ref-NilsLogicAi">
<p>[39] Nilsson, N.J. 1991. Logic and artificial intelligence. <em>Artificial Intelligence</em>. 47, 1-3 (Feb. 1991), 31–56. DOI:<a href="https://doi.org/10.1016/0004-3702(91)90049-P">https://doi.org/10.1016/0004-3702(91)90049-P</a>. url: &lt;<a href="http://dx.doi.org/10.1016/0004-3702(91)90049-P">http://dx.doi.org/10.1016/0004-3702(91)90049-P</a>&gt;.</p>
</div>
<div id="ref-PickeringCyber">
<p>[40] Pickering, A. 2010. <em>The cybernetic brain: Sketches of another future</em>. University of Chicago Press.</p>
</div>
<div id="ref-rabaey2003microbial">
<p>[41] Rabaey, K. et al. 2003. A microbial fuel cell capable of converting glucose to electricity at high rate and efficiency. <em>Biotechnology letters</em>. 25, 18 (2003), 1531–1535.</p>
</div>
<div id="ref-rigollet2015ocw">
<p>[42] Rigollet, P. 18.657 Mathematics of Machine Learning.</p>
</div>
<div id="ref-rudin1973functional">
<p>[43] Rudin, W. 1973. Functional analysis, mcgraw-hill series in higher mathematics. (1973).</p>
</div>
<div id="ref-russell2016artificial">
<p>[44] Russell, S.J. and Norvig, P. 2016. <em>Artificial intelligence: A modern approach</em>. Malaysia; Pearson Education Limited,</p>
</div>
<div id="ref-shour2018defining">
<p>[45] Shour, R. 2018. Defining intelligence. (2018). url: &lt;<a href="https://www.researchgate.net/publication/323203054_Defining_intelligence">https://www.researchgate.net/publication/323203054_Defining_intelligence</a>&gt;.</p>
</div>
<div id="ref-SlomanTuringIrrelevance">
<p>[46] Sloman, A. 2002. <em>The irrelevance of turing machines to artificial intelligence</em>. The MIT Press, Cambridge, Mass.</p>
</div>
<div id="ref-WdsIntelSlide">
<p>[47] Smith, W.D. 2006. Mathematical definition of “intelligence”, after mathematical definition of “intelligence” (and consequences). (2006).</p>
</div>
<div id="ref-WdsIntel">
<p>[48] Smith, W.D. 2006. Mathematical definition of “intelligence” (and consequences). (2006).</p>
</div>
<div id="ref-solomonoff1996does">
<p>[49] Solomonoff, R. 1996. Does algorithmic probability solve the problem of induction. <em>Oxbridge Research, POB</em>. 391887, (1996). url: &lt;<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.70.1572&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.70.1572&amp;rep=rep1&amp;type=pdf</a>&gt;.</p>
</div>
<div id="ref-SolAlpProb2011">
<p>[50] Solomonoff, R.J. 2011. Algorithmic probability – its discovery – its properties and application to strong AI. <em>Randomness through computation: Some answers, more questions</em>. H. Zenil, ed. World Scientific Publishing Company. 1–23.</p>
</div>
<div id="ref-GodelMachImpl">
<p>[51] Steunebrink, B.R. and Schmidhuber, J. Towards an actual Gödel machine implementation: a lesson in self-reflective systems.</p>
</div>
<div id="ref-sep-epistemology">
<p>[52] Steup, M. 2018. Epistemology. <em>The stanford encyclopedia of philosophy</em>. E.N. Zalta, ed. <a href="https://plato.stanford.edu/archives/win2018/entries/epistemology/">https://plato.stanford.edu/archives/win2018/entries/epistemology/</a>; Metaphysics Research Lab, Stanford University.</p>
</div>
<div id="ref-SuttonBartoRein">
<p>[53] Sutton, R.S. and Barto, A.G. 1998. <em>Reinforcement learning: An introduction</em>. MIT Press.</p>
</div>
<div id="ref-tarantola2005inverse">
<p>[54] Tarantola, A. 2005. <em>Inverse problem theory and methods for model parameter estimation</em>. SIAM.</p>
</div>
<div id="ref-SepLogicAi">
<p>[55] Thomason, R. 2016. Logic and artificial intelligence. <em>The stanford encyclopedia of philosophy</em>. E.N. Zalta, ed. <a href="https://plato.stanford.edu/archives/win2016/entries/logic-ai/">https://plato.stanford.edu/archives/win2016/entries/logic-ai/</a>; Metaphysics Research Lab, Stanford University.</p>
</div>
<div id="ref-ApproxThePrac">
<p>[56] Trefethen, L.N. <em>Approximation theory and approximation practice</em>.</p>
</div>
<div id="ref-valiant1984theory">
<p>[57] Valiant, L.G. 1984. A theory of the learnable. <em>Communications of the ACM</em>. 27, 11 (1984), 1134–1142. url: &lt;<a href="http://web.mit.edu/6.435/www/Valiant84.pdf">http://web.mit.edu/6.435/www/Valiant84.pdf</a>&gt;.</p>
</div>
<div id="ref-vittek1996compiler">
<p>[58] Vittek, M. 1996. A compiler for nondeterministic term rewriting systems. <em>International conference on rewriting techniques and applications</em> (1996), 154–168.</p>
</div>
<div id="ref-white2012generalized">
<p>[59] White, M. and Schuurmans, D. 2012. Generalized optimal reverse prediction. <em>Artificial intelligence and statistics</em> (2012), 1305–1313. url: &lt;<a href="http://proceedings.mlr.press/v22/white12/white12.pdf">http://proceedings.mlr.press/v22/white12/white12.pdf</a>&gt;.</p>
</div>
<div id="ref-WienerCyber">
<p>[60] Wiener, N. 1961. <em>Cybernetics or control and communication in the animal and the machine</em>. MIT Press.</p>
</div>
<div id="ref-wissner2013causal">
<p>[61] Wissner-Gross, A.D. and Freer, C.E. 2013. Causal entropic forces. <em>Physical review letters</em>. 110, 16 (2013), 168702. url: &lt;<a href="https://www.alexwg.org/publications/PhysRevLett_110-168702.pdf">https://www.alexwg.org/publications/PhysRevLett_110-168702.pdf</a>&gt;.</p>
</div>
<div id="ref-xu2009optimal">
<p>[62] Xu, L. et al. 2009. Optimal reverse prediction: A unified perspective on supervised, unsupervised and semi-supervised learning. <em>Proceedings of the 26th annual international conference on machine learning</em> (2009), 1137–1144. url: &lt;<a href="http://people.ee.duke.edu/~lcarin/OptReversePred.pdf">http://people.ee.duke.edu/~lcarin/OptReversePred.pdf</a>&gt;.</p>
</div>
<div id="ref-CircuitFitzHughNagumo">
<p>[63] Zhao, J. and Kim, Y.-B. 2007. Circuit implementation of FitzHugh-Nagumo neuron model using field programmable analog arrays. <em>50th midwest symposium on circuits and systems (mwscas)</em> (2007), 772–775.</p>
</div>
<div id="ref-zhu2014high">
<p>[64] Zhu, Z. et al. 2014. A high-energy-density sugar biobattery based on a synthetic enzymatic pathway. <em>Nature communications</em>. 5, (2014).</p>
</div>
</div>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p><a href="https://en.wiktionary.org/wiki/thon#English">https://en.wiktionary.org/wiki/thon#English</a><a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>&quot;Orbit&quot; is a standard mono-unary algebra terminology.<a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p><a href="https://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence">https://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence</a><a href="#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p><a href="https://www.etymonline.com/word/intelligence">https://www.etymonline.com/word/intelligence</a><a href="#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p><a href="http://www.dictionary.com/browse/intelligent">http://www.dictionary.com/browse/intelligent</a><a href="#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p><a href="http://www.idsia.ch/~juergen/newai/newai.html">http://www.idsia.ch/~juergen/newai/newai.html</a><a href="#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p><a href="http://www.cs.uic.edu/~piotr/cs594/Prashant-UniversalAI.pdf">http://www.cs.uic.edu/~piotr/cs594/Prashant-UniversalAI.pdf</a><a href="#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p><a href="https://en.wikipedia.org/wiki/Integrated_information_theory">https://en.wikipedia.org/wiki/Integrated_information_theory</a><a href="#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p><a href="https://twitter.com/search?q=karl%20friston">https://twitter.com/search?q=karl%20friston</a><a href="#fnref9" class="footnote-back">↩</a></p></li>
<li id="fn10"><p><a href="https://en.wikipedia.org/wiki/Microbial_intelligence">https://en.wikipedia.org/wiki/Microbial_intelligence</a><a href="#fnref10" class="footnote-back">↩</a></p></li>
<li id="fn11"><p><a href="https://en.wikipedia.org/wiki/Duck_typing">https://en.wikipedia.org/wiki/Duck_typing</a><a href="#fnref11" class="footnote-back">↩</a></p></li>
<li id="fn12"><p>&quot;McCarthy coined the term 'artificial intelligence' in 1955, and organized the famous Dartmouth Conference in Summer 1956. This conference started AI as a field.&quot; <a href="https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)">https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)</a><a href="#fnref12" class="footnote-back">↩</a></p></li>
<li id="fn13"><p><a href="https://en.wikipedia.org/wiki/Dartmouth_workshop">https://en.wikipedia.org/wiki/Dartmouth_workshop</a><a href="#fnref13" class="footnote-back">↩</a></p></li>
<li id="fn14"><p><a href="http://raysolomonoff.com/dartmouth/">http://raysolomonoff.com/dartmouth/</a><a href="#fnref14" class="footnote-back">↩</a></p></li>
<li id="fn15"><p><a href="http://www.mit.edu/~kardar/teaching/projects/chemotaxis(AndreaSchmidt)/finding_food.htm">http://www.mit.edu/~kardar/teaching/projects/chemotaxis(AndreaSchmidt)/finding_food.htm</a><a href="#fnref15" class="footnote-back">↩</a></p></li>
<li id="fn16"><p>&quot;[...] if you judge a fish by its ability to climb a tree, it will live its whole life believing that it is stupid.&quot; <a href="https://quoteinvestigator.com/2013/04/06/fish-climb/">https://quoteinvestigator.com/2013/04/06/fish-climb/</a><a href="#fnref16" class="footnote-back">↩</a></p></li>
<li id="fn17"><p><a href="https://christophm.github.io/interpretable-ml-book/">https://christophm.github.io/interpretable-ml-book/</a><a href="#fnref17" class="footnote-back">↩</a></p></li>
<li id="fn18"><p>X <em>causes</em> Y iff the absence of X causes the absence of Y. On the other hand, X <em>contributes</em> to Y iff the existence of X changes the severity of Y.<a href="#fnref18" class="footnote-back">↩</a></p></li>
<li id="fn19"><p>&quot;Learning is a an area of AI that focuses on processes of self-improvement.&quot; <a href="http://users.cs.cf.ac.uk/Dave.Marshall/AI2/node131.html#SECTION000151000000000000000">http://users.cs.cf.ac.uk/Dave.Marshall/AI2/node131.html#SECTION000151000000000000000</a><a href="#fnref19" class="footnote-back">↩</a></p></li>
<li id="fn20"><p><a href="https://www.quora.com/What-are-the-most-important-foundational-papers-in-artificial-intelligence-machine-learning">https://www.quora.com/What-are-the-most-important-foundational-papers-in-artificial-intelligence-machine-learning</a><a href="#fnref20" class="footnote-back">↩</a></p></li>
<li id="fn21"><p><a href="https://en.wikipedia.org/wiki/Forgetting_curve">https://en.wikipedia.org/wiki/Forgetting_curve</a><a href="#fnref21" class="footnote-back">↩</a></p></li>
<li id="fn22"><p><a href="https://en.wikipedia.org/wiki/Bloom%27s_taxonomy">https://en.wikipedia.org/wiki/Bloom%27s_taxonomy</a><a href="#fnref22" class="footnote-back">↩</a></p></li>
<li id="fn23"><p><a href="https://en.wikipedia.org/wiki/Hysteresis#Models_of_hysteresis">https://en.wikipedia.org/wiki/Hysteresis#Models_of_hysteresis</a><a href="#fnref23" class="footnote-back">↩</a></p></li>
<li id="fn24"><p><a href="https://www.etymonline.com/word/predict">https://www.etymonline.com/word/predict</a><a href="#fnref24" class="footnote-back">↩</a></p></li>
<li id="fn25"><p><a href="https://en.wikipedia.org/wiki/Primitive_recursive_function">https://en.wikipedia.org/wiki/Primitive_recursive_function</a><a href="#fnref25" class="footnote-back">↩</a></p></li>
<li id="fn26"><p><a href="https://en.wikipedia.org/wiki/Projection_(mathematics)">https://en.wikipedia.org/wiki/Projection_(mathematics)</a><a href="#fnref26" class="footnote-back">↩</a></p></li>
<li id="fn27"><p><a href="https://www.quora.com/What-do-we-intuitively-mean-by-embedding-a-manifold-into-a-higher-dimensional-space-Can-you-give-some-examples">https://www.quora.com/What-do-we-intuitively-mean-by-embedding-a-manifold-into-a-higher-dimensional-space-Can-you-give-some-examples</a><a href="#fnref27" class="footnote-back">↩</a></p></li>
<li id="fn28"><p><a href="https://en.wikipedia.org/wiki/Module_(mathematics)">https://en.wikipedia.org/wiki/Module_(mathematics)</a><a href="#fnref28" class="footnote-back">↩</a></p></li>
<li id="fn29"><p><a href="https://www.etymonline.com/word/plan">https://www.etymonline.com/word/plan</a><a href="#fnref29" class="footnote-back">↩</a></p></li>
<li id="fn30"><p><a href="https://www.etymonline.com/word/regret">https://www.etymonline.com/word/regret</a><a href="#fnref30" class="footnote-back">↩</a></p></li>
<li id="fn31"><p><a href="https://stats.stackexchange.com/questions/214381/what-exactly-is-the-mathematical-definition-of-a-classifier-classification-alg">https://stats.stackexchange.com/questions/214381/what-exactly-is-the-mathematical-definition-of-a-classifier-classification-alg</a><a href="#fnref31" class="footnote-back">↩</a></p></li>
<li id="fn32"><p><a href="https://ndutoitblog.wordpress.com/2018/04/01/defining-machine-learning-with-maths/">https://ndutoitblog.wordpress.com/2018/04/01/defining-machine-learning-with-maths/</a><a href="#fnref32" class="footnote-back">↩</a></p></li>
<li id="fn33"><p><a href="https://www.youtube.com/watch?v=reumVbH41Vc&amp;list=PLSpInro6Ys2IHve6oN9h005zmwfLnOSp1&amp;index=1">https://www.youtube.com/watch?v=reumVbH41Vc&amp;list=PLSpInro6Ys2IHve6oN9h005zmwfLnOSp1&amp;index=1</a><a href="#fnref33" class="footnote-back">↩</a></p></li>
<li id="fn34"><p><a href="https://github.com/cbaziotis/prolog-cfg-parser">https://github.com/cbaziotis/prolog-cfg-parser</a><a href="#fnref34" class="footnote-back">↩</a></p></li>
<li id="fn35"><p><a href="https://en.wikipedia.org/wiki/Theory_of_justification">https://en.wikipedia.org/wiki/Theory_of_justification</a><a href="#fnref35" class="footnote-back">↩</a></p></li>
<li id="fn36"><p><a href="https://www.theepochtimes.com/common-misconceptions-about-confucius_1955031.html">https://www.theepochtimes.com/common-misconceptions-about-confucius_1955031.html</a><a href="#fnref36" class="footnote-back">↩</a></p></li>
<li id="fn37"><p><a href="https://en.wikipedia.org/wiki/Confucianism">https://en.wikipedia.org/wiki/Confucianism</a><a href="#fnref37" class="footnote-back">↩</a></p></li>
<li id="fn38"><p><a href="https://en.wikipedia.org/wiki/Mass_surveillance_in_China">https://en.wikipedia.org/wiki/Mass_surveillance_in_China</a><a href="#fnref38" class="footnote-back">↩</a></p></li>
<li id="fn39"><p><a href="https://en.wikipedia.org/wiki/Social_Credit_System">https://en.wikipedia.org/wiki/Social_Credit_System</a><a href="#fnref39" class="footnote-back">↩</a></p></li>
<li id="fn40"><p><a href="https://en.wikipedia.org/wiki/Human_rights_in_China">https://en.wikipedia.org/wiki/Human_rights_in_China</a><a href="#fnref40" class="footnote-back">↩</a></p></li>
<li id="fn41"><p><a href="https://www.cambridge.org/core/journals/politics-and-religion/article/do-confucian-values-deter-chinese-citizens-support-for-democracy/A4492EE692013F82AB66FD9C90DAFAA9">https://www.cambridge.org/core/journals/politics-and-religion/article/do-confucian-values-deter-chinese-citizens-support-for-democracy/A4492EE692013F82AB66FD9C90DAFAA9</a><a href="#fnref41" class="footnote-back">↩</a></p></li>
<li id="fn42"><p><a href="https://www.businessinsider.com/china-facial-recognition-limitations-2018-7/">https://www.businessinsider.com/china-facial-recognition-limitations-2018-7/</a><a href="#fnref42" class="footnote-back">↩</a></p></li>
<li id="fn43"><p>Table of contents available at <a href="http://assets.cambridge.org/97805218/65593/frontmatter/9780521865593_frontmatter.pdf">http://assets.cambridge.org/97805218/65593/frontmatter/9780521865593_frontmatter.pdf</a><a href="#fnref43" class="footnote-back">↩</a></p></li>
<li id="fn44"><p><a href="https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html">https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html</a><a href="#fnref44" class="footnote-back">↩</a></p></li>
<li id="fn45"><p><a href="https://en.wikipedia.org/wiki/Timeline_of_artificial_intelligence">https://en.wikipedia.org/wiki/Timeline_of_artificial_intelligence</a><a href="#fnref45" class="footnote-back">↩</a></p></li>
<li id="fn46"><p><a href="https://en.wikipedia.org/wiki/Progress_in_artificial_intelligence">https://en.wikipedia.org/wiki/Progress_in_artificial_intelligence</a><a href="#fnref46" class="footnote-back">↩</a></p></li>
<li id="fn47"><p><a href="https://en.wikipedia.org/wiki/Timeline_of_machine_learning">https://en.wikipedia.org/wiki/Timeline_of_machine_learning</a><a href="#fnref47" class="footnote-back">↩</a></p></li>
<li id="fn48"><p>Proceedings at <a href="http://www.math.purdue.edu/calendar/conferences/machinelearning/abstracts.php">http://www.math.purdue.edu/calendar/conferences/machinelearning/abstracts.php</a><a href="#fnref48" class="footnote-back">↩</a></p></li>
<li id="fn49"><p><a href="https://papers.nips.cc/book/advances-in-neural-information-processing-systems-30-2017">https://papers.nips.cc/book/advances-in-neural-information-processing-systems-30-2017</a><a href="#fnref49" class="footnote-back">↩</a></p></li>
<li id="fn50"><p><a href="https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/">https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/</a><a href="#fnref50" class="footnote-back">↩</a></p></li>
<li id="fn51"><p><a href="https://www6.cityu.edu.hk/ma/people/profile/zhoudx.htm">https://www6.cityu.edu.hk/ma/people/profile/zhoudx.htm</a><a href="#fnref51" class="footnote-back">↩</a></p></li>
<li id="fn52"><p><a href="http://staff.ustc.edu.cn/~linlixu/">http://staff.ustc.edu.cn/~linlixu/</a><a href="#fnref52" class="footnote-back">↩</a></p></li>
<li id="fn53"><p><a href="http://webdocs.cs.ualberta.ca/~whitem/">http://webdocs.cs.ualberta.ca/~whitem/</a><a href="#fnref53" class="footnote-back">↩</a></p></li>
<li id="fn54"><p><a href="https://webdocs.cs.ualberta.ca/~dale/">https://webdocs.cs.ualberta.ca/~dale/</a><a href="#fnref54" class="footnote-back">↩</a></p></li>
<li id="fn55"><p><a href="https://functionalcs.github.io/curriculum/">https://functionalcs.github.io/curriculum/</a><a href="#fnref55" class="footnote-back">↩</a></p></li>
<li id="fn56"><p><a href="https://www.csd.cs.cmu.edu/academic/undergraduate/bachelors-curriculum-admitted-2017">https://www.csd.cs.cmu.edu/academic/undergraduate/bachelors-curriculum-admitted-2017</a><a href="#fnref56" class="footnote-back">↩</a></p></li>
<li id="fn57"><p><a href="https://cs.stanford.edu/degrees/ug/Requirements.shtml">https://cs.stanford.edu/degrees/ug/Requirements.shtml</a><a href="#fnref57" class="footnote-back">↩</a></p></li>
<li id="fn58"><p><a href="https://en.wikipedia.org/wiki/Function_space">https://en.wikipedia.org/wiki/Function_space</a><a href="#fnref58" class="footnote-back">↩</a></p></li>
<li id="fn59"><p><a href="https://en.wikipedia.org/wiki/Measure_(mathematics)">https://en.wikipedia.org/wiki/Measure_(mathematics)</a><a href="#fnref59" class="footnote-back">↩</a></p></li>
<li id="fn60"><p><a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">https://en.wikipedia.org/wiki/Metric_(mathematics)</a><a href="#fnref60" class="footnote-back">↩</a></p></li>
<li id="fn61"><p><a href="https://en.wikipedia.org/wiki/Function_space#In_linear_algebra">https://en.wikipedia.org/wiki/Function_space#In_linear_algebra</a><a href="#fnref61" class="footnote-back">↩</a></p></li>
<li id="fn62"><p><a href="https://en.wikipedia.org/wiki/Functional_analysis">https://en.wikipedia.org/wiki/Functional_analysis</a><a href="#fnref62" class="footnote-back">↩</a></p></li>
<li id="fn63"><p><a href="https://courses.cs.washington.edu/courses/cse590a/09wi/mathfoundation.pdf">https://courses.cs.washington.edu/courses/cse590a/09wi/mathfoundation.pdf</a><a href="#fnref63" class="footnote-back">↩</a></p></li>
<li id="fn64"><p><a href="https://en.wikipedia.org/wiki/Function_space#Functional_analysis">https://en.wikipedia.org/wiki/Function_space#Functional_analysis</a><a href="#fnref64" class="footnote-back">↩</a></p></li>
<li id="fn65"><p><a href="https://en.wikipedia.org/wiki/Functional_analysis">https://en.wikipedia.org/wiki/Functional_analysis</a><a href="#fnref65" class="footnote-back">↩</a></p></li>
<li id="fn66"><p><a href="https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space">https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space</a><a href="#fnref66" class="footnote-back">↩</a></p></li>
<li id="fn67"><p><a href="https://www.quora.com/What-are-the-most-notable-applications-of-functional-analysis-to-computer-science">https://www.quora.com/What-are-the-most-notable-applications-of-functional-analysis-to-computer-science</a><a href="#fnref67" class="footnote-back">↩</a></p></li>
<li id="fn68"><p><a href="https://math.stackexchange.com/questions/84238/is-there-a-shorthand-or-symbolic-notation-for-differentiable-or-continuous">https://math.stackexchange.com/questions/84238/is-there-a-shorthand-or-symbolic-notation-for-differentiable-or-continuous</a><a href="#fnref68" class="footnote-back">↩</a></p></li>
<li id="fn69"><p><a href="https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Arnold_representation_theorem">https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Arnold_representation_theorem</a><a href="#fnref69" class="footnote-back">↩</a></p></li>
<li id="fn70"><p><a href="http://ergoemacs.org/emacs/emacs_narrow-to-defun_eval-defun_bug.html">http://ergoemacs.org/emacs/emacs_narrow-to-defun_eval-defun_bug.html</a><a href="#fnref70" class="footnote-back">↩</a></p></li>
<li id="fn71"><p><a href="https://www.joelonsoftware.com/2000/08/09/the-joel-test-12-steps-to-better-code/">https://www.joelonsoftware.com/2000/08/09/the-joel-test-12-steps-to-better-code/</a><a href="#fnref71" class="footnote-back">↩</a></p></li>
<li id="fn72"><p><a href="https://en.wikipedia.org/wiki/Minimum_bounding_box">https://en.wikipedia.org/wiki/Minimum_bounding_box</a><a href="#fnref72" class="footnote-back">↩</a></p></li>
<li id="fn73"><p><a href="https://math.meta.stackexchange.com/questions/41/differences-between-mathoverflow-and-math-stackexchange">https://math.meta.stackexchange.com/questions/41/differences-between-mathoverflow-and-math-stackexchange</a><a href="#fnref73" class="footnote-back">↩</a></p></li>
<li id="fn74"><p><a href="https://en.wikipedia.org/wiki/Partition_of_a_set">https://en.wikipedia.org/wiki/Partition_of_a_set</a><a href="#fnref74" class="footnote-back">↩</a></p></li>
<li id="fn75"><p><a href="https://arxiv.org/abs/1802.08864">https://arxiv.org/abs/1802.08864</a><a href="#fnref75" class="footnote-back">↩</a></p></li>
<li id="fn76"><p><a href="https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0">https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0</a><a href="#fnref76" class="footnote-back">↩</a></p></li>
<li id="fn77"><p><a href="https://en.wikipedia.org/wiki/EcoBot">https://en.wikipedia.org/wiki/EcoBot</a><a href="#fnref77" class="footnote-back">↩</a></p></li>
<li id="fn78"><p><a href="https://en.wikipedia.org/wiki/Evolutionary_robotics">https://en.wikipedia.org/wiki/Evolutionary_robotics</a><a href="#fnref78" class="footnote-back">↩</a></p></li>
<li id="fn79"><p><a href="https://en.wikipedia.org/wiki/Cognitive_architecture">https://en.wikipedia.org/wiki/Cognitive_architecture</a><a href="#fnref79" class="footnote-back">↩</a></p></li>
<li id="fn80"><p>A single-celled organism capable of learning <a href="https://www.sciencedaily.com/releases/2016/04/160427081533.htm">https://www.sciencedaily.com/releases/2016/04/160427081533.htm</a><a href="#fnref80" class="footnote-back">↩</a></p></li>
<li id="fn81"><p><a href="https://en.wikipedia.org/wiki/Cluster_hypothesis">https://en.wikipedia.org/wiki/Cluster_hypothesis</a><a href="#fnref81" class="footnote-back">↩</a></p></li>
<li id="fn82"><p><a href="https://medium.com/continual-ai/why-continuous-learning-is-the-key-towards-machine-intelligence-1851cb57c308">https://medium.com/continual-ai/why-continuous-learning-is-the-key-towards-machine-intelligence-1851cb57c308</a><a href="#fnref82" class="footnote-back">↩</a></p></li>
<li id="fn83"><p><a href="https://www.cs.uic.edu/~liub/lifelong-learning.html">https://www.cs.uic.edu/~liub/lifelong-learning.html</a><a href="#fnref83" class="footnote-back">↩</a></p></li>
<li id="fn84"><p><a href="https://en.wikipedia.org/wiki/Nearest_centroid_classifier">https://en.wikipedia.org/wiki/Nearest_centroid_classifier</a><a href="#fnref84" class="footnote-back">↩</a></p></li>
<li id="fn85"><p><a href="https://link.springer.com/chapter/10.1007/978-3-642-28942-2_24">https://link.springer.com/chapter/10.1007/978-3-642-28942-2_24</a><a href="#fnref85" class="footnote-back">↩</a></p></li>
<li id="fn86"><p><a href="https://www.researchgate.net/publication/262204053_Nearest_Cluster_Classifier">https://www.researchgate.net/publication/262204053_Nearest_Cluster_Classifier</a><a href="#fnref86" class="footnote-back">↩</a></p></li>
<li id="fn87"><p><a href="https://en.wikipedia.org/wiki/Aitken%27s_delta-squared_process">https://en.wikipedia.org/wiki/Aitken%27s_delta-squared_process</a><a href="#fnref87" class="footnote-back">↩</a></p></li>
<li id="fn88"><p><a href="https://en.wikipedia.org/wiki/Sequence_transformation">https://en.wikipedia.org/wiki/Sequence_transformation</a><a href="#fnref88" class="footnote-back">↩</a></p></li>
<li id="fn89"><p>The only problem is that [computers] are still too slow [for ’True AI’] – around a billion neural connections compared with around 100,000bn in the human cortex.&quot; <a href="https://www.theguardian.com/technology/2017/apr/18/robot-man-artificial-intelligence-computer-milky-way">https://www.theguardian.com/technology/2017/apr/18/robot-man-artificial-intelligence-computer-milky-way</a><a href="#fnref89" class="footnote-back">↩</a></p></li>
<li id="fn90"><p><a href="https://en.wikipedia.org/wiki/List_of_animals_by_number_of_neurons">https://en.wikipedia.org/wiki/List_of_animals_by_number_of_neurons</a><a href="#fnref90" class="footnote-back">↩</a></p></li>
<li id="fn91"><p><a href="https://www.reddit.com/r/askscience/comments/3ib6hi/where_is_the_strong_ai_bottleneck/">https://www.reddit.com/r/askscience/comments/3ib6hi/where_is_the_strong_ai_bottleneck/</a><a href="#fnref91" class="footnote-back">↩</a></p></li>
<li id="fn92"><p><a href="https://www.theguardian.com/science/2012/oct/03/philosophy-artificial-intelligence">https://www.theguardian.com/science/2012/oct/03/philosophy-artificial-intelligence</a><a href="#fnref92" class="footnote-back">↩</a></p></li>
<li id="fn93"><p><a href="https://aeon.co/essays/how-close-are-we-to-creating-artificial-intelligence">https://aeon.co/essays/how-close-are-we-to-creating-artificial-intelligence</a><a href="#fnref93" class="footnote-back">↩</a></p></li>
<li id="fn94"><p><a href="http://people.idsia.ch/~juergen/">http://people.idsia.ch/~juergen/</a><a href="#fnref94" class="footnote-back">↩</a></p></li>
<li id="fn95"><p><a href="https://www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_j%C3%BCrgen_schmidhuber_ama/">https://www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_j%C3%BCrgen_schmidhuber_ama/</a><a href="#fnref95" class="footnote-back">↩</a></p></li>
<li id="fn96"><p><a href="https://www.theguardian.com/technology/2017/apr/18/robot-man-artificial-intelligence-computer-milky-way">https://www.theguardian.com/technology/2017/apr/18/robot-man-artificial-intelligence-computer-milky-way</a><a href="#fnref96" class="footnote-back">↩</a></p></li>
<li id="fn97"><p><a href="http://bootstrappingartificialintelligence.fr/WordPress3/">http://bootstrappingartificialintelligence.fr/WordPress3/</a><a href="#fnref97" class="footnote-back">↩</a></p></li>
<li id="fn98"><p><a href="https://www.nytimes.com/2018/06/20/technology/deep-learning-artificial-intelligence.html">https://www.nytimes.com/2018/06/20/technology/deep-learning-artificial-intelligence.html</a><a href="#fnref98" class="footnote-back">↩</a></p></li>
<li id="fn99"><p><a href="http://www.sussex.ac.uk/informatics/punctuation/essaysandletters/footnotes">http://www.sussex.ac.uk/informatics/punctuation/essaysandletters/footnotes</a><a href="#fnref99" class="footnote-back">↩</a></p></li>
<li id="fn100"><p><a href="https://en.wikipedia.org/wiki/Causal_reasoning">https://en.wikipedia.org/wiki/Causal_reasoning</a><a href="#fnref100" class="footnote-back">↩</a></p></li>
</ol>
</section>
                </div>
            </div>
        </main>
                        <div id="disqus_thread"></div>
<script>
/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
var disqus_config = function () {
    this.page.url = "https://edom.github.io/intelligence.html";  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = "https://edom.github.io/intelligence.html"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://edom-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
                        <footer class="site-footer h-card">
            <data class="u-url" href="/"></data>
            <div class="wrapper">
                <p>This page was created on 2017-06-22 03:57:00 +0700.</p>
                <p class="rss-subscribe">There is an
                    <a href="/feed.xml">RSS feed</a>, but it's unused because this site is a wiki, not a blog.</p>
                <p>Stop writing books, papers, and blogs!
                    Write a personal wiki instead!
                    Or, even better, contribute to a community wiki.
                </p>
            </div>
        </footer>
    </body>
</html>
