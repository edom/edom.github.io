<!DOCTYPE html>
<html lang="">
    <head>
        <meta charset="UTF-8"/>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Parsing Research Group</title>
        <link rel="stylesheet" href="/assets/main.css"/>
        <script>
// Help the reader estimate how much time the reading is going to take.
// Show word count and reading time estimation in TOC entry.
//
// TOC = table of contents
//
// Known issue: This janks: this DOM manipulation is done after the page is rendered.
// If we don't want jank, we have to manipulate the HTML source before it reaches the browser.
// We assume that the user doesn't refresh the page while reading.
// The benefit of fixing that jank is not enough for me to justify trying to fix it.
document.addEventListener("DOMContentLoaded", function () {
    function count_word (string) {
        return string.trim().split(/\s+/).length;
    }
    function show_quantity (count, singular) {
        let plural = singular + "s"; // For this script only.
        return count + " " + ((count == 1) ? singular : plural);
    }
    function create_length_indicator (word, minute) {
        let e = document.createElement("span");
        e.className = "toc_entry__length_indicator";
        e.textContent = " (" + show_quantity(word, "word") + " ~ " + show_quantity(minute, "minute") + ")";
        return e;
    }
    // We assume that readers read this many words per minute with 100% comprehension.
    // This assumption may not hold for dense texts such as philosophy and mathematics.
    const wpm_assumption = 200;
    // We assume a certain Jekyll template.
    let page = document.querySelector("main.page-content");
    if (page === null) {
        console.log("toc_generate_estimate: Impossible: CSS selector \"main.page-content\" does not match anything");
        return;
    }
    let page_title = document.querySelector("header.post-header h1.post-title");
    if (page_title === null) {
        console.log("toc_generate_estimate: Impossible: CSS selector \"header.post-header h1.post-title\" does not match anything");
        return;
    }
    let page_word = count_word(page.textContent);
    let page_minute = Math.ceil(page_word / wpm_assumption);
    page_title.insertAdjacentElement("afterend", create_length_indicator(page_word, page_minute));
    // We violate the HTML specification.
    // The page may have several elements with the same ID.
    // We assume that Org HTML Export generates a DIV element with ID "table-of-contents".
    // We assume that Jekyll Markdown-to-HTML generates a UL element with ID "markdown-toc".
    // This only works for Org HTML Export's TOC.
    let toc_entries = document.querySelectorAll("#table-of-contents a, #text-table-of-contents a");
    toc_entries.forEach((toc_entry_a) => {
        let href = toc_entry_a.getAttribute("href"); // We assume that this is a string like "#org0123456".
        if (href.charAt(0) !== '#') {
            console.log("toc_generate_estimate: Impossible: " + href + " does not begin with hash sign");
            return;
        }
        // We can't just document.querySelector(href) because target_id may contain invalid ID characters such as periods.
        let target_id = href.substring(1);
        let id_escaped = target_id.replace("\"", "\\\"");
        let h_elem = document.querySelector("[id=\"" + id_escaped + "\"]"); // We assume that this is the h1/h2/h3 element referred by the TOC entry.
        if (h_elem === null) { // We assume that this is impossible.
            console.log("toc_generate_estimate: Impossible: " + href + " does not refer to anything");
            return;
        }
        let section = h_elem.parentNode;
        let section_word = count_word(section.textContent);
        let section_minute = Math.ceil(section_word / wpm_assumption);
        toc_entry_a.insertAdjacentElement("afterend", create_length_indicator(section_word, section_minute));
    });
});
        </script>

        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-12628443-6"></script>
<script>
  window['ga-disable-UA-12628443-6'] = window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1";
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-12628443-6');
</script>
        
        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            jax: ["input/TeX","input/MathML","input/AsciiMath",
            "output/CommonHTML"
            ],
            extensions: ["tex2jax.js","mml2jax.js","asciimath2jax.js","MathMenu.js","MathZoom.js","AssistiveMML.js", "a11y/accessibility-menu.js"],
            TeX: {
                extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
                , equationNumbers: {
                    autoNumber: "AMS"
                }
            },
            "CommonHTML": {
                scale: 100
            },
            "fast-preview": {
                disabled: true,
            }
        });
        </script>
        <style>
            /*
            PreviewHTML produces small Times New Roman text.
            PreviewHTML scale doesn't work.
            */
            .MathJax_PHTML { font-size: 110%; }
        </style>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js" async defer></script>
    </head>
    <body>
        <header class="site-header" role="banner">
            <div class="wrapper">
                <a class="site-title" rel="author" href="/">Erik Dominikus Research Group</a>
            </div>
        </header>
    <div style="display:none;">\(
    \renewcommand\emptyset{\varnothing}
    \newcommand\abs[1]{\left|#1\right|}
    \newcommand\dom{\textrm{dom}}
    \newcommand\cod{\textrm{cod}}
    \newcommand\Bernoulli{\textrm{Bernoulli}}
    \newcommand\Binomial{\textrm{Binomial}}
    \newcommand\Expect[1]{\mathbb{E}[#1]}
    \newcommand\Nat{\mathbb{N}}
    \newcommand\Integers{\mathbb{Z}}
    \newcommand\Real{\mathbb{R}}
    \newcommand\Rational{\mathbb{Q}}
    \newcommand\Complex{\mathbb{C}}
    \newcommand\Pr{\mathrm{P}}
    \newcommand\Time{\text{Time}}
    \newcommand\DTime{\text{DTime}}
    \newcommand\NTime{\text{NTime}}
    \newcommand\TimeP{\text{P}}
    \newcommand\TimeNP{\text{NP}}
    \newcommand\TimeExp{\text{ExpTime}}
    \newcommand\norm[1]{\left\lVert#1\right\rVert}
    \newcommand\bbA{\mathbb{A}}
    \newcommand\bbC{\mathbb{C}}
    \newcommand\bbD{\mathbb{D}}
    \newcommand\bbE{\mathbb{E}}
    \newcommand\bbN{\mathbb{N}}
    \newcommand\frakI{\mathfrak{I}}
    % deprecated; use TimeExp
    \newcommand\ExpTime{\text{ExpTime}}
    \newcommand\Compute{\text{Compute}}
    \newcommand\Search{\text{Search}}
    % model theory structure
    \newcommand\struc[1]{\mathcal{#1}}
    \newcommand\SetBuilder[2]{\{#1 ~|~ #2\}}
    \newcommand\Set[1]{\{#1\}}
    \newcommand\semantics[1]{\langle #1 \rangle}
    \newcommand\bigsemantics[1]{S\left(#1\right)}
    \)</div>
        <main class="page-content" aria-label="Content">
            <div class="wrapper">
                <article class="post">
                    <header class="post-header">
                        <h1 class="post-title">Parsing Research Group</h1>
                    </header>
                </article>
                <div class="post-content">
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">1</span><span class="section_title"><a href="#what-is-parsing">What is parsing?</a></span><span class="word_count">(825w~5m)</span></li>
<li><span class="section_number">2</span><span class="section_title"><a href="#left-recursion-elimination">Left-recursion elimination</a></span><span class="word_count">(806w~5m)</span></li>
<li><span class="section_number">3</span><span class="section_title"><a href="#language-oriented-approach">Language-oriented approach</a></span><span class="word_count">(47w~1m)</span></li>
<li><span class="section_number">4</span><span class="section_title"><a href="#what-is-the-inverse-of-parsing">What is the inverse of parsing?</a></span><span class="word_count">(150w~1m)</span></li>
<li><span class="section_number">5</span><span class="section_title"><a href="#relational-parsing">Relational parsing</a></span><span class="word_count">(273w~2m)</span></li>
<li><span class="section_number">6</span><span class="section_title"><a href="#how-do-we-parse-how-should-we">How do we parse? How should we?</a></span><span class="word_count">(1785w~9m)</span></li>
<li><span class="section_number">7</span><span class="section_title"><a href="#conferences">Conferences</a></span><span class="word_count">(4w~1m)</span></li>
<li><span class="section_number">8</span><span class="section_title"><a href="#why-cant-top-down-parsers-prolog-dcg-handle-left-recursion">Why can't top-down parsers (Prolog DCG) handle left recursion?</a></span><span class="word_count">(23w~1m)</span></li>
<li><span class="section_number">9</span><span class="section_title"><a href="#can-we-extend-brzozowski-derivatives-to-context-sensitive-expressions">Can we extend Brzozowski derivatives to context-sensitive expressions?</a></span><span class="word_count">(37w~1m)</span></li>
<li><span class="section_number">10</span><span class="section_title"><a href="#politics-of-parsing">Politics of parsing</a></span><span class="word_count">(17w~1m)</span></li>
<li><span class="section_number">11</span><span class="section_title"><a href="#declarative-programming-research-group">Declarative Programming Research Group</a></span><span class="word_count">(322w~2m)</span></li>
<li><span class="section_number">12</span><span class="section_title"><a href="#bibliography">Bibliography</a></span><span class="word_count">(285w~2m)</span></li>
</ul>
</div>
<h2 id="what-is-parsing"><span class="section_number">1</span><span class="section_title">What is parsing?</span></h2>
<p>In 1550, &quot;to parse&quot; is &quot;to state the parts of speech in a sentence&quot;.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">1.1</span><span class="section_title"><a href="#what-is-the-problem">What is the problem?</a></span><span class="word_count">(122w~1m)</span></li>
<li><span class="section_number">1.2</span><span class="section_title"><a href="#parsing-with-brzozowski-quotients">Parsing with Brzozowski quotients</a></span><span class="word_count">(350w~2m)</span></li>
<li><span class="section_number">1.3</span><span class="section_title"><a href="#what-1">What</a></span><span class="word_count">(114w~1m)</span></li>
<li><span class="section_number">1.4</span><span class="section_title"><a href="#the-semantics-of-grammar-expressions">The semantics of grammar expressions</a></span><span class="word_count">(23w~1m)</span></li>
<li><span class="section_number">1.5</span><span class="section_title"><a href="#possible-prefix-incremental-parsing">Possible-prefix incremental parsing?</a></span><span class="word_count">(18w~1m)</span></li>
<li><span class="section_number">1.6</span><span class="section_title"><a href="#a-language-can-be-thought-as-a-possibly-infinite-set-of-strings">A language can be thought as a possibly infinite set of strings</a></span><span class="word_count">(12w~1m)</span></li>
<li><span class="section_number">1.7</span><span class="section_title"><a href="#grammar-and-parsing">Grammar and parsing</a></span><span class="word_count">(17w~1m)</span></li>
<li><span class="section_number">1.8</span><span class="section_title"><a href="#techniques">Techniques?</a></span><span class="word_count">(38w~1m)</span></li>
<li><span class="section_number">1.9</span><span class="section_title"><a href="#regular-expressions-can-be-extended-to-context-free-expressions-by-adding-a-fixed-point-expression-involving-a-binder">Regular expressions can be extended to context-free expressions by adding a fixed-point expression involving a binder</a></span><span class="word_count">(21w~1m)</span></li>
<li><span class="section_number">1.10</span><span class="section_title"><a href="#string-and-tree">String and tree</a></span><span class="word_count">(104w~1m)</span></li>
</ul>
</div>
<h3 id="what-is-the-problem"><span class="section_number">1.1</span><span class="section_title">What is the problem?</span></h3>
<p>The problem is to design a language that describes languages. To design a language specification language. To design a meta-language, for describing grammars, with practical operational semantics.</p>
<p>The problem is &quot;we don’t know how to <em>specify</em> language syntax&quot;<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>.</p>
<p>The language should facilitate these:</p>
<ul>
<li>Specify the grammar of Haskell off-side rule.</li>
<li>Specify the grammar of C.</li>
<li>Specify the grammar of C++.</li>
</ul>
<p>Are composable grammars and parsers possible?<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<p>Prolog definite-clause grammar (DCG) formalism is almost a dream. It is declarative. It handles context-sensitive grammars. Its only weakness is its non-handling of left recursion. But it seems that every left-recursive grammar can be algorithmically transformed into an equivalent non-left-recursive grammar, so what's the problem? It shouldn't be too hard to implement a left recursion elimination algorithm for Prolog DCGs.</p>
<h3 id="parsing-with-brzozowski-quotients"><span class="section_number">1.2</span><span class="section_title">Parsing with Brzozowski quotients</span></h3>
<p>Parsing with Brzozowski quotients<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a><a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> <span class="citation" data-cites="might2011parsing">[<a href="#ref-might2011parsing">8</a>]</span>. Does the general parser community understand that? How do we implement it in Prolog?</p>
<p>Some things I find interesting from <span class="citation" data-cites="might2011parsing">[<a href="#ref-might2011parsing">8</a>]</span>:</p>
<ul>
<li>Kleene fixed-point theorem has a practical application.</li>
</ul>
<p>Equational theories? Now that's a principled parsing.</p>
<p>The result of left-dividing a language <span class="math inline">\(L\)</span> by a string <span class="math inline">\(c\)</span> is <span class="math inline">\(
c \backslash L = \SetBuilder{w}{cw \in L}
\)</span>. <span class="citation" data-cites="brzozowski1964derivatives">[<a href="#ref-brzozowski1964derivatives">2</a>]</span> <span class="citation" data-cites="might2011parsing">[<a href="#ref-might2011parsing">8</a>]</span></p>
<p>Atoms<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
<p>Differentiating Parsers<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></p>
<p>Might et al.'s 2011 pearl <span class="citation" data-cites="might2011parsing">[<a href="#ref-might2011parsing">8</a>]</span> is not in Grune &amp; Jacobs's 2008 book <span class="citation" data-cites="grune2008parsing">[<a href="#ref-grune2008parsing">4</a>]</span>, but the book does mention Brzozowski. Brzozowski's idea goes back to his 1964 paper <span class="citation" data-cites="brzozowski1964derivatives">[<a href="#ref-brzozowski1964derivatives">2</a>]</span>. But who would have thought of adding laziness and memoization on top of it, and generalize it to context-free grammars? (Formal definition?)</p>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">1.2.1</span><span class="section_title"><a href="#what">What?</a></span><span class="word_count">(54w~1m)</span></li>
<li><span class="section_number">1.2.2</span><span class="section_title"><a href="#digression-how-is-the-brzozowski-derivative-a-derivative">Digression: How is the Brzozowski derivative a derivative?</a></span><span class="word_count">(185w~1m)</span></li>
</ul>
</div>
<h4 id="what"><span class="section_number">1.2.1</span><span class="section_title">What?</span></h4>
<ul>
<li>Differentiating Parsers Automatic derivation of incremental parser from a grammar or a non-incremental parser? Like automatic differentiation but generalized to any program? <a href="http://lambda-the-ultimate.org/node/3704">http://lambda-the-ultimate.org/node/3704</a></li>
<li><a href="http://matt.might.net/articles/implementation-of-regular-expression-matching-in-scheme-with-derivatives/">http://matt.might.net/articles/implementation-of-regular-expression-matching-in-scheme-with-derivatives/</a></li>
<li><a href="http://okmij.org/ftp/continuations/differentiating-parsers.html">http://okmij.org/ftp/continuations/differentiating-parsers.html</a></li>
<li><p>Parsing with derivatives?</p>
<ul>
<li><a href="https://hackage.haskell.org/package/derp">https://hackage.haskell.org/package/derp</a></li>
<li><a href="https://arxiv.org/abs/1010.5023">https://arxiv.org/abs/1010.5023</a></li>
<li><a href="http://matt.might.net/articles/parsing-with-derivatives/">http://matt.might.net/articles/parsing-with-derivatives/</a> &quot;Yacc is dead&quot;</li>
</ul></li>
<li><p>Brzozowski quotients.</p>
<ul>
<li><a href="https://arxiv.org/abs/1010.5023">Yacc is dead</a></li>
<li>&quot;Parsing with derivatives&quot;</li>
</ul></li>
<li><p>2017, <a href="https://www.cl.cam.ac.uk/~nk480/parsing.pdf">&quot;A Typed, Algebraic Approach to Parsing&quot;</a></p>
<ul>
<li>&quot;[…] we extend the notion of Brzozowski derivative from regular expressions to the typed context-free expressions.&quot;</li>
</ul></li>
</ul>
<h4 id="digression-how-is-the-brzozowski-derivative-a-derivative"><span class="section_number">1.2.2</span><span class="section_title">Digression: How is the Brzozowski derivative a derivative?</span></h4>
<p>Why does Brzozowski 1964 <span class="citation" data-cites="brzozowski1964derivatives">[<a href="#ref-brzozowski1964derivatives">2</a>]</span> calls it derivative if it is actually a quotient? The article contains has no explanation, so here goes our guess.</p>
<p>The <em>Brzozowski derivative of language <span class="math inline">\(R\)</span> with respect to string <span class="math inline">\(s\)</span></em> is written <span class="math inline">\(D_s R\)</span> and is <span class="math inline">\(\SetBuilder{t}{st \in R}\)</span> <span class="citation" data-cites="brzozowski1964derivatives">[<a href="#ref-brzozowski1964derivatives">2</a>]</span>. The <span class="math inline">\(D_a\)</span> in equation 3.7 in that article would indeed be a differential-algebraic <em>derivation</em><a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> (generalized product rule) if it lost the <span class="math inline">\(\delta(P)\)</span> term: <span class="math display">\[
D_a(PQ) = (D_a P) Q + \delta(P) D_a Q
\]</span> But it is a derivative (a &quot;derivation&quot; <em>in spirit</em>), and there are other things called derivatives that do not exactly satisfy the product rule either. It makes sense for regular expressions to have derivatives, because regular expressions can be studied from abstract-algebra perspective, because regular expressions form an algebra as defined in Brzozowski 1964 section 2 (although he does not explicitly mention that the structure is indeed an algebra).</p>
<p>A corollary: what is the integral? Smith &amp; Yau 1972 <span class="citation" data-cites="smith1972generation">[<a href="#ref-smith1972generation">12</a>]</span> defines an integral counterpart to Brzozowski derivatives. But is that integral really an anti-derivative?</p>
<p>Another corollary: Under what conditions do quotients form derivations/derivatives?</p>
<h3 id="what-1"><span class="section_number">1.3</span><span class="section_title">What</span></h3>
<p>The <em>multiplication</em> of two strings <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> is the concatenation <span class="math inline">\(x \cdot y = x y\)</span>.</p>
<p>Multiplication is associative: <span class="math inline">\((xy)z = x(yz)\)</span>.</p>
<p>The <em>inverse</em> of a string <span class="math inline">\(x\)</span> is written <span class="math inline">\(x^{-1}\)</span>. It's hypothetical. It's pure symbolic manipulation. Don't imagine what it looks like. Do care about its properties:</p>
<ul>
<li>We define <span class="math inline">\(x^{-1} x = \epsilon\)</span>.</li>
<li>We define <span class="math inline">\(x x^{-1} = \epsilon\)</span>.</li>
<li>We define <span class="math inline">\((x y)^{-1} = x^{-1} y^{-1}\)</span>.</li>
</ul>
<p>The <em>left division</em> of a string <span class="math inline">\(x\)</span> by divisor <span class="math inline">\(y\)</span> is <span class="math inline">\(y^{-1} x\)</span>.</p>
<p>The <em>right division</em> of a string <span class="math inline">\(x\)</span> by divisor <span class="math inline">\(y\)</span> is <span class="math inline">\(x y^{-1}\)</span>.</p>
<p>How do we define quotient and remainder?</p>
<p>The Brzozowski derivative is a quotient<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>, because it is the result of dividing a language (a set of strings) by a string.</p>
<h3 id="the-semantics-of-grammar-expressions"><span class="section_number">1.4</span><span class="section_title">The semantics of grammar expressions</span></h3>
<p>Consider the expression X,Y. Declaratively it means X followed by Y. Operationally it means match X <em>then</em> match Y.</p>
<h3 id="possible-prefix-incremental-parsing"><span class="section_number">1.5</span><span class="section_title">Possible-prefix incremental parsing?</span></h3>
<p>Given a string S, find all rules that <em>may</em> match a string that begins with S.</p>
<h3 id="a-language-can-be-thought-as-a-possibly-infinite-set-of-strings"><span class="section_number">1.6</span><span class="section_title">A language can be thought as a possibly infinite set of strings</span></h3>
<h3 id="grammar-and-parsing"><span class="section_number">1.7</span><span class="section_title">Grammar and parsing</span></h3>
<p>Grammar is the what. Parsing is the how.</p>
<p>We say that a parser <em>implements</em> a grammar.</p>
<h3 id="techniques"><span class="section_number">1.8</span><span class="section_title">Techniques?</span></h3>
<p>In <em>recursive descent parsing</em><a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>, the program procedures mirror the grammar rules. Backtracking <em>unreads</em> the input (places the input back into a queue).</p>
<p>&quot;How should I specify a grammar for a parser?&quot;<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a></p>
<p>Naive parser with memoization.</p>
<p>TODO sample Leiss's book &quot;Language equations&quot;</p>
<h3 id="regular-expressions-can-be-extended-to-context-free-expressions-by-adding-a-fixed-point-expression-involving-a-binder"><span class="section_number">1.9</span><span class="section_title">Regular expressions can be extended to context-free expressions by adding a fixed-point expression involving a binder</span></h3>
<p><span class="math inline">\( \mu a . b \)</span>.</p>
<h3 id="string-and-tree"><span class="section_number">1.10</span><span class="section_title">String and tree</span></h3>
<p>A <em>string</em> is a homogeneous sequence.</p>
<p>A <em>tree</em> may be represented by a list of lists.</p>
<p>Parsing is relating strings and trees. Parsing is creating a tree from a string.</p>
<p>What is an alphabet? It may be the set of Unicode character code points. It may be the set of the tokens that a <em>lexical analyzer</em> may produce.</p>
<p>A parser <em>implements</em> a grammar, as a machine <em>implements</em> an algorithm.</p>
<p>A <em>lexer</em> is a degenerate<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a> parser whose codomain is a list (which is a degenerate tree).</p>
<p>The parser is <em>parallelizable</em> if there exists a relatively fast function <span class="math inline">\(combine\)</span> such that for all <span class="math inline">\(x,y \in C^*\)</span>: <span class="math display">\[
P(xy) = combine(P(x), P(y))
\]</span></p>
<h2 id="left-recursion-elimination"><span class="section_number">2</span><span class="section_title">Left-recursion elimination</span></h2>
<p>It is possible to <em>manually</em> eliminate left recursion by rewriting all rules of the form <span class="math inline">\(A \to AB | C\)</span> to <span class="math inline">\(A \to C B^*\)</span> where each of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> is an expression that does not begin with <span class="math inline">\(A\)</span>. I have an example in <code>parse_manual.pro</code>.</p>
<p>Are we OK with manual transformations? There are not many left-recursive rules in practice.</p>
<p>For the computer, our manual transformation is a perfectly fine solution.</p>
<p>The grammar must not have a nullable left-recursive rule like <span class="math inline">\( A \to A \)</span> or <span class="math inline">\( A \to \epsilon^* \)</span>. Otherwise a computer running a naive top-down left-to-right parsing algorithm is doomed into infinite loop. But we can argue that the only <span class="math inline">\(A\)</span> satisfying <span class="math inline">\(A \to A\)</span> is <span class="math inline">\(epsilon\)</span>, and that <span class="math inline">\( \epsilon^* = \epsilon \)</span>.</p>
<p>Two problems arise:</p>
<ul>
<li>What about the parse tree? We want a parser, not a matcher.</li>
<li>Can it be automated?</li>
</ul>
<p>Why do we care about left recursion? Grune &amp; Jacobs 2008 sums it up: &quot;Basically almost all parsing is done by top-down search with left-recursion protection&quot;<span class="citation" data-cites="grune2008parsing">[<a href="#ref-grune2008parsing">4</a>]</span>.</p>
<p>We are interested in eliminating left recursion from Prolog definite-clause grammars (DCGs).</p>
<p>to-do: summarize:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Left_recursion">https://en.wikipedia.org/wiki/Left_recursion</a></li>
<li><a href="https://www.microsoft.com/en-us/research/publication/removing-left-recursion-from-context-free-grammars/">https://www.microsoft.com/en-us/research/publication/removing-left-recursion-from-context-free-grammars/</a></li>
</ul>
<p>I got this idea for left-recursion elimination on &lt;2019-02-20&gt;, but this may be well-known.</p>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">2.1</span><span class="section_title"><a href="#what-is-left-recursion">What is left recursion?</a></span><span class="word_count">(101w~1m)</span></li>
<li><span class="section_number">2.2</span><span class="section_title"><a href="#semiring-of-languages">Semiring of languages</a></span><span class="word_count">(77w~1m)</span></li>
<li><span class="section_number">2.3</span><span class="section_title"><a href="#production-rule-language-endofunction-and-least-fixed-point">Production rule, language endofunction, and least fixed point</a></span><span class="word_count">(94w~1m)</span></li>
<li><span class="section_number">2.4</span><span class="section_title"><a href="#factoring-finite-left-recursion">Factoring finite left-recursion</a></span><span class="word_count">(43w~1m)</span></li>
<li><span class="section_number">2.5</span><span class="section_title"><a href="#left-recursive-language">Left-recursive language</a></span><span class="word_count">(90w~1m)</span></li>
<li><span class="section_number">2.6</span><span class="section_title"><a href="#left-recursion-elimination-algorithm">Left-recursion elimination algorithm</a></span><span class="word_count">(129w~1m)</span></li>
<li><span class="section_number">2.7</span><span class="section_title"><a href="#inlining-the-auxiliary-rules-parse-tree">Inlining the auxiliary rule's parse tree</a></span><span class="word_count">(27w~1m)</span></li>
<li><span class="section_number">2.8</span><span class="section_title"><a href="#prolog-implementation"><span class="todo TODO">TODO</span> Prolog implementation</a></span><span class="word_count">(39w~1m)</span></li>
<li><span class="section_number">2.9</span><span class="section_title"><a href="#reverse-parsing">Reverse parsing</a></span><span class="word_count">(26w~1m)</span></li>
</ul>
</div>
<h3 id="what-is-left-recursion"><span class="section_number">2.1</span><span class="section_title">What is left recursion?</span></h3>
<p>This is a grammar with three left-recursive non-terminals.</p>
<span class="math display">\[\begin{align*}
A &amp;\to B | C
\\ B &amp;\to Ab | b
\\ C &amp;\to Bc | c
\end{align*}
\]</span>
<p>We say that <span class="math inline">\(A\)</span> <em>left-calls</em> <span class="math inline">\(B\)</span> iff there exists a reduction <span class="math inline">\(A \to B C\)</span>.</p>
<p>A non-terminal <span class="math inline">\(A\)</span> is <em>left-recursive</em> iff it may reduce to something beginning with itself. For example, the following rule <span class="math inline">\(A\)</span> is left-recursive.</p>
<span class="math display">\[\begin{align*}
A &amp;\to B
\\ B &amp;\to \epsilon | AC
\end{align*}
\]</span>
<p>The left-call graph. Each vertex represents a non-terminal. An edge <span class="math inline">\((A,B)\)</span> represents that <span class="math inline">\(A\)</span> left-calls <span class="math inline">\(B\)</span>.</p>
<p>If the left-call graph is cyclic, then a top-down parser may not work.</p>
<p>Left-recursion elimination is about breaking cycles in the left-call graph.</p>
<p>How do we delete the minimum number of edges from a graph to make it acyclic? Is this problem NP-hard?</p>
<h3 id="semiring-of-languages"><span class="section_number">2.2</span><span class="section_title">Semiring of languages</span></h3>
<p>We care about algebra because it guides us to <em>correct</em> algorithms.</p>
<p>A <em>semiring</em> is—roughly—an additive group, a multiplicative group, and an interaction between addition and multiplication.</p>
<p>The alphabet is <span class="math inline">\(A\)</span>. It is a finite set.</p>
<p>The semiring's underlying set is <span class="math inline">\(A^*\)</span>.</p>
<p>The languages of the same alphabet form a semiring.</p>
<p>0 is the empty set.</p>
<p>1 is <span class="math inline">\(\Set{\epsilon}\)</span>, the language that consists of the empty string only.</p>
<p>Addition is set union.</p>
<p>Multiplication is language concatenation: <span class="math inline">\(AB = \SetBuilder{ab}{a \in A, b \in B}\)</span>.</p>
<h3 id="production-rule-language-endofunction-and-least-fixed-point"><span class="section_number">2.3</span><span class="section_title">Production rule, language endofunction, and least fixed point</span></h3>
<p>We can think of a production rule as a <em>language endofunction</em>. For example, we can think of the rule <span class="math inline">\(A \to \epsilon | a A\)</span> as the function <span class="math inline">\(A \mapsto 1 + \Set{a} A\)</span>. Then, we can think of the language described by the rule as the <em>least fixed point</em> of the corresponding function, that is, the smallest set such that <span class="math inline">\(A = 1 + \Set{a} A\)</span>.</p>
<p>If a rule is non-recursive, then the corresponding language endofunction is a constant function that does not depend on the parameter.</p>
<h3 id="factoring-finite-left-recursion"><span class="section_number">2.4</span><span class="section_title">Factoring finite left-recursion</span></h3>
<p>Conjecture: Every finite left-recursive rule can be factored into the form <span class="math inline">\(A \to AB | C\)</span> such that the rule <span class="math inline">\(A \to C\)</span> would not be left-recursive.</p>
<p>Example of <em>infinite</em> left recursion: <span class="math inline">\(A \to Aa\)</span>. It matches an infinite string of <span class="math inline">\(a\)</span>.</p>
<h3 id="left-recursive-language"><span class="section_number">2.5</span><span class="section_title">Left-recursive language</span></h3>
<p>Because every rule can be factored as above, it suffices us to consider the least fixed point of the function <span class="math inline">\( A \mapsto AB + C \)</span>.</p>
<p>We obtain the least fixed point by inferring the pattern formed by repeatedly replacing <span class="math inline">\(A = AB+C\)</span> and manipulating the equation.</p>
<span class="math display">\[\begin{align*}
A &amp;= AB+C
\\ A &amp;= (AB+C)B + C
\\ A &amp;= ABB + CB + C
\\ A &amp;= (AB+C)BB + CB + C
\\ A &amp;= ABBB + CBB + CB + C
\\ A &amp;= \ldots + CB^3 + CB^2 + CB^1 + CB^0
\\ A &amp;= \sum_{k\in\Nat} CB^k
\\ A &amp;= C \sum_{k\in\Nat} B^k
\\ A &amp;= C B^*
\end{align*}
\]</span>
<p>It turns out that <span class="math inline">\( lfp(A \mapsto AB + C) = C B^* \)</span>.</p>
<p>Because we are not using extended context-free grammar (which would have regular expressions and the Kleene star), we have to introduce an auxiliary non-terminal <span class="math inline">\(A&#39;\)</span> for representing <span class="math inline">\(B^*\)</span>:</p>
<span class="math display">\[\begin{align*}
A &amp;= C A&#39;
\\ A&#39; &amp;= 1 + BA&#39;
\end{align*}
\]</span>
<p>Observe that <span class="math inline">\(A&#39; = B^*\)</span>.</p>
<span class="math display">\[\begin{align*}
A&#39; &amp;= 1 + BA&#39;
\\ A&#39; &amp;= 1 + B(1 + BA&#39;)
\\ A&#39; &amp;= 1 + B(1 + B(1 + BA&#39;))
\\ A&#39; &amp;= \sum_{k\in\Nat} B^k
\end{align*}
\]</span>
<h3 id="left-recursion-elimination-algorithm"><span class="section_number">2.6</span><span class="section_title">Left-recursion elimination algorithm</span></h3>
<p>The algebra leads us to this left-recursion elimination algorithm:</p>
<ol>
<li>Remove the original rule for the left-recursive non-terminal <span class="math inline">\(A\)</span> from the grammar.</li>
<li>Factor that original rule into the form <span class="math inline">\(A \to AB | C\)</span> such that <span class="math inline">\(A \to C\)</span> would not be left-recursive and would not be empty. If this is impossible, tell the user about the infinite left recursion. Do not add <span class="math inline">\(A \to AB | C\)</span> to the grammar; this rule is only an intermediate product.</li>
<li>Add these two rules to the grammar: <span class="math inline">\(A \to C A&#39;\)</span> and <span class="math inline">\(A&#39; \to \epsilon | B A&#39;\)</span>.</li>
</ol>
<p>We have just eliminated left-recursion in a principled way, in a provably language-preserving way, guided by algebra. Now we understand why it works. If we forget the algorithm, we can always derive it from the algebra.</p>
<p>Example:</p>
<pre class="example"><code>Original left-recursive rule:
exp :- num ; &quot;(&quot;, exp, &quot;)&quot; ; exp, &quot;*&quot;, exp ; exp, &quot;+&quot;, exp

After factoring (A :- ...) into (A :- A,B ; C):
exp :- exp, (&quot;*&quot;, exp ; &quot;+&quot;, exp) ; (num ; &quot;(&quot;, exp, &quot;)&quot;)

After replacement:
exp :- (num ; &quot;(&quot;, exp, &quot;)&quot;), exp0
exp0 :- &quot;&quot; ; (&quot;*&quot;, exp ; &quot;+&quot;, exp), exp0
</code></pre>
<h3 id="inlining-the-auxiliary-rules-parse-tree"><span class="section_number">2.7</span><span class="section_title">Inlining the auxiliary rule's parse tree</span></h3>
<p>Two grammars describing the same language may produce different parse trees.</p>
<p>Unfortunately left-recursion elimination changes the syntax tree. How do we unchange it?</p>
<h3 id="prolog-implementation"><span class="section_number">2.8</span><span class="section_title"><span class="todo TODO">TODO</span> Prolog implementation</span></h3>
<p>Write a Prolog program to eliminate left recursion from definite-clause grammars.</p>
<p>The logical meaning of the Prolog DCG rule <span class="math inline">\(A(x) \to B_1(x), \ldots, B_n(x)\)</span> is the predicate <span class="math inline">\(A\)</span> where <span class="math inline">\(A(x,s_1,s_{n+1}) \leftarrow ( B_1(x,s_1,s_2) \wedge \ldots \wedge B_n(x,s_n,s_{n+1}) )\)</span>.</p>
<h3 id="reverse-parsing"><span class="section_number">2.9</span><span class="section_title">Reverse parsing</span></h3>
<p>parse((A,B),C) iff parse(r((A,B)),r(C)).</p>
<p>where r((A,B)) = r(B),r(A).</p>
<p>Reversing the parser makes it right-to-left top-down parser. It can now handle left-recursion, but it can now not handle right-recursion.</p>
<h2 id="language-oriented-approach"><span class="section_number">3</span><span class="section_title">Language-oriented approach</span></h2>
<p>The language-oriented approach to parsing is to make a language for expressing a relation between strings and trees.</p>
<p>The structure of the concrete syntax tree reflects the structure of the grammar production rules.</p>
<p>Example: a regular expression is a DSL for string matching / pattern matching / parsing.</p>
<h2 id="what-is-the-inverse-of-parsing"><span class="section_number">4</span><span class="section_title">What is the inverse of parsing?</span></h2>
<p>The inverse of parsing is <em>unparsing</em> (tree linearization).</p>
<p>A reverse of parsing is <em>grammar inference</em>, that is to find a grammar that produces a given set of sentences <span class="citation" data-cites="grune2008parsing">[<a href="#ref-grune2008parsing">4</a>]</span>.</p>
<p>Parsing is the treeization (delinearization, deserialization) of a line. Unparsing is the linearization (serialization) of a tree.</p>
<p>Parsing is String -&gt; Maybe Tree. Unparsing is Tree -&gt; String.</p>
<p>Can we make parsing truly one-to-one? String -&gt; Tree. CST = AST. Very rigid syntax. Forbid whitespace freedom.</p>
<p>Another possibility: Inverse of parsing is anti-parsing (generation)? From grammar, generate all possible strings and their syntax trees.</p>
<p>Inverse of analytical grammar is generative grammar?</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Generative_grammar">https://en.wikipedia.org/wiki/Generative_grammar</a></li>
<li><a href="https://en.wikipedia.org/wiki/Formal_grammar#Analytic_grammars">https://en.wikipedia.org/wiki/Formal_grammar#Analytic_grammars</a></li>
</ul>
<p>Parser is syntax analyzer. Analysis is the opposite of synthesis? What is syntax synthesizer?</p>
<p>Inverse of parsing is pretty-printing?</p>
<p>If matching is analogous to subtraction, then what is analogous to multiplication? Generation?</p>
<ul>
<li><p>algebra of pretty-printing</p>
<ul>
<li>1995, Hughes, &quot;The design of a pretty-printing library&quot;</li>
<li>1998, Wadler, &quot;A prettier printer&quot;</li>
<li>Hughes, Peyton-Jones, et al., <a href="http://hackage.haskell.org/package/pretty-1.1.3.6/docs/Text-PrettyPrint-HughesPJ.html">http://hackage.haskell.org/package/pretty-1.1.3.6/docs/Text-PrettyPrint-HughesPJ.html</a></li>
</ul></li>
<li><a href="https://www.cs.kent.ac.uk/people/staff/oc/pretty.html">Efficient simple pretty printing combinators</a></li>
</ul>
<h2 id="relational-parsing"><span class="section_number">5</span><span class="section_title">Relational parsing</span></h2>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">5.1</span><span class="section_title"><a href="#what-2">What?</a></span><span class="word_count">(265w~2m)</span></li>
<li><span class="section_number">5.2</span><span class="section_title"><a href="#history-of-dcg">History of DCG?</a></span><span class="word_count">(8w~1m)</span></li>
</ul>
</div>
<h3 id="what-2"><span class="section_number">5.1</span><span class="section_title">What?</span></h3>
<p>Recall that a <em>relation</em> is a triple that consists of domain, codomain, and pairing.</p>
<p>A grammar <span class="math inline">\(G\)</span> can be thought as a relation between the set <span class="math inline">\(F\)</span> of forms and the set <span class="math inline">\(M\)</span> of meanings: <span class="math inline">\(G \subseteq F \times M\)</span>.</p>
<p>In computer-language parsing, usually the form set <span class="math inline">\(F = C^*\)</span> is the set of character strings, and the meaning set <span class="math inline">\(M\)</span> is the set of syntax tree nodes.</p>
<p>Viewing grammar as <em>relation</em> leads to writing parsers as <em>logic programs</em>, which are almost synonymous with <em>relational programs</em>.</p>
<p>Shieber, Schabes, &amp; Pereira 1995 <span class="citation" data-cites="shieber1995principles">[<a href="#ref-shieber1995principles">11</a>]</span> sees parsing as deduction. It sees parsing from proof-theory point of view. It presents a proof-theoretic framework that unifies several parsing algorithms (CYK, Earley, etc.). It implies that we can use a theorem prover for parsing. But should we?</p>
<p>The correspondence: one Chomsky production rule corresponds to one Horn clause with two parameters (input and rest/unparsed). P(A,B) means that the rule P matches the prefix of A that B lacks.</p>
<p>A DCG predicate can be thought as a relation between two strings. <span class="math inline">\( P \subseteq C^* \times C^* \)</span>.</p>
<p>A <em>grammar relation</em> is a relation <span class="math inline">\(G \subseteq C^* \times T\)</span>. The set <span class="math inline">\(C\)</span> is the <em>alphabet</em>. The set <span class="math inline">\(C^*\)</span> is the <em>Kleene closure</em> of <span class="math inline">\(C\)</span>. The set <span class="math inline">\(T\)</span> is the set of <em>syntax trees</em>.</p>
<p>Let <span class="math inline">\(G\)</span> be a grammar.</p>
<p>We say that a string <span class="math inline">\(S\)</span> is <em>grammatical</em> with respect to <span class="math inline">\(G\)</span> iff there exists a tree <span class="math inline">\(T\)</span> such that <span class="math inline">\(G(S,T)\)</span>. We may omit &quot;with respect to <span class="math inline">\(G\)</span>&quot; if it is clear from context that there is only one grammar.</p>
<p>Iff the grammar relation is a function, then we say that the grammar is <em>unambiguous</em>.</p>
<h3 id="history-of-dcg"><span class="section_number">5.2</span><span class="section_title">History of DCG?</span></h3>
<p>DCG evolved from Colmerauer's &quot;metamorphosis grammar&quot;?</p>
<h2 id="how-do-we-parse-how-should-we"><span class="section_number">6</span><span class="section_title">How do we parse? How should we?</span></h2>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">6.1</span><span class="section_title"><a href="#how">How?</a></span><span class="word_count">(239w~2m)</span></li>
<li><span class="section_number">6.2</span><span class="section_title"><a href="#incrementalonline-parsing">Incremental/online parsing</a></span><span class="word_count">(65w~1m)</span></li>
<li><span class="section_number">6.3</span><span class="section_title"><a href="#how-should-we-generate-parsers-and-unparsers-from-grammars">How should we generate parsers and unparsers from grammars?</a></span><span class="word_count">(117w~1m)</span></li>
<li><span class="section_number">6.4</span><span class="section_title"><a href="#what-parsing-techniquesformalisms-are-there">What parsing techniques/formalisms are there?</a></span><span class="word_count">(280w~2m)</span></li>
<li><span class="section_number">6.5</span><span class="section_title"><a href="#how-do-we-relate-cst-and-ast-without-clutter">How do we relate CST and AST without clutter?</a></span><span class="word_count">(19w~1m)</span></li>
<li><span class="section_number">6.6</span><span class="section_title"><a href="#direct-left-recursive-parsers-in-prolog">&lt;2018-11-02&gt; Direct left-recursive parsers in Prolog</a></span><span class="word_count">(13w~1m)</span></li>
<li><span class="section_number">6.7</span><span class="section_title"><a href="#relational-parsing-parsing-with-prolog">Relational parsing; parsing with Prolog</a></span><span class="word_count">(836w~5m)</span></li>
<li><span class="section_number">6.8</span><span class="section_title"><a href="#metainterpreter-for-left-recursive-parsing">Metainterpreter for left-recursive parsing?</a></span><span class="word_count">(8w~1m)</span></li>
<li><span class="section_number">6.9</span><span class="section_title"><a href="#what-is-left-recursion-and-how-should-we-handle-it">What is left-recursion, and how should we handle it?</a></span><span class="word_count">(166w~1m)</span></li>
<li><span class="section_number">6.10</span><span class="section_title"><a href="#inconclusive">Inconclusive</a></span><span class="word_count">(8w~1m)</span></li>
<li><span class="section_number">6.11</span><span class="section_title"><a href="#parsing">Parsing</a></span><span class="word_count">(38w~1m)</span></li>
</ul>
</div>
<h3 id="how"><span class="section_number">6.1</span><span class="section_title">How?</span></h3>
<p>Zaytsev &amp; Bagge 2014 <span class="citation" data-cites="zaytsev2014parsing">[<a href="#ref-zaytsev2014parsing">14</a>]</span> survey</p>
<p><span class="citation" data-cites="Mu2004AnIL">[<a href="#ref-Mu2004AnIL">9</a>]</span></p>
<p><span class="citation" data-cites="alimarine2005there">[<a href="#ref-alimarine2005there">1</a>]</span></p>
<p>Kourzanov 2014 <span class="citation" data-cites="kourzanov2014bidirectional">[<a href="#ref-kourzanov2014bidirectional">5</a>]</span> bidirectional parsing</p>
<p><span class="citation" data-cites="caballero1999functional">[<a href="#ref-caballero1999functional">3</a>]</span></p>
<p>somewhat unrelated <span class="citation" data-cites="Tan2016BidirectionalGF">[<a href="#ref-Tan2016BidirectionalGF">13</a>]</span></p>
<p><span class="citation" data-cites="Matsuda2013FliPprAP">[<a href="#ref-Matsuda2013FliPprAP">7</a>]</span></p>
<p>Parsing is also called &quot;syntax analysis&quot; (analysis = breakdown, syntax = put together).</p>
<p>Parsing is the act of modifying the <em>state</em> of the parser. This is the operational view.</p>
<p>Parsing is converting a sequence to a tree. This is the data view.</p>
<p>What is the difference between syntax and grammar?</p>
<p>We <em>lex</em> (perform lexical analysis / tokenization) to clean up the grammar (no need to mention whitespaces in the grammar).</p>
<p>Lexing simplifies grammars.</p>
<p>With lexing:</p>
<pre class="example"><code>exp ::= exp PLUS exp
</code></pre>
<p>Without lexing:</p>
<pre class="example"><code>white ::= ...
exp ::= exp white &quot;+&quot; white exp
</code></pre>
<p>&quot;Strictly speaking, tokenization may be handled by the parser. The reason why we tend to bother with tokenising in practice is that it makes the parser simpler, and decouples it from the character encoding used for the source code.&quot; (<a href="https://en.wikibooks.org/wiki/Compiler_Construction/Lexical_analysis">Wikibooks:Compiler construction</a>)</p>
<ul>
<li><a href="https://jeffreykegler.github.io/personal/timeline_v3">Parsing: a timeline – V3.0</a>: 2012 article about a history of parsing.
<ul>
<li><a href="https://www.reddit.com/r/ProgrammingLanguages/comments/8cz97n/parsing_a_timeline_hopefully_this_puts_parsing_is/">Parsing: a timeline. Hopefully this puts &quot;Parsing is a solved problem&quot; to rest. : ProgrammingLanguages</a></li>
<li><a href="http://jeffreykegler.github.io/Ocean-of-Awareness-blog/individual/2018/05/knuth_1965.html">Why is parsing considered solved?</a></li>
</ul></li>
</ul>
<p>Parsing is transforming a list into a tree.</p>
<p>Stand on the shoulders of giants. 2012 timeline of parsing. <a href="https://jeffreykegler.github.io/personal/timeline_v3">https://jeffreykegler.github.io/personal/timeline_v3</a></p>
<p>partial parsing; wrong formatting <a href="http://www.vinartus.net/spa/94j.pdf">http://www.vinartus.net/spa/94j.pdf</a></p>
<p>Deep: &quot;Partial evaluation can turn a general parser into a parser generator.&quot; &quot;The Essence of LR Parsing&quot; Sperber_Thiemann_The_essence_of_LR_parsing.pdf</p>
<p>See the forest, not only the trees.</p>
<p>Some parsing techniques:</p>
<ul>
<li>recursive descent parser (writing a parser manually)</li>
<li>parser generators: Happy (Haskell), Bison (with Yacc)</li>
<li>parser combinators: Parsec (Haskell)</li>
<li>PEG (parsing expression grammar)</li>
<li>Brzozowski quotient</li>
<li>binary-parser description languages: ASN.1, Google Protobuf, Apache Thrift, Apache Avro</li>
<li>invertible parsing?</li>
<li><a href="https://en.wikipedia.org/wiki/Chart_parser">https://en.wikipedia.org/wiki/Chart_parser</a></li>
<li>Parsing Expression Grammar (PEG)
<ul>
<li><a href="https://github.com/harc/ohm/">https://github.com/harc/ohm/</a>
<ul>
<li><a href="https://ohmlang.github.io/">https://ohmlang.github.io/</a>
<ul>
<li><a href="https://harc.ycr.org/project/ohm/">https://harc.ycr.org/project/ohm/</a></li>
</ul></li>
</ul></li>
<li>Packrat</li>
</ul></li>
<li>2015, <a href="https://arxiv.org/abs/1511.08307">Nez: practical open grammar language</a></li>
<li>Earley parser
<ul>
<li><a href="https://en.wikipedia.org/wiki/Earley_parser">https://en.wikipedia.org/wiki/Earley_parser</a></li>
<li><a href="https://hackage.haskell.org/package/Earley">https://hackage.haskell.org/package/Earley</a></li>
</ul></li>
<li><a href="https://github.com/Gabriel439/post-rfc/blob/master/sotu.md#parsing--pretty-printing">https://github.com/Gabriel439/post-rfc/blob/master/sotu.md#parsing--pretty-printing</a>
<ul>
<li><a href="https://hackage.haskell.org/package/trifecta">https://hackage.haskell.org/package/trifecta</a></li>
<li><a href="https://hackage.haskell.org/package/parsers">https://hackage.haskell.org/package/parsers</a></li>
</ul></li>
<li>Parsing in Lisp and Racket <a href="https://stackoverflow.com/questions/21185879/writing-a-formal-language-parser-with-lisp">https://stackoverflow.com/questions/21185879/writing-a-formal-language-parser-with-lisp</a></li>
</ul>
<h3 id="incrementalonline-parsing"><span class="section_number">6.2</span><span class="section_title">Incremental/online parsing</span></h3>
<p>How do IDEs not have to reparse the entire document when the user presses one keystroke?</p>
<p>Incremental parsing is parsing as input becomes available (without waiting for the whole input to become available).</p>
<ul>
<li><p>Type-directed automatic incrementalization</p>
<ul>
<li><a href="http://www.cs.cmu.edu/~joshuad/papers/incr/">http://www.cs.cmu.edu/~joshuad/papers/incr/</a></li>
</ul></li>
<li><p><a href="https://en.wikipedia.org/wiki/Incremental_computing">https://en.wikipedia.org/wiki/Incremental_computing</a></p>
<ul>
<li><a href="https://inc-lc.github.io/">https://inc-lc.github.io/</a></li>
</ul></li>
<li><a href="https://hackage.haskell.org/package/incremental-parser">https://hackage.haskell.org/package/incremental-parser</a></li>
<li><p><a href="https://yi-editor.github.io/posts/2014-09-04-incremental-parsing/">incremental/online parsing</a></p></li>
</ul>
<p>An <em>incremental</em> parser is a relation <span class="math inline">\(step \subseteq C \times T \times T\)</span>.</p>
<p>The idea is to output to all possible continuations? <span class="math inline">\(incrementalize : (C^* \to T) \to (C^* \to T^*)\)</span>?</p>
<h3 id="how-should-we-generate-parsers-and-unparsers-from-grammars"><span class="section_number">6.3</span><span class="section_title">How should we generate parsers and unparsers from grammars?</span></h3>
<p>What we are interested in is how to specify grammar, and how to derive a parser and unparser from grammar specificiation.</p>
<p>I expect the computer to infer a parser and a pretty-printer from the same grammar. Parser generators only give half of what I want.</p>
<p>I expect the computer to work with non-ambiguous left-recursive grammars.</p>
<p>How should parsing be done? From grammar description, the machine should generate both a parser and a pretty-printer.</p>
<p>Given grammar, generate both parser and unparser/pretty-printer.</p>
<ul>
<li><a href="http://www.semdesigns.com/Products/DMS/DMSPrettyPrinters.html?Home=DMSToolkit">http://www.semdesigns.com/Products/DMS/DMSPrettyPrinters.html?Home=DMSToolkit</a></li>
<li><a href="https://hackage.haskell.org/package/invertible-syntax-0.2.1/src/Example.lhs">https://hackage.haskell.org/package/invertible-syntax-0.2.1/src/Example.lhs</a></li>
<li><a href="https://hackage.haskell.org/package/invertible-syntax">https://hackage.haskell.org/package/invertible-syntax</a></li>
<li><a href="http://www.informatik.uni-marburg.de/~rendel/unparse/rendel10invertible.pdf">Tillmann Rendel and Klaus Ostermann. &quot;Invertible Syntax Descriptions: Unifying Parsing and Pretty Printing&quot;. In Proc. of Haskell Symposium, 2010.</a></li>
<li><a href="http://jssst.or.jp/files/user/taikai/2016/PPL/ppl1-1.pdf">http://jssst.or.jp/files/user/taikai/2016/PPL/ppl1-1.pdf</a></li>
<li><a href="http://lambda-the-ultimate.org/node/4191">LTU: Invertible Syntax Descriptions: Unifying Parsing and Pretty Printing</a></li>
<li><a href="http://www.informatik.uni-marburg.de/~rendel/unparse/rendel10invertible.pdf">Invertible Syntax Descriptions: Unifying Parsing and Pretty Printing</a></li>
</ul>
<h3 id="what-parsing-techniquesformalisms-are-there"><span class="section_number">6.4</span><span class="section_title">What parsing techniques/formalisms are there?</span></h3>
<p>There are many techniques/formalisms:</p>
<ul>
<li>Prolog definite-clause grammar (DCG) rules</li>
<li>Haskell parser combinators</li>
<li>continuation-based parsing</li>
<li>parser generators</li>
</ul>
<p>Prolog DCG is interesting because it is often <em>reversible</em>: the same code often gives us both a parser and an unparser.</p>
<p>Logically, a production (a syntax rule) is a predicate (relation) of arity 2. That is, the rule <code>Exp ::= Num Op Num</code> is logically the Horn-clause <code>exp(A,D) :- num(A,B), op(B,C), num(C,D)</code>.</p>
<p>The application of a rule to an input-list produces a syntax object and a remaining-list. A syntax object contains the name of the rule that produces it, the part of the input that matches it, the input position, and so on. We can make this with SWI-Prolog dicts.</p>
<p>We can use Scheme continuation for backtracking like Prolog.</p>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">6.4.1</span><span class="section_title"><a href="#syntax-objects">Syntax objects?</a></span><span class="word_count">(49w~1m)</span></li>
<li><span class="section_number">6.4.2</span><span class="section_title"><a href="#reversible-programming-bidirectional-programming">Reversible programming? Bidirectional programming?</a></span><span class="word_count">(112w~1m)</span></li>
</ul>
</div>
<h4 id="syntax-objects"><span class="section_number">6.4.1</span><span class="section_title">Syntax objects?</span></h4>
<p>The application of a rule to an input-list produces a syntax object and a remaining-list. A syntax object contains the name of the rule that produces it, the part of the input that matches it, the input position, and so on. We can make this with SWI-Prolog dicts.</p>
<h4 id="reversible-programming-bidirectional-programming"><span class="section_number">6.4.2</span><span class="section_title">Reversible programming? Bidirectional programming?</span></h4>
<p>Example: If <span class="math inline">\(T\)</span> is a terminal, then the nonterminal <span class="math inline">\(N \to T\)</span> is invertible. To parse, remove the prefix matching T from the input list. To unparse, prepend T to the input list.</p>
<p>If the rules <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are invertible, then the concatenation nonterminal <span class="math inline">\(N \to AB\)</span> is invertible.</p>
<p>Thus we say the relation <code>cons/3</code> is invertible: <code>cons(H,T,[H|T])</code>.</p>
<p>We want something similar to Rendell &amp; Ostermann 2010 <span class="citation" data-cites="rendel2010invertible">[<a href="#ref-rendel2010invertible">10</a>]</span>, but in Prolog instead of Haskell.</p>
<p>Given view : D -&gt; V and modv : V -&gt; V, the interpreter should be able to infer modd : D -&gt; D.</p>
<p>modd = through view modv</p>
<p>Boomerang language?</p>
<p>Benjamin C. Pierce 2006 &quot;The Weird World of Bi-Directional Programming&quot;<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a></p>
<p>Wikipedia<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a></p>
<p>Janus<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a><a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a></p>
<h3 id="how-do-we-relate-cst-and-ast-without-clutter"><span class="section_number">6.5</span><span class="section_title">How do we relate CST and AST without clutter?</span></h3>
<p>Big problems in parsing: lossless clutterless relation between CST and AST.</p>
<h3 id="direct-left-recursive-parsers-in-prolog"><span class="section_number">6.6</span><span class="section_title">&lt;2018-11-02&gt; Direct left-recursive parsers in Prolog</span></h3>
<p>The key: unify terminals before recursing into nonterminals.</p>
<pre class="example"><code>% S is a list of character codes.
binary_operator([0&#39;+]).
binary_operator([0&#39;*]).

digit(C) :- code_type(C, digit).

number(S) :-
    digit([S])
;   append([[A], B], S), digit(A), number(B);

expression(S) :-
    number(S)
;   binary_operator(B), append([A, B, C], S), expression(A), expression(C).
</code></pre>
<h3 id="relational-parsing-parsing-with-prolog"><span class="section_number">6.7</span><span class="section_title">Relational parsing; parsing with Prolog</span></h3>
<p>Parsing is turning a list into a tree.</p>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">6.7.1</span><span class="section_title"><a href="#approaches">Approaches</a></span><span class="word_count">(66w~1m)</span></li>
<li><span class="section_number">6.7.2</span><span class="section_title"><a href="#determining-the-groundness-of-the-length-of-the-lists-involved-in-append3-and-append2">Determining the groundness of the length of the lists involved in append/3 and append/2</a></span><span class="word_count">(245w~2m)</span></li>
<li><span class="section_number">6.7.3</span><span class="section_title"><a href="#naive-approach-with-recognizer-membership-predicate">Naive approach with recognizer / membership predicate</a></span><span class="word_count">(226w~2m)</span></li>
<li><span class="section_number">6.7.4</span><span class="section_title"><a href="#prefix-remover-difference-list-recognizer-list-partitioner">Prefix remover / difference-list recognizer / list partitioner</a></span><span class="word_count">(156w~1m)</span></li>
<li><span class="section_number">6.7.5</span><span class="section_title"><a href="#definite-clause-grammars">Definite clause grammars</a></span><span class="word_count">(89w~1m)</span></li>
<li><span class="section_number">6.7.6</span><span class="section_title"><a href="#context-sensitive-grammars">Context-sensitive grammars?</a></span><span class="word_count">(8w~1m)</span></li>
<li><span class="section_number">6.7.7</span><span class="section_title"><a href="#libraries">Libraries?</a></span><span class="word_count">(8w~1m)</span></li>
<li><span class="section_number">6.7.8</span><span class="section_title"><a href="#left-recursion">Left recursion</a></span><span class="word_count">(23w~1m)</span></li>
<li><span class="section_number">6.7.9</span><span class="section_title"><a href="#precedence-parsing">Precedence parsing?</a></span><span class="word_count">(12w~1m)</span></li>
</ul>
</div>
<h4 id="approaches"><span class="section_number">6.7.1</span><span class="section_title">Approaches</span></h4>
<ul>
<li>2002 course notes <a href="http://www.cs.sfu.ca/~cameron/Teaching/383/DCG.html">http://www.cs.sfu.ca/~cameron/Teaching/383/DCG.html</a></li>
<li>1987 article &quot;Parsing and compiling using Prolog&quot; <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.9739&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.9739&amp;rep=rep1&amp;type=pdf</a></li>
<li>relational approach
<ul>
<li>recognizer: <code>digit(Input)</code>
<ul>
<li>recognizer with explicit search strategy</li>
</ul></li>
<li>prefix remover: <code>digit(Input, Unparsed_suffix)</code>
<ul>
<li>This is the approach used by Prolog DCG (definite clause grammar).</li>
</ul></li>
<li>prefix extractor: <code>digit(Input, Parsed_prefix, Unparsed_suffix)</code>
<ul>
<li>This enables us to get the parsed input without <code>append/3</code>.</li>
</ul></li>
<li>concrete syntax tree parser: <code>digit(Input, Parsed, Unparsed)</code> where <code>Parsed = number(Children)</code>.
<ul>
<li>An example of <code>Parsed</code> is <code>number(digit(1), number(digit(2)))</code>.</li>
</ul></li>
<li>interpreter</li>
</ul></li>
<li>functional approach
<ul>
<li>parser combinator</li>
</ul></li>
<li>generator approach
<ul>
<li>parser generator</li>
<li>parsing expression grammar</li>
</ul></li>
<li>procedural approach
<ul>
<li>recursive-descent</li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Garden-path_sentence">https://en.wikipedia.org/wiki/Garden-path_sentence</a></li>
</ul>
<h4 id="determining-the-groundness-of-the-length-of-the-lists-involved-in-append3-and-append2"><span class="section_number">6.7.2</span><span class="section_title">Determining the groundness of the length of the lists involved in append/3 and append/2</span></h4>
<ol>
<li><p>Why do we care?</p>
<p>Because we want to write naive parsers that terminate.</p></li>
<li><p>What?</p>
<p>From the source code of SWI-Prolog, with some modifications:</p>
<ul>
<li><a href="http://www.swi-prolog.org/pldoc/doc/_SWI_/library/lists.pl?show=src#append/3">http://www.swi-prolog.org/pldoc/doc/_SWI_/library/lists.pl?show=src#append/3</a></li>
</ul>
<p>&quot;Ground&quot; here is an adjective, not a noun. A term is <em>ground</em> iff it has no variables. A term is non-ground otherwise.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode prolog"><code class="sourceCode prolog"><a class="sourceLine" id="cb5-1" title="1">append([]<span class="kw">,</span> <span class="dt">L</span><span class="kw">,</span> <span class="dt">L</span>)<span class="kw">.</span></a>
<a class="sourceLine" id="cb5-2" title="2">append([<span class="dt">H</span><span class="fu">|</span><span class="dt">T</span>]<span class="kw">,</span> <span class="dt">L</span><span class="kw">,</span> [<span class="dt">H</span><span class="fu">|</span><span class="dt">R</span>]) <span class="kw">:-</span></a>
<a class="sourceLine" id="cb5-3" title="3">    append(<span class="dt">T</span><span class="kw">,</span> <span class="dt">L</span><span class="kw">,</span> <span class="dt">R</span>)<span class="kw">.</span></a>
<a class="sourceLine" id="cb5-4" title="4"></a>
<a class="sourceLine" id="cb5-5" title="5">append([]<span class="kw">,</span> [])<span class="kw">.</span></a>
<a class="sourceLine" id="cb5-6" title="6">append([<span class="dt">L</span><span class="fu">|</span><span class="dt">Ls</span>]<span class="kw">,</span> <span class="dt">As</span>) <span class="kw">:-</span></a>
<a class="sourceLine" id="cb5-7" title="7">    append(<span class="dt">L</span><span class="kw">,</span> <span class="dt">Ws</span><span class="kw">,</span> <span class="dt">As</span>)<span class="kw">,</span></a>
<a class="sourceLine" id="cb5-8" title="8">    append(<span class="dt">Ls</span><span class="kw">,</span> <span class="dt">Ws</span>)<span class="kw">.</span></a></code></pre></div>
<p>We say that a list is <em>length-ground</em> iff its length is ground, and <em>length-unground</em> otherwise. The elements don't have to be ground.</p>
<ul>
<li>The empty list is length-ground.</li>
<li>A list [_|T] is length-ground iff T is length-ground.</li>
<li>If a variable gets unified with a length-ground list, then the variable is length-ground.</li>
</ul>
<p>To analyze length-groundedness, we &quot;reverse&quot; the program.</p>
<pre class="example"><code>% append(T, L, R)
append([], L, L).
append(T, L, R) =&gt; append([H|T], L, [H|R]).
</code></pre>
<p>(Length-ground = proper list?)</p>
<p>Now we can infer these about append(T, L, R):</p>
<ul>
<li>If T = [], then L and R have the same length-groundness.</li>
<li>The recursive case:
<ul>
<li>Iff T is length-ground, then [H|T] is length-ground.</li>
<li>Iff R is length-ground, then [H|R] is length-ground.</li>
</ul></li>
<li>If we want L to be length-ground, then R has to be length-ground.</li>
<li>Thus we can infer that L and R have the same length-groundness regardless of the length-groundness of T.</li>
</ul>
<p>If append(A, B, C) succeeds, then:</p>
<ul>
<li>If A = [], then B and C have the same length-groundness.</li>
<li>If two of A, B, C are length-ground, then the other one is length-ground?</li>
<li>If two of A, B, C are length-unground, then the other one is length-unground?</li>
</ul>
<p>What?</p>
<ul>
<li>2002 article &quot;Efficient Groundness Analysis in Prolog&quot; <a href="https://arxiv.org/abs/cs/0201012">https://arxiv.org/abs/cs/0201012</a>
<ul>
<li><a href="https://github.com/pschachte/groundness">https://github.com/pschachte/groundness</a></li>
</ul></li>
</ul></li>
<li><p>How do we generate a long list in Prolog, for testing?</p>
<ol>
<li><p>How do we say &quot;A is a list of 100 equal elements&quot; in Prolog?</p></li>
</ol></li>
</ol>
<h4 id="naive-approach-with-recognizer-membership-predicate"><span class="section_number">6.7.3</span><span class="section_title">Naive approach with recognizer / membership predicate</span></h4>
<p>A <em>recognizer</em> is a unary predicate that takes a list of character codes.</p>
<p>Another possible names for recognizer are <em>acceptor</em>, <em>determiner</em>, <em>decider</em>, <em>membership predicate</em>.</p>
<p>Example: The following <code>digit</code> predicate recognizes ASCII decimal digits.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode prolog"><code class="sourceCode prolog"><a class="sourceLine" id="cb7-1" title="1">digit([<span class="dt">D</span>]) <span class="kw">:-</span> code_type(<span class="dt">D</span><span class="kw">,</span> digit)<span class="kw">.</span></a></code></pre></div>
<p>We can build recognizers on other recognizers. For example, here we use <code>digit</code> to define <code>number_</code>:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode prolog"><code class="sourceCode prolog"><a class="sourceLine" id="cb8-1" title="1"><span class="co">% We append underscore because =number= is a reserved Prolog predicate.</span></a>
<a class="sourceLine" id="cb8-2" title="2">number_([<span class="dt">H</span>]) <span class="kw">:-</span> digit([<span class="dt">H</span>])<span class="kw">.</span></a>
<a class="sourceLine" id="cb8-3" title="3">number_([<span class="dt">H</span><span class="fu">|</span><span class="dt">T</span>]) <span class="kw">:-</span> digit([<span class="dt">H</span>])<span class="kw">,</span> number_(<span class="dt">T</span>)<span class="kw">.</span></a></code></pre></div>
<p>That Prolog knowledge base corresponds to this context-free grammar:</p>
<pre><code>digit ::= &lt;a digit character as defined by Unicode&gt;
number ::= digit | digit number
</code></pre>
<p>Exercise:</p>
<ul>
<li>Here you will compare depth-first search and iterative deepening search, and understand search completeness.</li>
<li>Try the query <code>number_(S)</code>.</li>
<li>Try the query <code>length(S,_), number_(S)</code>.</li>
<li>If you keep pressing semicolon in the first query, will you ever encounter <code>S = [48,49]</code>?</li>
</ul>
<ol>
<li><p>A cool thing: recognizers are generators.</p>
<p>The predicate <code>number_</code> can be used not only to recognize strings, but also to <em>generate</em> all such strings.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode prolog"><code class="sourceCode prolog"><a class="sourceLine" id="cb10-1" title="1"><span class="co">% Press ; to generate the next possibility.</span></a>
<a class="sourceLine" id="cb10-2" title="2"><span class="co">% Press . to stop.</span></a>
<a class="sourceLine" id="cb10-3" title="3"><span class="fu">?-</span> length(<span class="dt">S</span><span class="kw">,</span><span class="dt">_</span>)<span class="kw">,</span> number_(<span class="dt">S</span>)<span class="kw">.</span></a></code></pre></div>
<p>To understand how that works, we have to understand Prolog backtracking.</p></li>
<li><p>Left recursion thwarts the naive approach.</p>
<p>Problem: The following <code>expression</code> doesn't terminate.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode prolog"><code class="sourceCode prolog"><a class="sourceLine" id="cb11-1" title="1">operator([<span class="dt">A</span>]) <span class="kw">:-</span> string_codes(<span class="ot">&quot;+&quot;</span><span class="kw">,</span> <span class="dt">Ops</span>)<span class="kw">,</span> member(<span class="dt">A</span><span class="kw">,</span> <span class="dt">Ops</span>)<span class="kw">.</span></a>
<a class="sourceLine" id="cb11-2" title="2"></a>
<a class="sourceLine" id="cb11-3" title="3">expression(<span class="dt">E</span>) <span class="kw">:-</span> number_(<span class="dt">E</span>)<span class="kw">.</span></a>
<a class="sourceLine" id="cb11-4" title="4">expression(<span class="dt">E</span>) <span class="kw">:-</span> <span class="kw">true</span></a>
<a class="sourceLine" id="cb11-5" title="5">    <span class="kw">,</span> append([<span class="dt">A</span>, <span class="dt">B</span>, <span class="dt">C</span>]<span class="kw">,</span> <span class="dt">E</span>)</a>
<a class="sourceLine" id="cb11-6" title="6">    <span class="kw">,</span> expression(<span class="dt">A</span>)</a>
<a class="sourceLine" id="cb11-7" title="7">    <span class="kw">,</span> operator(<span class="dt">B</span>)</a>
<a class="sourceLine" id="cb11-8" title="8">    <span class="kw">,</span> expression(<span class="dt">C</span>)</a>
<a class="sourceLine" id="cb11-9" title="9">    <span class="kw">.</span></a></code></pre></div>
<p>The corresponding context-free grammar is left-recursive:</p>
<pre><code>expression ::= number | expression operator expression
</code></pre>
<p>We don't want to sacrifice the elegance of the description.</p></li>
<li><p>Can memoization (tabling) help speed up the naive approach?</p>
<p>No.</p></li>
<li><p>Another naive approach that works.</p>
<p>This one works.</p>
<p>The key is:</p>
<ul>
<li>Put grounding goals first. A grounding goal is a goal that grounds its variables.</li>
<li><p>Be careful with the pattern <code>g, u</code> where <code>g</code> generates ungrounded terms and <code>u</code> fails, because it may cause infinite loop when Prolog backtracks, because Prolog continues to generate fresh variables. For example, this doesn't terminate:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode prolog"><code class="sourceCode prolog"><a class="sourceLine" id="cb13-1" title="1"><span class="fu">?-</span> length(<span class="dt">L</span><span class="kw">,</span> <span class="dt">N</span>)<span class="kw">,</span> <span class="kw">fail.</span></a></code></pre></div>
<ul>
<li>If <code>p</code> may generate infinite choice points, then <code>p, fail</code> doesn't terminate.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb14"><pre class="sourceCode prolog"><code class="sourceCode prolog"><a class="sourceLine" id="cb14-1" title="1">digit([<span class="dt">C</span>]) <span class="kw">:-</span> code_type(<span class="dt">C</span><span class="kw">,</span> digit)<span class="kw">.</span></a>
<a class="sourceLine" id="cb14-2" title="2"></a>
<a class="sourceLine" id="cb14-3" title="3">number_([<span class="dt">H</span>]) <span class="kw">:-</span> digit([<span class="dt">H</span>])<span class="kw">.</span></a>
<a class="sourceLine" id="cb14-4" title="4">number_([<span class="dt">H</span><span class="fu">|</span><span class="dt">T</span>]) <span class="kw">:-</span> digit([<span class="dt">H</span>])<span class="kw">,</span> number_(<span class="dt">T</span>)<span class="kw">.</span></a>
<a class="sourceLine" id="cb14-5" title="5"></a>
<a class="sourceLine" id="cb14-6" title="6">operator([<span class="bn">0&#39;+</span>])<span class="kw">.</span></a>
<a class="sourceLine" id="cb14-7" title="7"></a>
<a class="sourceLine" id="cb14-8" title="8"><span class="co">% expression(Meaning,Codes) may not work if Codes is ungrounded.</span></a>
<a class="sourceLine" id="cb14-9" title="9">expression(<span class="dt">number</span>(<span class="dt">E</span>)<span class="kw">,</span> <span class="dt">E</span>) <span class="kw">:-</span> number_(<span class="dt">E</span>)<span class="kw">.</span></a>
<a class="sourceLine" id="cb14-10" title="10">expression(plus(<span class="dt">MA</span><span class="kw">,</span><span class="dt">MC</span>)<span class="kw">,</span> <span class="dt">E</span>) <span class="kw">:-</span> <span class="kw">true</span></a>
<a class="sourceLine" id="cb14-11" title="11">    <span class="kw">,</span> operator(<span class="dt">EB</span>) <span class="co">% Put grounding goals first.</span></a>
<a class="sourceLine" id="cb14-12" title="12">    <span class="kw">,</span> append([<span class="dt">EA</span>,<span class="dt">EB</span>,<span class="dt">EC</span>]<span class="kw">,</span> <span class="dt">E</span>) <span class="co">% Thus B is grounded.</span></a>
<a class="sourceLine" id="cb14-13" title="13">    <span class="kw">,</span> expression(<span class="dt">MA</span><span class="kw">,</span><span class="dt">EA</span>)</a>
<a class="sourceLine" id="cb14-14" title="14">    <span class="kw">,</span> expression(<span class="dt">MC</span><span class="kw">,</span><span class="dt">EC</span>)</a>
<a class="sourceLine" id="cb14-15" title="15">    <span class="kw">.</span></a></code></pre></div></li>
</ol>
<h4 id="prefix-remover-difference-list-recognizer-list-partitioner"><span class="section_number">6.7.4</span><span class="section_title">Prefix remover / difference-list recognizer / list partitioner</span></h4>
<p>We can turn the naive recognizer <code>digit/1</code> into difference-list recognizer <code>digit/2</code>.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode prolog"><code class="sourceCode prolog"><a class="sourceLine" id="cb15-1" title="1">digit([<span class="dt">D</span>]) <span class="kw">:-</span> code_type(<span class="dt">D</span><span class="kw">,</span> digit)<span class="kw">.</span></a></code></pre></div>
<ul>
<li>The first parameter is the input string, say Input.</li>
<li>The second parameter is the recognized prefix of Input.</li>
<li>The third parameter is the unrecognized suffix of Input.</li>
</ul>
<p>In the following, P stands for Parsed, and U stands for Unparsed.</p>
<p>We can turn the recognizer into:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode prolog"><code class="sourceCode prolog"><a class="sourceLine" id="cb16-1" title="1"><span class="co">% Prefix remover.</span></a>
<a class="sourceLine" id="cb16-2" title="2">digit([<span class="dt">P</span><span class="fu">|</span><span class="dt">U</span>]<span class="kw">,</span> <span class="dt">U</span>) <span class="kw">:-</span> code_type(<span class="dt">P</span><span class="kw">,</span> digit)<span class="kw">.</span></a>
<a class="sourceLine" id="cb16-3" title="3"></a>
<a class="sourceLine" id="cb16-4" title="4"><span class="co">% List partitioner.</span></a>
<a class="sourceLine" id="cb16-5" title="5">digit([<span class="dt">P</span><span class="fu">|</span><span class="dt">U</span>]<span class="kw">,</span> [<span class="dt">P</span>]<span class="kw">,</span> <span class="dt">U</span>) <span class="kw">:-</span> code_type(<span class="dt">P</span><span class="kw">,</span> digit)<span class="kw">.</span></a>
<a class="sourceLine" id="cb16-6" title="6"></a>
<a class="sourceLine" id="cb16-7" title="7"><span class="co">% The list partitioner can be derived from the prefix remover:</span></a>
<a class="sourceLine" id="cb16-8" title="8"><span class="co">% digit(U0, P0, U1) :- digit(U0, U1), append(P0, U1, U0).</span></a>
<a class="sourceLine" id="cb16-9" title="9"></a>
<a class="sourceLine" id="cb16-10" title="10">number_(<span class="dt">U0</span><span class="kw">,</span> <span class="dt">U1</span>) <span class="kw">:-</span> digit(<span class="dt">U0</span><span class="kw">,</span> <span class="dt">U1</span>)<span class="kw">.</span></a>
<a class="sourceLine" id="cb16-11" title="11"></a>
<a class="sourceLine" id="cb16-12" title="12">number_(<span class="dt">U0</span><span class="kw">,</span> <span class="dt">P0</span><span class="kw">,</span> <span class="dt">U1</span>) <span class="kw">:-</span> digit(<span class="dt">U0</span><span class="kw">,</span> <span class="dt">P0</span><span class="kw">,</span> <span class="dt">U1</span>)<span class="kw">.</span></a>
<a class="sourceLine" id="cb16-13" title="13">number_(<span class="dt">U0</span><span class="kw">,</span> <span class="dt">P2</span><span class="kw">,</span> <span class="dt">U2</span>) <span class="kw">:-</span> <span class="kw">true</span></a>
<a class="sourceLine" id="cb16-14" title="14">    <span class="kw">,</span> digit(<span class="dt">U0</span><span class="kw">,</span> <span class="dt">P0</span><span class="kw">,</span> <span class="dt">U1</span>)</a>
<a class="sourceLine" id="cb16-15" title="15">    <span class="kw">,</span> number_(<span class="dt">U1</span><span class="kw">,</span> <span class="dt">P1</span><span class="kw">,</span> <span class="dt">U2</span>)</a>
<a class="sourceLine" id="cb16-16" title="16">    <span class="kw">,</span> append(<span class="dt">P0</span><span class="kw">,</span> <span class="dt">P1</span><span class="kw">,</span> <span class="dt">P2</span>)</a>
<a class="sourceLine" id="cb16-17" title="17">    <span class="kw">.</span></a></code></pre></div>
<p>The meaning of <code>number_(U0, P0, U1)</code> is:</p>
<ul>
<li>P0 is a number.</li>
<li>P0 is a prefix of U0.</li>
<li>U0 is the concatenation of P0 and U1.</li>
</ul>
<p>Observe how we &quot;thread&quot; the state. The calls in the body follow the pattern <code>something(U&lt;n&gt;, P&lt;n&gt;, U&lt;n+1&gt;)</code>.</p>
<p>We can translate a recognizer into a difference-list recognizer.</p>
<p>The cool thing is that each parameter works both ways.</p>
<ul>
<li>The query <code>string_codes(&quot;123&quot;, A), number_(A, A, [])</code> asks Prolog to find out whether &quot;123&quot; parses as a number.</li>
<li>The query <code>length(A, _), number_(A, A, []).</code> asks Prolog to find a string that parse as a number. You can keep pressing <code>;</code> to generate the next strings.</li>
</ul>
<div class="sourceCode" id="cb17"><pre class="sourceCode prolog"><code class="sourceCode prolog"><a class="sourceLine" id="cb17-1" title="1">operator([<span class="dt">P</span><span class="fu">|</span><span class="dt">U</span>]<span class="kw">,</span> [<span class="dt">P</span>]<span class="kw">,</span> <span class="dt">U</span>) <span class="kw">:-</span> string_codes(<span class="ot">&quot;+&quot;</span><span class="kw">,</span> <span class="dt">Codes</span>)<span class="kw">,</span> member(<span class="dt">P</span><span class="kw">,</span> <span class="dt">Codes</span>)<span class="kw">.</span></a>
<a class="sourceLine" id="cb17-2" title="2"></a>
<a class="sourceLine" id="cb17-3" title="3">expression(<span class="dt">U0</span><span class="kw">,</span> <span class="dt">P0</span><span class="kw">,</span> <span class="dt">U1</span>) <span class="kw">:-</span> number_(<span class="dt">U0</span><span class="kw">,</span> <span class="dt">P0</span><span class="kw">,</span> <span class="dt">U1</span>)<span class="kw">.</span></a>
<a class="sourceLine" id="cb17-4" title="4">expression(<span class="dt">U0</span><span class="kw">,</span> <span class="dt">P0</span><span class="kw">,</span> <span class="dt">U1</span>) <span class="kw">:-</span> <span class="kw">true</span></a>
<a class="sourceLine" id="cb17-5" title="5">    <span class="kw">,</span> expression(<span class="dt">U0</span><span class="kw">,</span> <span class="dt">P0</span><span class="kw">,</span> <span class="dt">U1</span>)</a>
<a class="sourceLine" id="cb17-6" title="6">    <span class="kw">,</span> operator(<span class="dt">U1</span><span class="kw">,</span> <span class="dt">P1</span><span class="kw">,</span> <span class="dt">U2</span>)</a>
<a class="sourceLine" id="cb17-7" title="7">    <span class="kw">,</span> expression(<span class="dt">U2</span><span class="kw">,</span> <span class="dt">P2</span><span class="kw">,</span> <span class="dt">U3</span>)</a>
<a class="sourceLine" id="cb17-8" title="8">    <span class="kw">.</span></a></code></pre></div>
<h4 id="definite-clause-grammars"><span class="section_number">6.7.5</span><span class="section_title">Definite clause grammars</span></h4>
<ul>
<li>The DCG clause <code>left --&gt; right</code> desugars/expands/translates into the definite clause <code>left(U0, U1) :- ...</code> where:
<ul>
<li>U0 is the input.</li>
<li>U1 is the suffix of U0 that is not recognized by the DCG clause.</li>
<li>The string recognized by the clause is the difference between U0 and U1. That string is the P such that U0 = P + U1 where + denotes list concatenation.</li>
</ul></li>
<li>&quot;Interesting Things about Prolog&quot; <a href="https://gist.github.com/CMCDragonkai/89a6c502ca7272e5e7464c0fc8667f4d">https://gist.github.com/CMCDragonkai/89a6c502ca7272e5e7464c0fc8667f4d</a>
<ul>
<li>&quot;Definite clause grammars (DCG) make the difference list pattern into a first class primitive with the <code>--&gt;</code> operator.&quot;</li>
</ul></li>
</ul>
<ol>
<li><p>Why does this naive DCG fail?</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode prolog"><code class="sourceCode prolog"><a class="sourceLine" id="cb18-1" title="1">digit <span class="kw">--&gt;</span> [<span class="dt">Code</span>]<span class="kw">,</span> <span class="kw">{</span>code_type(<span class="dt">Code</span><span class="kw">,</span> digit)<span class="kw">}.</span></a>
<a class="sourceLine" id="cb18-2" title="2"></a>
<a class="sourceLine" id="cb18-3" title="3"><span class="dt">number</span> <span class="kw">--&gt;</span></a>
<a class="sourceLine" id="cb18-4" title="4">    digit<span class="kw">,</span> <span class="dt">number</span></a>
<a class="sourceLine" id="cb18-5" title="5"><span class="kw">;</span>   digit</a>
<a class="sourceLine" id="cb18-6" title="6"><span class="kw">.</span></a>
<a class="sourceLine" id="cb18-7" title="7"></a>
<a class="sourceLine" id="cb18-8" title="8">operator <span class="kw">--&gt;</span> <span class="ot">&quot;+&quot;</span><span class="kw">.</span></a>
<a class="sourceLine" id="cb18-9" title="9"></a>
<a class="sourceLine" id="cb18-10" title="10">expression <span class="kw">--&gt;</span></a>
<a class="sourceLine" id="cb18-11" title="11">    <span class="dt">number</span></a>
<a class="sourceLine" id="cb18-12" title="12"><span class="kw">;</span>   expression<span class="kw">,</span> operator<span class="kw">,</span> expression</a>
<a class="sourceLine" id="cb18-13" title="13"><span class="kw">.</span></a></code></pre></div></li>
</ol>
<h4 id="context-sensitive-grammars"><span class="section_number">6.7.6</span><span class="section_title">Context-sensitive grammars?</span></h4>
<p>We can add context by adding parameter.</p>
<h4 id="libraries"><span class="section_number">6.7.7</span><span class="section_title">Libraries?</span></h4>
<ul>
<li><a href="https://github.com/cbaziotis/prolog-cfg-parser">https://github.com/cbaziotis/prolog-cfg-parser</a></li>
<li>This isn't Prolog, but this looks awesome <a href="https://github.com/Engelberg/instaparse/blob/master/README.md">https://github.com/Engelberg/instaparse/blob/master/README.md</a></li>
</ul>
<h4 id="left-recursion"><span class="section_number">6.7.8</span><span class="section_title">Left recursion</span></h4>
<p>Mathematics handles left recursion just fine. Computers should too. We shouldn't chicken out. We shouldn't compromise by working around our grammar descriptions.</p>
<h4 id="precedence-parsing"><span class="section_number">6.7.9</span><span class="section_title">Precedence parsing?</span></h4>
<ul>
<li>1996 article &quot;An Operator Precedence Parser for Standard Prolog Text&quot; <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-024X%28199607%2926%3A7%3C763%3A%3AAID-SPE33%3E3.0.CO%3B2-L">https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-024X%28199607%2926%3A7%3C763%3A%3AAID-SPE33%3E3.0.CO%3B2-L</a></li>
</ul>
<h3 id="metainterpreter-for-left-recursive-parsing"><span class="section_number">6.8</span><span class="section_title">Metainterpreter for left-recursive parsing?</span></h3>
<p>&quot;Parsing with left-recursive grammars&quot; <a href="https://www.metalevel.at/acomip/">https://www.metalevel.at/acomip/</a></p>
<h3 id="what-is-left-recursion-and-how-should-we-handle-it"><span class="section_number">6.9</span><span class="section_title">What is left-recursion, and how should we handle it?</span></h3>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">6.9.1</span><span class="section_title"><a href="#should-we-blame-left-recursion-on-naive-operational-semantics">Should we blame left-recursion on naive operational semantics?</a></span><span class="word_count">(20w~1m)</span></li>
<li><span class="section_number">6.9.2</span><span class="section_title"><a href="#handling-left-recursion">Handling left-recursion</a></span><span class="word_count">(87w~1m)</span></li>
<li><span class="section_number">6.9.3</span><span class="section_title"><a href="#left-recursive-parsing">Left-recursive parsing</a></span><span class="word_count">(53w~1m)</span></li>
</ul>
</div>
<h4 id="should-we-blame-left-recursion-on-naive-operational-semantics"><span class="section_number">6.9.1</span><span class="section_title">Should we blame left-recursion on naive operational semantics?</span></h4>
<p>Mathematics has no problem with left-recursion. Why should computers have problem with left-recursion?</p>
<h4 id="handling-left-recursion"><span class="section_number">6.9.2</span><span class="section_title">Handling left-recursion</span></h4>
<p>Laurent and Mens 2016 <span class="citation" data-cites="laurent2016taming">[<a href="#ref-laurent2016taming">6</a>]</span> (some emphasis ours): &quot;When a parser invokes itself (either directly or indirectly through intermediate parsers) without intervening state changes, the result is an infinite loop of parser invocations. This is a well-known problem of top-down recursive parsers, called <em>left-recursion</em>. Fortunately, it can be <em>mitigated</em> as follows: start by running the left-recursive parser <em>while failing all left-recursive invocations</em>, then re-run it, using the result of the initial parse as the result of all left-recursive invocations.&quot;</p>
<p>Avoiding left-recursion means always consuming something before recursing.</p>
<h4 id="left-recursive-parsing"><span class="section_number">6.9.3</span><span class="section_title">Left-recursive parsing</span></h4>
<p>2009 Direct Left-Recursive Parsing Expressing Grammars <a href="https://www.semanticscholar.org/paper/Direct-Left-Recursive-Parsing-Expressing-Grammars-Tratt/b1e8309db5537fb15f51071fcdc39e139659ed15">https://www.semanticscholar.org/paper/Direct-Left-Recursive-Parsing-Expressing-Grammars-Tratt/b1e8309db5537fb15f51071fcdc39e139659ed15</a></p>
<p>2008 Packrat Parsers Can Support Left Recursion</p>
<p>Naive recognizer + memoization</p>
<p>list_not_empty</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode prolog"><code class="sourceCode prolog"><a class="sourceLine" id="cb19-1" title="1">exp(<span class="dt">S</span>) <span class="kw">:-</span> is_list(<span class="dt">S</span>)<span class="kw">,</span> append([<span class="dt">A</span>,[<span class="bn">0&#39;+</span>],<span class="dt">C</span>]<span class="kw">,</span><span class="dt">S</span>)<span class="kw">,</span> exp(<span class="dt">A</span>)<span class="kw">,</span> exp(<span class="dt">C</span>)<span class="kw">.</span></a></code></pre></div>
<p>Consume before recursing?</p>
<p>We can't piggyback Prolog's unification for lambda calculus substitution, because Prolog unifies same-named variables while lambda-calculus shadows same-named variables.</p>
<p>If the recursive call has smaller arguments than the parent call does, then the predicate should terminate.</p>
<h3 id="inconclusive"><span class="section_number">6.10</span><span class="section_title">Inconclusive</span></h3>
<p>1997 inconclusive discussion &quot;Prolog Parser in Prolog&quot; <a href="https://dtai.cs.kuleuven.be/projects/ALP/newsletter/archive_93_96/net/grammars/parser.html">https://dtai.cs.kuleuven.be/projects/ALP/newsletter/archive_93_96/net/grammars/parser.html</a></p>
<h3 id="parsing"><span class="section_number">6.11</span><span class="section_title">Parsing</span></h3>
<p>&quot;Parsing in Prolog&quot; <a href="http://www.cs.sfu.ca/~cameron/Teaching/383/DCG.html">http://www.cs.sfu.ca/~cameron/Teaching/383/DCG.html</a></p>
<p>&quot;Jacc's LR-Parsing with Dynamic Operators&quot; &quot;This part of the Jacc documentation explains the modifications we can make to a basic table-driven LR parser generator à la yacc to accommodate support for Prolog's dynamic operators.&quot; <a href="http://www.hassan-ait-kaci.net/hlt/doc/hlt/jaccdoc/dynamicLR.html">http://www.hassan-ait-kaci.net/hlt/doc/hlt/jaccdoc/dynamicLR.html</a></p>
<h2 id="conferences"><span class="section_number">7</span><span class="section_title">Conferences</span></h2>
<p>ACM SIGPLAN SLE <a href="http://www.sleconf.org/blog/11-20-2013-parsing-at-sle-2013">http://www.sleconf.org/blog/11-20-2013-parsing-at-sle-2013</a></p>
<h2 id="why-cant-top-down-parsers-prolog-dcg-handle-left-recursion"><span class="section_number">8</span><span class="section_title">Why can't top-down parsers (Prolog DCG) handle left recursion?</span></h2>
<p>Can we fix it by prescribing a different operational semantics?</p>
<p>Should we just use bottom-up parsers?</p>
<h2 id="can-we-extend-brzozowski-derivatives-to-context-sensitive-expressions"><span class="section_number">9</span><span class="section_title">Can we extend Brzozowski derivatives to context-sensitive expressions?</span></h2>
<p>Context-free expression is regular expression plus fixed points.</p>
<p>A context-sensitive rule has a left-hand side that may contain more than one non-terminal. An example of such rule is <span class="math inline">\(AB \to C\)</span>.</p>
<h2 id="politics-of-parsing"><span class="section_number">10</span><span class="section_title">Politics of parsing</span></h2>
<p>This patent (US patent 6449589, &quot;Elimination of left recursion from context-free grammars&quot;)<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a><a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a> should not exist?</p>
<h2 id="declarative-programming-research-group"><span class="section_number">11</span><span class="section_title">Declarative Programming Research Group</span></h2>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">11.1</span><span class="section_title"><a href="#transitive-closure">Transitive closure</a></span><span class="word_count">(280w~2m)</span></li>
<li><span class="section_number">11.2</span><span class="section_title"><a href="#transitive-closure-in-prolog">Transitive closure in Prolog</a></span><span class="word_count">(40w~1m)</span></li>
</ul>
</div>
<h3 id="transitive-closure"><span class="section_number">11.1</span><span class="section_title">Transitive closure</span></h3>
<p>There are several ways of thinking about transitivity: relation, logic, graph, fixed-point, and limit.</p>
<p>A relation <span class="math inline">\(R\)</span> is <em>transitive</em> iff <span class="math inline">\(\forall x \forall y \forall z [(R(x,y) \wedge R(y,z)) \to R(x,z)]\)</span>.</p>
<p>The transitive closure of a relation <span class="math inline">\(R\)</span> is the smallest transitive superrelation of <span class="math inline">\(R\)</span>. Such closure is obtained by adding the fewest number of edges to make <span class="math inline">\(R\)</span> transitive.</p>
<p>The <em>transitive closure of an arity-2 predicate <span class="math inline">\(P\)</span></em> is <span class="math inline">\(T(P)\)</span> where <span class="math inline">\(T(P,x,y) = P(x,y) \vee \exists i (P(x,i) \wedge T(P,i,y)) \)</span>. The transitive closure of a first-order logic predicate is a first-order logic predicate. But the transitive closure <em>operator</em> <span class="math inline">\(T\)</span> is a second-order logic predicate. Fagin 1974 proves that transitive closure makes first-order logic more expressive.<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a></p>
<p>The <em>transitive closure of an arity-2 relation <span class="math inline">\(R\)</span></em> is <span class="math inline">\(R \cup R_2 \cup R_3 \cup \ldots = \bigcup_{k \in \Nat \ge 1} R_k\)</span> where <span class="math inline">\(R_k = \underbrace{R \circ \ldots \circ R}_k\)</span>. But this assumes that the relation is countable. If the relation is finite and its domain has <span class="math inline">\(n\)</span> elements, then <span class="math inline">\(k\)</span> does not need to go higher than <span class="math inline">\(n-1\)</span>, because the shortest path between two connected vertices in that graph will have at most <span class="math inline">\(n-1\)</span> edges. Thus <span class="math inline">\(T(R)\)</span> is the smallest set that satisfies the equation <span class="math inline">\(T(R) = T(R) \cup R\)</span>. Thus <span class="math inline">\(T(R)\)</span> is the least fixed point of the function <span class="math inline">\(A \mapsto (A \cup R)\)</span>.</p>
<p>We can also think of transitive closure of <span class="math inline">\(R\)</span> as the limit <span class="math inline">\(\lim_{n\to\infty} S_n\)</span> But this also assumes that the relation is countable. where <span class="math inline">\(S_1 = R\)</span> and <span class="math inline">\(S_{n+1} = (S_n \circ R) \cup R\)</span> and <span class="math inline">\((B,C,S) \circ (A,B,R) = (A,C,\SetBuilder{(x,z)}{\exists x (R(x,y) \wedge S(y,z))})\)</span>. We can think of <span class="math inline">\(S_n\)</span> as the set of paths whose length does not exceed <span class="math inline">\(n\)</span>.</p>
<h3 id="transitive-closure-in-prolog"><span class="section_number">11.2</span><span class="section_title">Transitive closure in Prolog</span></h3>
<p>This naïve Prolog predicate <code>t/2</code> may not terminate if the graph represented by <code>edge</code> is cyclic. Direct translation of the logical formula does not work.</p>
<pre class="example"><code>t(A,B) :- edge(A,B).
t(A,C) :- edge(A,B), t(B,C).
</code></pre>
<p>How do we make Prolog smarter so that the above predicate <code>t/2</code> terminates?</p>
<h2 id="bibliography" class="unnumbered"><span class="section_number">12</span><span class="section_title">Bibliography</span></h2>
<div id="refs" class="references">
<div id="ref-alimarine2005there">
<p>[1] Alimarine, A. et al. 2005. There and back again: Arrows for invertible programming. <em>Proceedings of the 2005 acm sigplan workshop on haskell</em> (2005), 86–97. url: &lt;<a href="https://www.cs.ru.nl/~marko/research/pubs/2005/bi-arrows.pdf">https://www.cs.ru.nl/~marko/research/pubs/2005/bi-arrows.pdf</a>&gt;.</p>
</div>
<div id="ref-brzozowski1964derivatives">
<p>[2] Brzozowski, J.A. 1964. Derivatives of regular expressions. <em>Journal of the ACM</em>. 11, (1964), 481–494. url: &lt;<a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.98.4378">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.98.4378</a>&gt;.</p>
</div>
<div id="ref-caballero1999functional">
<p>[3] Caballero, R. and López-Fraguas, F.J. 1999. A functional-logic perspective of parsing. <em>International symposium on functional and logic programming</em> (1999), 85–99. url: &lt;<a href="https://pdfs.semanticscholar.org/a87f/56ad2113060650afb230aa9182cbe845041e.pdf">https://pdfs.semanticscholar.org/a87f/56ad2113060650afb230aa9182cbe845041e.pdf</a>&gt;.</p>
</div>
<div id="ref-grune2008parsing">
<p>[4] Grune, D. and Jacobs, C.J. 2008. Parsing techniques: A practical guide. (2008).</p>
</div>
<div id="ref-kourzanov2014bidirectional">
<p>[5] Kourzanov, P. 2014. Bidirectional parsing a functional / logic perspective. (2014). url: &lt;<a href="https://ifl2014.github.io/submissions/ifl2014_submission_18.pdf">https://ifl2014.github.io/submissions/ifl2014_submission_18.pdf</a>&gt;.</p>
</div>
<div id="ref-laurent2016taming">
<p>[6] Laurent, N. and Mens, K. 2016. Taming context-sensitive languages with principled stateful parsing. <em>Proceedings of the 2016 acm sigplan international conference on software language engineering</em> (2016), 15–27. url: &lt;<a href="http://arxiv.org/abs/1609.05365">http://arxiv.org/abs/1609.05365</a>&gt;.</p>
</div>
<div id="ref-Matsuda2013FliPprAP">
<p>[7] Matsuda, K. and Wang, M. 2013. FliPpr: A prettier invertible printing system. <em>ESOP</em> (2013). url: &lt;<a href="http://www2.sf.ecei.tohoku.ac.jp/~kztk/papers/kztk_esop2013.pdf">http://www2.sf.ecei.tohoku.ac.jp/~kztk/papers/kztk_esop2013.pdf</a>&gt;.</p>
</div>
<div id="ref-might2011parsing">
<p>[8] Might, M. et al. 2011. Parsing with derivatives: A functional pearl. <em>ACM sigplan notices</em> (2011), 189–195. url: &lt;<a href="http://matt.might.net/papers/might2011derivatives.pdf">http://matt.might.net/papers/might2011derivatives.pdf</a>&gt;.</p>
</div>
<div id="ref-Mu2004AnIL">
<p>[9] Mu, S.-C. et al. 2004. An injective language for reversible computation. <em>MPC</em> (2004). url: &lt;<a href="http://takeichi.ipl-lab.org/~scm/pub/reversible.pdf">http://takeichi.ipl-lab.org/~scm/pub/reversible.pdf</a>&gt;.</p>
</div>
<div id="ref-rendel2010invertible">
<p>[10] Rendel, T. and Ostermann, K. 2010. Invertible syntax descriptions: Unifying parsing and pretty printing. <em>ACM sigplan notices</em> (2010), 1–12. url: &lt;<a href="http://www.informatik.uni-marburg.de/~rendel/unparse/rendel10invertible.pdf">http://www.informatik.uni-marburg.de/~rendel/unparse/rendel10invertible.pdf</a>&gt;.</p>
</div>
<div id="ref-shieber1995principles">
<p>[11] Shieber, S.M. et al. 1995. Principles and implementation of deductive parsing. <em>The Journal of logic programming</em>. 24, 1-2 (1995), 3–36. url: &lt;<a href="https://www.eecs.harvard.edu/shieber/Biblio/Papers/infer.pdf">https://www.eecs.harvard.edu/shieber/Biblio/Papers/infer.pdf</a>&gt;.</p>
</div>
<div id="ref-smith1972generation">
<p>[12] Smith, L.W. and Yau, S.S. 1972. Generation of regular expressions for automata by the integral of regular expressions. <em>The Computer Journal</em>. 15, 3 (Aug. 1972), 222–228. url: &lt;<a href="https://academic.oup.com/comjnl/article/15/3/222/480588">https://academic.oup.com/comjnl/article/15/3/222/480588</a>&gt;.</p>
</div>
<div id="ref-Tan2016BidirectionalGF">
<p>[13] Tan, G. and Morrisett, J.G. 2016. Bidirectional grammars for machine-code decoding and encoding. <em>Journal of Automated Reasoning</em>. 60, (2016), 257–277. url: &lt;<a href="http://www.cse.psu.edu/~gxt29/papers/bigrammar_jar.pdf">http://www.cse.psu.edu/~gxt29/papers/bigrammar_jar.pdf</a>&gt;.</p>
</div>
<div id="ref-zaytsev2014parsing">
<p>[14] Zaytsev, V. and Bagge, A.H. 2014. Parsing in a broad sense. <em>International conference on model driven engineering languages and systems</em> (2014), 50–67. url: &lt;<a href="https://bora.uib.no/bitstream/handle/1956/8938/zaytsev-bagge-models14-parsing.pdf">https://bora.uib.no/bitstream/handle/1956/8938/zaytsev-bagge-models14-parsing.pdf</a>&gt;.</p>
</div>
</div>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p><a href="https://www.etymonline.com/word/parse">https://www.etymonline.com/word/parse</a><a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p><a href="http://trevorjim.com/parsing-not-solved/">http://trevorjim.com/parsing-not-solved/</a><a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p><a href="https://tratt.net/laurie/blog/entries/parsing_the_solved_problem_that_isnt.html">https://tratt.net/laurie/blog/entries/parsing_the_solved_problem_that_isnt.html</a><a href="#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p><a href="http://matt.might.net/articles/parsing-with-derivatives/">http://matt.might.net/articles/parsing-with-derivatives/</a><a href="#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p><a href="https://github.com/webyrd/relational-parsing-with-derivatives/blob/master/README.md">https://github.com/webyrd/relational-parsing-with-derivatives/blob/master/README.md</a><a href="#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p><a href="https://blog.github.com/2018-10-31-atoms-new-parsing-system/">https://blog.github.com/2018-10-31-atoms-new-parsing-system/</a><a href="#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p><a href="http://lambda-the-ultimate.org/node/3704">http://lambda-the-ultimate.org/node/3704</a><a href="#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p><a href="https://en.wikipedia.org/wiki/Derivation_(differential_algebra)">https://en.wikipedia.org/wiki/Derivation_(differential_algebra)</a><a href="#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p><a href="https://en.wikipedia.org/wiki/Quotient_of_a_formal_language">https://en.wikipedia.org/wiki/Quotient_of_a_formal_language</a><a href="#fnref9" class="footnote-back">↩</a></p></li>
<li id="fn10"><p><a href="https://en.wikipedia.org/wiki/Recursive_descent_parser">https://en.wikipedia.org/wiki/Recursive_descent_parser</a><a href="#fnref10" class="footnote-back">↩</a></p></li>
<li id="fn11"><p><a href="https://softwareengineering.stackexchange.com/questions/107266/how-should-i-specify-a-grammar-for-a-parser">https://softwareengineering.stackexchange.com/questions/107266/how-should-i-specify-a-grammar-for-a-parser</a><a href="#fnref11" class="footnote-back">↩</a></p></li>
<li id="fn12"><p><a href="https://en.wikipedia.org/wiki/Degeneracy_(mathematics)">https://en.wikipedia.org/wiki/Degeneracy_(mathematics)</a><a href="#fnref12" class="footnote-back">↩</a></p></li>
<li id="fn13"><p><a href="https://www.cis.upenn.edu/~bcpierce/papers/lenses-etapsslides.pdf">https://www.cis.upenn.edu/~bcpierce/papers/lenses-etapsslides.pdf</a><a href="#fnref13" class="footnote-back">↩</a></p></li>
<li id="fn14"><p><a href="https://en.wikipedia.org/wiki/Bidirectional_transformation">https://en.wikipedia.org/wiki/Bidirectional_transformation</a><a href="#fnref14" class="footnote-back">↩</a></p></li>
<li id="fn15"><p><a href="https://topps.diku.dk/pirc/?id=janus">https://topps.diku.dk/pirc/?id=janus</a><a href="#fnref15" class="footnote-back">↩</a></p></li>
<li id="fn16"><p><a href="https://en.wikipedia.org/wiki/Janus_(time-reversible_computing_programming_language)">https://en.wikipedia.org/wiki/Janus_(time-reversible_computing_programming_language)</a><a href="#fnref16" class="footnote-back">↩</a></p></li>
<li id="fn17"><p><a href="http://www.freepatentsonline.com/6449589.html">http://www.freepatentsonline.com/6449589.html</a><a href="#fnref17" class="footnote-back">↩</a></p></li>
<li id="fn18"><p><a href="https://patents.google.com/patent/US6449589B1/">https://patents.google.com/patent/US6449589B1/</a><a href="#fnref18" class="footnote-back">↩</a></p></li>
<li id="fn19"><p><a href="https://en.wikipedia.org/wiki/Transitive_closure#In_logic_and_computational_complexity">https://en.wikipedia.org/wiki/Transitive_closure#In_logic_and_computational_complexity</a><a href="#fnref19" class="footnote-back">↩</a></p></li>
</ol>
</section>
                </div>
            </div>
        </main>
                        <div id="disqus_thread"></div>
<script>
/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
var disqus_config = function () {
    this.page.url = "https://edom.github.io/parse.html";  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = "https://edom.github.io/parse.html"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://edom-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
                        <footer class="site-footer h-card">
            <data class="u-url" href="/"></data>
            <div class="wrapper">
                <p>This page was created on 2018-04-11 00:00 +0700.</p>
                <p class="rss-subscribe">There is an
                    <a href="/feed.xml">RSS feed</a>, but it's unused because this site is a wiki, not a blog.</p>
                <p>Stop writing books, papers, and blogs!
                    Write a personal wiki instead!
                    Or, even better, contribute to a community wiki.
                </p>
            </div>
        </footer>
    </body>
</html>
