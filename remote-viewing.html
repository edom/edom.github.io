<!DOCTYPE html>
<html lang="">
    <head>
        <meta charset="UTF-8"/>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>On remote viewing</title>
        <link rel="stylesheet" href="/assets/main.css"/>
        <script>
// Help the reader estimate how much time the reading is going to take.
// Show word count and reading time estimation in TOC entry.
//
// TOC = table of contents
//
// Known issue: This janks: this DOM manipulation is done after the page is rendered.
// If we don't want jank, we have to manipulate the HTML source before it reaches the browser.
// We assume that the user doesn't refresh the page while reading.
// The benefit of fixing that jank is not enough for me to justify trying to fix it.
document.addEventListener("DOMContentLoaded", function () {
    function count_word (string) {
        return string.trim().split(/\s+/).length;
    }
    function show_quantity (count, singular) {
        let plural = singular + "s"; // For this script only.
        return count + " " + ((count == 1) ? singular : plural);
    }
    function create_length_indicator (word, minute) {
        let e = document.createElement("div");
        e.className = "toc_entry__length_indicator";
        e.textContent = " (" + show_quantity(word, "word") + " ~ " + show_quantity(minute, "minute") + ")";
        return e;
    }
    // We assume that readers read this many words per minute with 100% comprehension.
    // This assumption may not hold for dense texts such as philosophy and mathematics.
    const wpm_assumption = 200;
    // We assume a certain Jekyll template.
    let page = document.querySelector("main.page-content");
    if (page === null) {
        console.log("toc_generate_estimate: Impossible: CSS selector \"main.page-content\" does not match anything");
        return;
    }
    let page_title = document.querySelector("header.post-header h1.post-title");
    if (page_title === null) {
        console.log("toc_generate_estimate: Impossible: CSS selector \"header.post-header h1.post-title\" does not match anything");
        return;
    }
    let page_word = count_word(page.textContent);
    let page_minute = Math.ceil(page_word / wpm_assumption);
    page_title.insertAdjacentElement("afterend", create_length_indicator(page_word, page_minute));
    // We violate the HTML specification.
    // The page may have several elements with the same ID.
    // We assume that Org HTML Export generates a DIV element with ID "table-of-contents".
    // We assume that Jekyll Markdown-to-HTML generates a UL element with ID "markdown-toc".
    // This only works for Org HTML Export's TOC.
    let toc_entries = document.querySelectorAll("#table-of-contents a, #text-table-of-contents a");
    toc_entries.forEach((toc_entry_a) => {
        let href = toc_entry_a.getAttribute("href"); // We assume that this is a string like "#org0123456".
        if (href.charAt(0) !== '#') {
            console.log("toc_generate_estimate: Impossible: " + href + " does not begin with hash sign");
            return;
        }
        // We can't just document.querySelector(href) because target_id may contain invalid ID characters such as periods.
        let target_id = href.substring(1);
        let id_escaped = target_id.replace("\"", "\\\"");
        let h_elem = document.querySelector("[id=\"" + id_escaped + "\"]"); // We assume that this is the h1/h2/h3 element referred by the TOC entry.
        if (h_elem === null) { // We assume that this is impossible.
            console.log("toc_generate_estimate: Impossible: " + href + " does not refer to anything");
            return;
        }
        let section = h_elem.parentNode;
        let section_word = count_word(section.textContent);
        let section_minute = Math.ceil(section_word / wpm_assumption);
        toc_entry_a.insertAdjacentElement("afterend", create_length_indicator(section_word, section_minute));
    });
});
        </script>

        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-12628443-6"></script>
<script>
  window['ga-disable-UA-12628443-6'] = window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1";
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-12628443-6');
</script>
        
        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            jax: ["input/TeX","input/MathML","input/AsciiMath",
            "output/CommonHTML"
            ],
            extensions: ["tex2jax.js","mml2jax.js","asciimath2jax.js","MathMenu.js","MathZoom.js","AssistiveMML.js", "a11y/accessibility-menu.js"],
            TeX: {
                extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
                , equationNumbers: {
                    autoNumber: "AMS"
                }
            },
            "CommonHTML": {
                scale: 100
            },
            "fast-preview": {
                disabled: true,
            }
        });
        </script>
        <style>
            /*
            PreviewHTML produces small Times New Roman text.
            PreviewHTML scale doesn't work.
            */
            .MathJax_PHTML { font-size: 110%; }
        </style>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js" async defer></script>
    </head>
    <body>
        <header class="site-header" role="banner">
            <div class="wrapper">
                <a class="site-title" rel="author" href="/">Erik Dominikus Research Group</a>
            </div>
        </header>
    <div style="display:none;">\(
    \renewcommand\emptyset{\varnothing}
    \newcommand\abs[1]{\left|#1\right|}
    \newcommand\dom{\textrm{dom}}
    \newcommand\cod{\textrm{cod}}
    \newcommand\Bernoulli{\textrm{Bernoulli}}
    \newcommand\Binomial{\textrm{Binomial}}
    \newcommand\Expect[1]{\mathbb{E}[#1]}
    \newcommand\Nat{\mathbb{N}}
    \newcommand\Integers{\mathbb{Z}}
    \newcommand\Real{\mathbb{R}}
    \newcommand\Rational{\mathbb{Q}}
    \newcommand\Complex{\mathbb{C}}
    \newcommand\Pr{\mathrm{P}}
    \newcommand\Time{\text{Time}}
    \newcommand\DTime{\text{DTime}}
    \newcommand\NTime{\text{NTime}}
    \newcommand\TimeP{\text{P}}
    \newcommand\TimeNP{\text{NP}}
    \newcommand\TimeExp{\text{ExpTime}}
    \newcommand\norm[1]{\left\lVert#1\right\rVert}
    \newcommand\bbA{\mathbb{A}}
    \newcommand\bbC{\mathbb{C}}
    \newcommand\bbD{\mathbb{D}}
    \newcommand\bbE{\mathbb{E}}
    \newcommand\bbN{\mathbb{N}}
    \newcommand\frakI{\mathfrak{I}}
    % deprecated; use TimeExp
    \newcommand\ExpTime{\text{ExpTime}}
    \newcommand\Compute{\text{Compute}}
    \newcommand\Search{\text{Search}}
    % model theory structure
    \newcommand\struc[1]{\mathcal{#1}}
    \newcommand\SetBuilder[2]{\{#1 ~|~ #2\}}
    \newcommand\Set[1]{\{#1\}}
    \newcommand\semantics[1]{\langle #1 \rangle}
    \newcommand\bigsemantics[1]{S\left(#1\right)}
    \)</div>
        <main class="page-content" aria-label="Content">
            <div class="wrapper">
                <article class="post">
                    <header class="post-header">
                        <h1 class="post-title">On remote viewing</h1>
                    </header>
                </article>
                <div class="post-content">
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">1</span><span class="section_title"><a href="#on-the-importance-of-practice">On the importance of practice</a></span><span class="word_count">(71w~1m)</span></li>
<li><span class="section_number">2</span><span class="section_title"><a href="#a-working-model-of-psychic-functioning">A working model of psychic functioning</a></span><span class="word_count">(143w~1m)</span></li>
<li><span class="section_number">3</span><span class="section_title"><a href="#on-the-subconscious">On the subconscious</a></span><span class="word_count">(29w~1m)</span></li>
<li><span class="section_number">4</span><span class="section_title"><a href="#what-we-know-about-remote-viewing">What we know about remote viewing</a></span><span class="word_count">(330w~2m)</span></li>
<li><span class="section_number">5</span><span class="section_title"><a href="#what-are-we-actually-learning">What are we actually learning?</a></span><span class="word_count">(123w~1m)</span></li>
<li><span class="section_number">6</span><span class="section_title"><a href="#practice-1">Practice 1</a></span><span class="word_count">(81w~1m)</span></li>
<li><span class="section_number">7</span><span class="section_title"><a href="#practice-2">Practice 2</a></span><span class="word_count">(281w~2m)</span></li>
<li><span class="section_number">8</span><span class="section_title"><a href="#remote-viewing-self-training-protocol">Remote viewing self-training protocol?</a></span><span class="word_count">(551w~3m)</span></li>
<li><span class="section_number">9</span><span class="section_title"><a href="#circumstantial-evidence-for-remote-viewing">Circumstantial evidence for remote viewing</a></span><span class="word_count">(94w~1m)</span></li>
<li><span class="section_number">10</span><span class="section_title"><a href="#my-opinion-on-some-names-associated-with-remote-viewing"><span class="todo TODO">TODO</span> My opinion on some names associated with remote viewing</a></span><span class="word_count">(121w~1m)</span></li>
<li><span class="section_number">11</span><span class="section_title"><a href="#how-did-some-people-remote-view-without-protocol">How did some people remote-view without protocol?</a></span><span class="word_count">(136w~1m)</span></li>
<li><span class="section_number">12</span><span class="section_title"><a href="#on-ingo-swann">On Ingo Swann</a></span><span class="word_count">(122w~1m)</span></li>
<li><span class="section_number">13</span><span class="section_title"><a href="#on-remote-viewing-1">On remote viewing</a></span><span class="word_count">(399w~2m)</span></li>
<li><span class="section_number">14</span><span class="section_title"><a href="#on-indirect-remote-viewing">On indirect remote viewing</a></span><span class="word_count">(388w~2m)</span></li>
<li><span class="section_number">15</span><span class="section_title"><a href="#delayed-decisions">Delayed decisions</a></span><span class="word_count">(12w~1m)</span></li>
<li><span class="section_number">16</span><span class="section_title"><a href="#bibliography">Bibliography</a></span><span class="word_count">(99w~1m)</span></li>
</ul>
</div>
<h2 id="on-the-importance-of-practice"><span class="section_number">1</span><span class="section_title">On the importance of practice</span></h2>
<p>Training/practice is extremely important.</p>
<p>Ingo Swann did not become a proficient psychic overnight. He debugged, practiced, and trained a lot, everyday, for tens of years, in thousands of training sessions; thus he was able to execute the protocol so quickly that it looked as if he did it spontaneously without any protocols.</p>
<p>Must read Swann 2018 <span class="citation" data-cites="swann2018everybody">[<a href="#ref-swann2018everybody">4</a>]</span>, but beware that it might be a reprint of his 1987 book?</p>
<h2 id="a-working-model-of-psychic-functioning"><span class="section_number">2</span><span class="section_title">A working model of psychic functioning</span></h2>
<p>This working model is mostly due to Ingo Swann?</p>
<p>The model combines Shannon information channel model and perception model.</p>
<p>We do not know how to increase the signal strength, but we know how to <em>reduce the noise</em>.</p>
<p>Remote viewing involves bilocation?<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>:</p>
<p>The theory so far is that, by quieting the mind, and relaxedly focusing the attention on the target, sometimes vague signals surface from the cosmic consciousness to the viewer's conscious mind.</p>
<p>&quot;A suggested remote viewing training procedure&quot;<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> (CIA Project Stargate FOIA archive). It contains a model (an explanatory hypothesis) of how remote viewing might work. It is written in plain language.</p>
<p>Is meditation thinking or feeling?</p>
<p>René Warcollier's &quot;Mind to mind&quot;?</p>
<p>I think we should first learn what we know about remote viewing<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>, and begin with free-response remote viewing. Free-response does not mean anything goes; there is still a <em>protocol</em> to follow to prevent contamination.</p>
<h2 id="on-the-subconscious"><span class="section_number">3</span><span class="section_title">On the subconscious</span></h2>
<p>It seems that automatic writing, automatic speaking, and remote viewing have something in common, and it seems that they can teach us to communicate with our subconscious.</p>
<h2 id="what-we-know-about-remote-viewing"><span class="section_number">4</span><span class="section_title">What we know about remote viewing</span></h2>
<p>This is mostly due to Ingo Swann's observations.</p>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">4.1</span><span class="section_title"><a href="#deterrents-to-psychic-reception">Deterrents to psychic reception</a></span><span class="word_count">(318w~2m)</span></li>
</ul>
</div>
<h3 id="deterrents-to-psychic-reception"><span class="section_number">4.1</span><span class="section_title">Deterrents to psychic reception</span></h3>
<p>Psychic reception is deterred by memory, imagination, and analysis. By &quot;analysis&quot;, we mean language and logic/inference/reasoning, the desire to name what is perceived, such as the desire to infer that a criss-cross metal pattern is the Eiffel tower. Perhaps the first step in training is to stop the analytic mind from functioning automatically.</p>
<p>There is almost no way to protect the target.</p>
<p>One way to disturb remote viewing is by placing <em>distractors</em>, temporally or spatially near the target. A distractor is a thing or event that is more emotional or interesting than the target.</p>
<p>That is, your mind is its own obstacle, not the target.</p>
<p>The analytic mind is like the respiratory system: they are <em>jointly controlled</em> by the conscious mind and the unconscious mind. However, the conscious mind only controls the chest muscles and not the desire to breathe. We know our desire to breathe, but we do not know any way to control our desire to breathe.</p>
<p>Conscious is manual, unconscious is automatic.</p>
<p>Example: conscious is your focal vision, subconscious is your peripheral vision, unconscious is your heart beat. If you try hard, you may be aware of your heart beat, but how much can you control it? You can control your heart beat indirectly by changing your breathing, but can you control your heart beat directly?</p>
<p>For example, if one holds his breath long enough, he will pass out and breathe involuntarily. But I don't know; I have never tried that myself; I have never seen anyone do it either.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
<p>We are much less conscious than we think we are.</p>
<p>We cannot directly control every single cell of our body. Thus, if we are the sum of everything we can control, what are we?</p>
<p>Interesting observation: Agitated mind blocks ESP reception but promotes telepathy<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></p>
<p>The sensory integration process can be modeled as a function <span class="math inline">\( \Real^n \to C \)</span> where <span class="math inline">\( n \)</span> is the number of sensory neurons and <span class="math inline">\( C \)</span> is a finite set of concepts.</p>
<h2 id="what-are-we-actually-learning"><span class="section_number">5</span><span class="section_title">What are we actually learning?</span></h2>
<p>When we are learning remote viewing, we are actually learning to <em>distinguish</em> between external psychic signals and internal signals conjured by our own mind (memory, imagination, analysis).</p>
<p>We are actually learning to deprogram, decondition ourselves.</p>
<p>If I was a psychic child as every child is and I grew to be a dumb adult, then perhaps all I have to do is to degrow or deprogram myself.</p>
<p>Children mostly <em>observe</em> and hardly analyze.</p>
<p>Children have little fear. The only fear is the one built-in (insects? abandonment?); children do not have fear from experience because they have not experienced pain.</p>
<p>Children like to play.</p>
<p>Children always seem mostly happy and running around.</p>
<p>Children are curious.</p>
<p>Children find everything new and fun.</p>
<p>Children touch everything. Children put everything in their mouth.</p>
<h2 id="practice-1"><span class="section_number">6</span><span class="section_title">Practice 1</span></h2>
<p>It must feel <em>fun</em> and unforced.</p>
<p>Do not feel invested in the outcome. In the viewing phase, do not worry about being right or wrong; worry about it later in the feedback phase.</p>
<p>Do not <em>judge</em>. Do not <em>doubt</em>. Do not <em>worry</em>.</p>
<p>Fix the gaze onto the paper, but do not strain/focus the eyes. Gently quiet the mind. Try to bilocate to the target.</p>
<p>Do not expect to actually see anything. (So how does it work?)</p>
<p>Focus on low-level perceptions and not on high-level inferences.</p>
<h2 id="practice-2"><span class="section_number">7</span><span class="section_title">Practice 2</span></h2>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">7.1</span><span class="section_title"><a href="#on-remote-viewing-target-pools">On remote-viewing target pools</a></span><span class="word_count">(124w~1m)</span></li>
<li><span class="section_number">7.2</span><span class="section_title"><a href="#on-the-ideal-training-targets-for-beginners">On the ideal training targets for beginners</a></span><span class="word_count">(157w~1m)</span></li>
</ul>
</div>
<h3 id="on-remote-viewing-target-pools"><span class="section_number">7.1</span><span class="section_title">On remote-viewing target pools</span></h3>
<p>Joe McMoneagle <span class="citation" data-cites="mcmoneagle2000remote">[<a href="#ref-mcmoneagle2000remote">2</a>]</span> stressed the importance of <em>target pools</em>.</p>
<p>What we call &quot;target pool&quot;, machine-learning researchers call &quot;dataset&quot;. On &lt;2019-09-16&gt;, an idea comes to me: Perhaps we can reuse machine-learning datasets for remote-viewing! For example, the datasets for &quot;Object detection and recognition&quot;<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> such as Caltech 101 (101 categories, 40–800 images per category, 126 MB)<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> and Caltech 256 (30607 images, 256 categories, 1.2 GB)<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>. But those datasets are not ideal; they have many complex images that mix several objects.</p>
<p>We can search and download some photos for personal use. I go to Google Images, search some common objects, and download some images.</p>
<p>However, if we train with photos, wouldn't that train the visual system disproportionately and atrophy the other senses?</p>
<p>We need hundreds of diverse-but-isolated targets.</p>
<h3 id="on-the-ideal-training-targets-for-beginners"><span class="section_number">7.2</span><span class="section_title">On the ideal training targets for beginners</span></h3>
<p>Targ 2010, chapter 3, section &quot;Choosing target objects&quot; <span class="citation" data-cites="targ2010limitless">[<a href="#ref-targ2010limitless">5</a>]</span> recommends (emphasis mine):</p>
<blockquote>
<p>[…] The target object should be <em>bigger than a matchbox and smaller than a bread box</em>. It should be visually interesting and have <em>describable parts</em>, rather than being compact. That is, a Raggedy-Ann doll or a teacup with a handle is easier to describe than an ivory Buddha figurine or a tennis ball. A pineapple would be easier to describe than a peach. A hairbrush is better than a nail file. […] It’s also best to <em>avoid using a target object that might be perceived as frightening or distasteful to the viewer</em>. This is an important point, since you would not want to violate your viewer’s unconditional trust of you or the process.</p>
</blockquote>
<p>In short, I think that the ideal image for a newbie remote viewer should be <em>convenient for someone to hold with his hands</em> and be <em>simple to sketch</em>.</p>
<h2 id="remote-viewing-self-training-protocol"><span class="section_number">8</span><span class="section_title">Remote viewing self-training protocol?</span></h2>
<p>On monitors: Because I have no friends, I have to be both the interviewer and the viewer. Can one concurrently (alternatingly) be the viewer and the monitor; that is, to alternate between remote-viewing and analyzing every 1 minute (sequentially, never simultaneously)?</p>
<p>How do we distinguish conscious noise (mental noise, &quot;interpretative overlay&quot;, now called &quot;analytical overlay&quot;) from remote-perception signal? This can only be personally experienced and cannot be said; it is like to make someone who has never seen a green thing know green; it must be directly experienced and cannot be transmitted by language.</p>
<p>The conscious mind interferes with its imagination.</p>
<p>Perhaps the aim of meditation is to <em>feel</em> that we are not our conscious minds. It is as if we were trying to look at ourselves from a third person point of view.</p>
<p>My hypothesis is that remote viewing experts are able to quickly relax their brains; perhaps they are able to quickly switch into and out of &quot;theta state&quot;?</p>
<p>Information comes in as short bursts (less than 1 second) of vague signals, not as a smooth sailing experience. Why is that?</p>
<div class="local_table_of_contents">
<ul>
<li><span class="section_number">8.1</span><span class="section_title"><a href="#an-imperfect-protocol-for-remote-viewing-self-training-using-google-maps">An imperfect protocol for remote viewing self-training using Google Maps</a></span><span class="word_count">(365w~2m)</span></li>
<li><span class="section_number">8.2</span><span class="section_title"><a href="#self-training-remote-viewing-using-machine-learning-datasets">Self-training remote viewing using machine learning datasets?</a></span><span class="word_count">(7w~1m)</span></li>
</ul>
</div>
<h3 id="an-imperfect-protocol-for-remote-viewing-self-training-using-google-maps"><span class="section_number">8.1</span><span class="section_title">An imperfect protocol for remote viewing self-training using Google Maps</span></h3>
<p>Open Google Maps in your browser.</p>
<p>Pick any city in the world. It is better to pick cities you are not familiar with. For example: another city in your country, or a city outside your country.</p>
<p>Adjust the zoom level such that you can see road names and some landmarks but not detailed buildings.</p>
<p>Drag the Street View guy to see roads that have Street View photos, but drop the guy back in the toolbar he came from; don't drop the guy on any road. While you are dragging the Street View guy, the roads with Street View will be highlighted in blue.</p>
<p>Cover the bottom part that shows preview photo.</p>
<p>Click on any point on any road that has Street View. Note the pair of coordinates in the search box. The pair of coordinates is the <em>identifier</em>. This identifier should be thought of referring to a Google Street View photo, not the real location on Earth where the photo was taken. We are interested in the photo itself, not in the location where it was taken.</p>
<p>Hide the browser window, such as by Alt+Tab-ing to another maximized window. You can now release your hand.</p>
<p>Remote view the target photo at the time the Street View photo was taken. Note that you want to remote-view the photo itself and not the actual location on Earth where the photo was taken.</p>
<p>Click the lower photo on the left sidebar to open Street View at that point.</p>
<p>Compare your remote viewing result and the Street View photo.</p>
<p>Repeat the exercise as many times as desired.</p>
<p>Note that this protocol is not perfect for training. The data pool is somewhat predictable, and some information leaks: You know there will be a road in the photo, and it seems that all Street View photos are taken at noon. But, from this, can you learn to tell apart between the roads that come from your imagination and the roads that come from your subconscious?</p>
<p>It seems focusing on the photo does not work; perhaps we should focus on the actual location.</p>
<p>This protocol is bad. It is too easy to accidentally click on something, and a photo pops up, and it contaminates your mind.</p>
<h3 id="self-training-remote-viewing-using-machine-learning-datasets"><span class="section_number">8.2</span><span class="section_title">Self-training remote viewing using machine learning datasets?</span></h3>
<h2 id="circumstantial-evidence-for-remote-viewing"><span class="section_number">9</span><span class="section_title">Circumstantial evidence for remote viewing</span></h2>
<p>The USA government spent <em>tens of millions of dollars and tens of years</em> to research remote viewing. (Source?)</p>
<p>If remote viewing did not work, surely they would have terminated it before they have spent twenty million dollars in twenty years.</p>
<p>But instead their research resulted in protocols.</p>
<p>Everyone can strictly follow a protocol and judge for themselves.</p>
<p>Remote viewing merits scientific investigation because it can be replicated by strictly following a protocol.</p>
<p>For the history of USA remote viewing, I recommend some pages in Daz Smith's remoteviewed.com,<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>,<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a> and Ingo Swann's book, and Russell Targ's book.</p>
<h2 id="my-opinion-on-some-names-associated-with-remote-viewing"><span class="section_number">10</span><span class="section_title"><span class="todo TODO">TODO</span> My opinion on some names associated with remote viewing</span></h2>
<p>Ingo Swann's writing was prone to rambling, but I consider his writing authoritative (at least the part that I can understand), because, after all, he is the father of remote viewing?</p>
<p>Harold E. Puthoff was the director of what in SRI?</p>
<p>Russell Targ?</p>
<p>Joseph McMoneagle seems honest to me. It seems to me that he does not pretend he knew how it works.</p>
<p>Edwin C. May knows some Russian researchers.</p>
<p>Lyn Buchanan?</p>
<p>Charles T. Tart?</p>
<p>David Morehouse wrote some incomprehensible quantum blub, had some bad reviews, <em>but</em> he can recommend a book that attacks him.</p>
<p>Jim Schnabel?</p>
<p>Jim Marrs (in the preface of what book? was it one of Ingo Swann's books?) claims that his manuscript was silenced/stolen?</p>
<p>Paul H. Smith?</p>
<p>Lori Williams<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a>?</p>
<h2 id="how-did-some-people-remote-view-without-protocol"><span class="section_number">11</span><span class="section_title">How did some people remote-view without protocol?</span></h2>
<p>Ingo Swann, Pat Price.</p>
<p>How did they do that?</p>
<p>Why could they do that?</p>
<p>Perhaps Ingo Swann does follow protocol, but he does it faster because he is accustomed to it (perhaps he has a &quot;muscle memory&quot; of it). After all, he had to be able to tell others how to do it, in order for other people to be able to learn to do it. Thus, I think the CRV protocol is a codification of how Ingo Swann did it.</p>
<p>Did Ingo Swann use ideograms? In his weather remote viewing experiment, he was strapped to an EEG machine, and he had to avoid moving too many muscles, so perhaps he did not ideograms, but perhaps he had some subtle kinesthetic response (subtle ideomotor response).</p>
<p>&quot;The Ideogram Controversy in Remote Viewing&quot; with Paul H. Smith<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a></p>
<h2 id="on-ingo-swann"><span class="section_number">12</span><span class="section_title">On Ingo Swann</span></h2>
<p>Why did he use the term &quot;bio-mind&quot; instead of just &quot;mind&quot;? Did he knew of &quot;non-bio-minds&quot;, such as artificial intelligence?</p>
<p>I should summarize his writings. I find his writing wordy and jumpy.</p>
<p>Important: Carole K. Silfen's experiments with Ingo Swann, that shows that remote viewing happens from a <em>point</em> in space.</p>
<p>Google Search returns nothing for Carole Silfen! What the hell happened to this person!?</p>
<p>If mediumship is true, and Ingo Swann has not crossed over to the other side, then we may be able to ask a medium to contact him, learn remote viewing, finish his books, etc., but is it wise to contact or disturb the departed? Perhaps not all of the departed would like that?</p>
<p>Ingo Swann's old website (biomindsuperpowers.com) in PDF.<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a></p>
<h2 id="on-remote-viewing-1"><span class="section_number">13</span><span class="section_title">On remote viewing</span></h2>
<p>STAR GATE documents <a href="http://www.remoteviewed.com/star-gate-documents/">http://www.remoteviewed.com/star-gate-documents/</a></p>
<p>Reddit <a href="https://www.reddit.com/r/remoteviewing/">https://www.reddit.com/r/remoteviewing/</a></p>
<p>There is evidence of remote viewing, although perhaps one has to experience it himself.</p>
<p>There is a protocol for remote viewing. It is <em>reproducible</em>. Thus it is a scientific experiment.</p>
<p>Joe McMoneagle 2000 book <span class="citation" data-cites="mcmoneagle2000remote">[<a href="#ref-mcmoneagle2000remote">2</a>]</span>.</p>
<p>Russell Targ, in his 2012 book <span class="citation" data-cites="targ2012reality">[<a href="#ref-targ2012reality">6</a>]</span>, advises us to think twice before enrolling in <em>expensive</em> remote-viewing schools:</p>
<blockquote>
<p>I believe there is presently no evidence that there is any benefit to paying thousands of dollars to attend any such remote-viewing school—as compared with reading this book or Ingo Swann’s wonderful book &quot;Natural ESP&quot;. But I could be wrong. The claims many of these schools make are confusing to the public, as implied by their very names—Controlled Remote Viewing (CRV®), Extended Remote Viewing (ERV®), and Technical Remote Viewing (TRV®), for example. Joe McMoneagle, who was one of the first, and by far the most successful of the army viewers, has also written an excellent book, &quot;Remote Viewing Secrets&quot;, in which he unscrambles these acronyms. He also describes a very clear and sensible approach to learning remote viewing, based on his more than thirty years of experience. <span class="citation" data-cites="targ2012reality">[<a href="#ref-targ2012reality">6</a>]</span></p>
</blockquote>
<p>I find Buchanan 2009 <span class="citation" data-cites="buchanan2009seventh">[<a href="#ref-buchanan2009seventh">1</a>]</span> to be more comprehensive than McMoneagle 2000 <span class="citation" data-cites="mcmoneagle2000remote">[<a href="#ref-mcmoneagle2000remote">2</a>]</span> or Targ 2012 <span class="citation" data-cites="targ2012reality">[<a href="#ref-targ2012reality">6</a>]</span>.</p>
<p>&lt;2019-09-16&gt; I'm trying remote viewing. I think my accuracy so far, as a total newbie, out of about 5 trials, is below 10%.</p>
<p>Remote viewing has been used for psychic archeology.<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a> Stephan A. Schwartz seems to have some strong evidence for remote viewing, with archeological flair. It seems promising. Project Deep Quest.<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a></p>
<p>More recent, 2004, Courtney Brown, &quot;Scientific Remote Viewing&quot;, a protocol<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a></p>
<p>International Remote Viewing Association<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a>.</p>
<p>It seems remote viewers undergo some spiritual changes.</p>
<p>If the issue is the bandwidth (transfer rate) between the conscious and the subconscious, then it should be easiest to train with smell and taste first, with the senses that evolved first. Then, it should be easy to discern between light and dark ambience, but not the visual details. Then, color, heat, pressure, and so on. Sight contains lots of information. A lot of things enter our eyes, then the brain ignores a lot of them, but there is still a lot of information at our focal point.</p>
<p>But my experiment is inconclusive; I remote-viewed poorly with smell, taste, or sight; I think relaxation is more important than choice of the senses?</p>
<p>Perhaps the state of relaxed focus is like Cziksenmihaly's state of flow; as a computer programmer, I am familiar with this state.</p>
<h2 id="on-indirect-remote-viewing"><span class="section_number">14</span><span class="section_title">On indirect remote viewing</span></h2>
<p>Is <em>reverse remote viewing</em> possible? In forward remote viewing, from an address, we perceive the object referred to by the address. In reverse remote viewing, from a photo, we find out where the photo was taken.</p>
<p>But isn't reverse remote viewing just forward remote viewing whose address is the photo and whose object is the address where the photo was taken?</p>
<p><em>Associative remote viewing</em> can be used to ask multiple-choice questions about the future.</p>
<p>Targ et al. used <em>associative</em> remote viewing for financial prediction, because it is hard to remote-view anything <em>analytical</em> such as numbers, letters, etc.<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a> Why is that? Why is it hard to remote-view left-brain stuff? Are there psychic people without right hemisphere? What is Sperry's split-brain experiment trying to tell us?<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a> Why does it seem that people without corpus callosum cannot verbally describe the things in their left visual field? Douglas Dean et al. (in &quot;Executive ESP&quot; book) found that CEOs of profitable companies have more precognitive abilities than the CEOs of non-profitable companies do. Rauscher &amp; Targ 2006 proposes a &quot;complex Minkowski space&quot;<span class="citation" data-cites="rauscher2006investigation">[<a href="#ref-rauscher2006investigation">3</a>]</span>, a generalization of the Minkowski space in Einstein's general relativity theory.</p>
<p>But, in the same book <span class="citation" data-cites="targ2012reality">[<a href="#ref-targ2012reality">6</a>]</span>, Targ claims that Ingo could &quot;read the code words written on the file cabinets&quot;. Perhaps it's because it was so hidden that it became so clear in the psychic space; that is what Targ reports Pat Price said.</p>
<blockquote>
<p>When the two CIA agents who came to investigate asked why he had so accurately described the “incorrect” location, Pat said, “The more intent you are on hiding something, the more it shines like a beacon in psychic space.” <span class="citation" data-cites="targ2012reality">[<a href="#ref-targ2012reality">6</a>]</span></p>
</blockquote>
<p>Psychic stock pickers, gamblers, or lottery winners?</p>
<p>One can use remote viewing to profit from the financial market.<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a><a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a> However, it would be more convincing if the study lasted <em>tens of years</em> through several economic cycles and crises instead of only 17 months.</p>
<p>But what about the Efficient Market Hypothesis? What if all financial traders are psychic with 100% accuracy? What if all relevant future events are known and certain, and the price takes into account all of those future events? Will the price the constant? If everyone knew that, exactly 123,456 days later, the biggest oil pipeline will experience an inevitable catastrophe with certain probability, then what would the price of oil be?</p>
<p>There is a <em>genealogy</em> of remote viewing methods.<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a><a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a></p>
<h2 id="delayed-decisions"><span class="section_number">15</span><span class="section_title">Delayed decisions</span></h2>
<p>&lt;2019-11-05&gt; Is Arvari<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a> (Academy of Remote Viewing and Remote Influencing) legitimate?</p>
<h2 id="bibliography" class="unnumbered"><span class="section_number">16</span><span class="section_title">Bibliography</span></h2>
<div id="refs" class="references">
<div id="ref-buchanan2009seventh">
<p>[1] Buchanan, L. 2009. <em>The seventh sense: The secrets of remote viewing as told by a&quot; psychi</em>. Simon; Schuster.</p>
</div>
<div id="ref-mcmoneagle2000remote">
<p>[2] McMoneagle, J. 2000. <em>Remote viewing secrets: A handbook</em>. Hampton Roads Publishing Company.</p>
</div>
<div id="ref-rauscher2006investigation">
<p>[3] Rauscher, E.A. and Targ, R. 2006. Investigation of a complex space-time metric to describe precognition of the future. <em>AIP conference proceedings</em> (2006), 121–146. url: &lt;<a href="http://www.espresearch.com/espgeneral/doc-SpeedOfThought.pdf">http://www.espresearch.com/espgeneral/doc-SpeedOfThought.pdf</a>&gt;.</p>
</div>
<div id="ref-swann2018everybody">
<p>[4] Swann, I. 2018. <em>Everybody’s guide to natural esp</em>. Swann-Ryder Productions, LLC.</p>
</div>
<div id="ref-targ2010limitless">
<p>[5] Targ, R. 2010. <em>Limitless mind: A guide to remote viewing and transformation of consciousness</em>. New World Library.</p>
</div>
<div id="ref-targ2012reality">
<p>[6] Targ, R. 2012. <em>The reality of esp: A physicist’s proof of psychic abilities</em>. Quest Books.</p>
</div>
</div>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>&lt;2019-11-11&gt; <a href="http://www.remoteviewed.com/crv_docs_full.pdf">http://www.remoteviewed.com/crv_docs_full.pdf</a><a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p><a href="https://www.cia.gov/library/readingroom/document/cia-rdp96-00789r002200070001-0">https://www.cia.gov/library/readingroom/document/cia-rdp96-00789r002200070001-0</a><a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>&lt;2019-09-18&gt; Targ &amp; Ketra, &quot;What We Know About Remote Viewing&quot; <a href="http://www.espresearch.com/espgeneral/WhatWeKnow.shtml">http://www.espresearch.com/espgeneral/WhatWeKnow.shtml</a><a href="#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>&lt;2019-11-16&gt; <a href="https://biology.stackexchange.com/questions/73866/why-cant-we-kill-ourselves-by-holding-our-breath">https://biology.stackexchange.com/questions/73866/why-cant-we-kill-ourselves-by-holding-our-breath</a><a href="#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>&lt;2019-11-16&gt; InPresence 0006: Blocks to Psychic Functioning with Jeffrey Mishlove <a href="https://www.youtube.com/watch?v=TBL-TaUROXc">https://www.youtube.com/watch?v=TBL-TaUROXc</a><a href="#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>&lt;2019-09-16&gt; <a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research#Object_detection_and_recognition">https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research#Object_detection_and_recognition</a><a href="#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>&lt;2019-09-19&gt; <a href="http://www.vision.caltech.edu/Image_Datasets/Caltech101/">http://www.vision.caltech.edu/Image_Datasets/Caltech101/</a><a href="#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p>&lt;2019-09-19&gt; <a href="http://www.vision.caltech.edu/Image_Datasets/Caltech256/">http://www.vision.caltech.edu/Image_Datasets/Caltech256/</a><a href="#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p>&lt;2019-11-11&gt; <a href="http://www.remoteviewed.com/remote_viewing_history_military.htm">http://www.remoteviewed.com/remote_viewing_history_military.htm</a><a href="#fnref9" class="footnote-back">↩</a></p></li>
<li id="fn10"><p>&lt;2019-11-11&gt; <a href="http://www.remoteviewed.com/rvhistorymap.html">http://www.remoteviewed.com/rvhistorymap.html</a><a href="#fnref10" class="footnote-back">↩</a></p></li>
<li id="fn11"><p>&lt;2019-11-09&gt; Mishlove interview <a href="https://www.youtube.com/watch?v=wKIxQEPu7ys">https://www.youtube.com/watch?v=wKIxQEPu7ys</a><a href="#fnref11" class="footnote-back">↩</a></p></li>
<li id="fn12"><p>&lt;2019-11-11&gt; The Ideogram Controversy in Remote Viewing with Paul H. Smith <a href="https://www.youtube.com/watch?v=CGOKfM7AORI">https://www.youtube.com/watch?v=CGOKfM7AORI</a><a href="#fnref12" class="footnote-back">↩</a></p></li>
<li id="fn13"><p>&lt;2019-11-15&gt; <a href="https://ingoswann.com/biomind-1">https://ingoswann.com/biomind-1</a><a href="#fnref13" class="footnote-back">↩</a></p></li>
<li id="fn14"><p>&lt;2019-09-13&gt; The History of Psychic Archeology with Stephan A. Schwartz <a href="https://www.youtube.com/watch?v=KwcEyflmaxk">https://www.youtube.com/watch?v=KwcEyflmaxk</a><a href="#fnref14" class="footnote-back">↩</a></p></li>
<li id="fn15"><p>&lt;2019-09-13&gt; Project Deep Quest with Stephan A. Schwartz <a href="https://www.youtube.com/watch?v=WH4i7Z4JwPA">https://www.youtube.com/watch?v=WH4i7Z4JwPA</a><a href="#fnref15" class="footnote-back">↩</a></p></li>
<li id="fn16"><p><a href="https://farsight.org/SRV/SRVManualByCourtneyBrown.pdf">https://farsight.org/SRV/SRVManualByCourtneyBrown.pdf</a><a href="#fnref16" class="footnote-back">↩</a></p></li>
<li id="fn17"><p><a href="https://www.irva.org/remote-viewing/howto.html">https://www.irva.org/remote-viewing/howto.html</a><a href="#fnref17" class="footnote-back">↩</a></p></li>
<li id="fn18"><p>&lt;2019-09-16&gt; 3:27 Precognitive Financial Forecasting with Russell Targ <a href="https://www.youtube.com/watch?v=bQK0oHP94x4">https://www.youtube.com/watch?v=bQK0oHP94x4</a><a href="#fnref18" class="footnote-back">↩</a></p></li>
<li id="fn19"><p><a href="https://www.psychologytoday.com/intl/blog/consciousness-self-organization-and-neuroscience/201802/no-you-re-not-left-brained-or-right">https://www.psychologytoday.com/intl/blog/consciousness-self-organization-and-neuroscience/201802/no-you-re-not-left-brained-or-right</a><a href="#fnref19" class="footnote-back">↩</a></p></li>
<li id="fn20"><p>&lt;2019-09-11&gt; 60% success rate is not an exorbitant claim; 17-month study; brochure for a 2005 workshop <a href="http://www.espresearch.com/JAN05ARVBrochure.pdf">http://www.espresearch.com/JAN05ARVBrochure.pdf</a><a href="#fnref20" class="footnote-back">↩</a></p></li>
<li id="fn21"><p>&lt;2019-09-11&gt; SSE Talks - Remote viewing the Stock Market - Christopher Carson Smith <a href="https://www.youtube.com/watch?v=K3x5QHD7Ewo">https://www.youtube.com/watch?v=K3x5QHD7Ewo</a><a href="#fnref21" class="footnote-back">↩</a></p></li>
<li id="fn22"><p>&lt;2019-09-16&gt; <a href="http://www.remoteviewed.com/methodshistorymap.html">http://www.remoteviewed.com/methodshistorymap.html</a><a href="#fnref22" class="footnote-back">↩</a></p></li>
<li id="fn23"><p>&lt;2019-09-16&gt; <a href="http://www.remoteviewed.com/remote-viewing-methods/">http://www.remoteviewed.com/remote-viewing-methods/</a><a href="#fnref23" class="footnote-back">↩</a></p></li>
<li id="fn24"><p>&lt;2019-11-05&gt; <a href="https://arvari.probablefuture.com/">https://arvari.probablefuture.com/</a><a href="#fnref24" class="footnote-back">↩</a></p></li>
</ol>
</section>
                </div>
            </div>
        </main>
        <footer class="site-footer h-card">
            <data class="u-url" href="/"></data>
            <div class="wrapper">
                <p>This page was created on 2019-09-07 00:00:00 +0700.</p>
                <p class="rss-subscribe">The
                    <a href="/feed.xml">RSS feed</a> of this website has not been implemented.</p>
                <p>
                    I used Disqus, but I removed it because it hijacks my links and redirects them to third-party ad networks.
                    On 2019-05-27, a friend of mine reported that links on my website were broken,
                    and I caught Disqus red-handed redirecting my links to pwieu.com.
                </p>
            </div>
        </footer>
    </body>
</html>
